<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Reza Mohammadi">

<title>7&nbsp; Classification Using k-Nearest Neighbors – &lt;span style='color:#0056B3'&gt;Data Science Foundations and Machine Learning with R: From Data to Decisions&lt;/span&gt;</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./8-Model-evaluation.html" rel="next">
<link href="./6-Setup-data.html" rel="prev">
<link href="./images/logo.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5c395c020fa0215c66c8d962dcba7617.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./7-Classification-kNN.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification Using k-Nearest Neighbors</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"><span style="color:#0056B3">Data Science Foundations and Machine Learning with R: From Data to Decisions</span></a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/RezaMoammadi/Book-Data-Science-R" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./-span-style=-color--0056B3--Data-Science-Foundations-and-Machine-Learning-with-R--From-Data-to-Decisions--span-.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./-span-style=-color--0056B3--Data-Science-Foundations-and-Machine-Learning-with-R--From-Data-to-Decisions--span-.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-Intro-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">R Foundations for Data Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-Intro-data-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Data Science Workflow and the Role of Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-Data-preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Preparation in Practice: From Raw Data to Insight</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-Exploratory-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Exploratory Data Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-Statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Statistical Inference and Hypothesis Testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6-Setup-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Setup for Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7-Classification-kNN.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification Using k-Nearest Neighbors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8-Model-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Model Evaluation and Performance Assessment</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9-Naive-Bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Naive Bayes Classifier</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regression Analysis: Foundations and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-Tree-based-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Decision Trees and Random Forests</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-Neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Neural Networks: Foundations of Artificial Intelligence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Clustering for Insight: Segmenting Data Without Labels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-References.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-this-chapter-covers" id="toc-what-this-chapter-covers" class="nav-link active" data-scroll-target="#what-this-chapter-covers">What This Chapter Covers</a></li>
  <li><a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification"><span class="header-section-number">7.1</span> Classification</a>
  <ul class="collapse">
  <li><a href="#how-classification-works" id="toc-how-classification-works" class="nav-link" data-scroll-target="#how-classification-works">How Classification Works</a></li>
  <li><a href="#classification-algorithms-and-the-role-of-knn" id="toc-classification-algorithms-and-the-role-of-knn" class="nav-link" data-scroll-target="#classification-algorithms-and-the-role-of-knn">Classification Algorithms and the Role of kNN</a></li>
  </ul></li>
  <li><a href="#how-k-nearest-neighbors-works" id="toc-how-k-nearest-neighbors-works" class="nav-link" data-scroll-target="#how-k-nearest-neighbors-works"><span class="header-section-number">7.2</span> How k-Nearest Neighbors Works</a>
  <ul class="collapse">
  <li><a href="#how-does-knn-classify-a-new-observation" id="toc-how-does-knn-classify-a-new-observation" class="nav-link" data-scroll-target="#how-does-knn-classify-a-new-observation">How Does kNN Classify a New Observation?</a></li>
  <li><a href="#strengths-and-limitations-of-knn" id="toc-strengths-and-limitations-of-knn" class="nav-link" data-scroll-target="#strengths-and-limitations-of-knn">Strengths and Limitations of kNN</a></li>
  </ul></li>
  <li><a href="#a-simple-example-of-knn-classification" id="toc-a-simple-example-of-knn-classification" class="nav-link" data-scroll-target="#a-simple-example-of-knn-classification"><span class="header-section-number">7.3</span> A Simple Example of kNN Classification</a></li>
  <li><a href="#sec-ch7-knn-distance-metrics" id="toc-sec-ch7-knn-distance-metrics" class="nav-link" data-scroll-target="#sec-ch7-knn-distance-metrics"><span class="header-section-number">7.4</span> How Does kNN Measure Similarity?</a>
  <ul class="collapse">
  <li><a href="#euclidean-distance" id="toc-euclidean-distance" class="nav-link" data-scroll-target="#euclidean-distance"><span class="header-section-number">7.4.1</span> Euclidean Distance</a></li>
  </ul></li>
  <li><a href="#sec-ch7-knn-prep" id="toc-sec-ch7-knn-prep" class="nav-link" data-scroll-target="#sec-ch7-knn-prep"><span class="header-section-number">7.5</span> Data Setup for kNN</a>
  <ul class="collapse">
  <li><a href="#sec-ch7-knn-proper-scaling" id="toc-sec-ch7-knn-proper-scaling" class="nav-link" data-scroll-target="#sec-ch7-knn-proper-scaling"><span class="header-section-number">7.5.1</span> Preventing Data Leakage during Scaling</a></li>
  </ul></li>
  <li><a href="#sec-ch7-knn-choose-k" id="toc-sec-ch7-knn-choose-k" class="nav-link" data-scroll-target="#sec-ch7-knn-choose-k"><span class="header-section-number">7.6</span> Choosing the Right Value of <em>k</em> in kNN</a></li>
  <li><a href="#sec-ch7-knn-churn" id="toc-sec-ch7-knn-churn" class="nav-link" data-scroll-target="#sec-ch7-knn-churn"><span class="header-section-number">7.7</span> Case Study: Predicting Customer Churn with kNN</a>
  <ul class="collapse">
  <li><a href="#data-setup-for-knn" id="toc-data-setup-for-knn" class="nav-link" data-scroll-target="#data-setup-for-knn"><span class="header-section-number">7.7.1</span> Data Setup for kNN</a></li>
  <li><a href="#finding-the-best-value-for-k" id="toc-finding-the-best-value-for-k" class="nav-link" data-scroll-target="#finding-the-best-value-for-k"><span class="header-section-number">7.7.2</span> Finding the Best Value for <span class="math inline">\(k\)</span></a></li>
  <li><a href="#applying-the-knn-classifier" id="toc-applying-the-knn-classifier" class="nav-link" data-scroll-target="#applying-the-knn-classifier"><span class="header-section-number">7.7.3</span> Applying the kNN Classifier</a></li>
  <li><a href="#evaluating-model-performance-of-the-knn-model" id="toc-evaluating-model-performance-of-the-knn-model" class="nav-link" data-scroll-target="#evaluating-model-performance-of-the-knn-model"><span class="header-section-number">7.7.4</span> Evaluating Model Performance of the kNN Model</a></li>
  </ul></li>
  <li><a href="#chapter-summary-and-takeaways" id="toc-chapter-summary-and-takeaways" class="nav-link" data-scroll-target="#chapter-summary-and-takeaways"><span class="header-section-number">7.8</span> Chapter Summary and Takeaways</a></li>
  <li><a href="#sec-ch7-exercises" id="toc-sec-ch7-exercises" class="nav-link" data-scroll-target="#sec-ch7-exercises"><span class="header-section-number">7.9</span> Exercises</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/edit/main/7-Classification-kNN.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-ch7-classification-knn" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification Using k-Nearest Neighbors</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="chapterquote">
<p>Tell me who your friends are, and I will tell you who you are.</p>
<div class="author">
<p>— Spanish proverb</p>
</div>
</div>
<p>Classification is a foundational task in machine learning. It enables algorithms to assign observations to predefined categories based on patterns learned from labeled data. Whether we filter spam emails or predict customer churn, classification models support decisions in many real-world systems. In this chapter, we introduce classification as a supervised learning problem and focus on a method that is both intuitive and practical for a first encounter with predictive modeling.</p>
<p>This chapter marks the start of Step 5 (Modeling) in the Data Science Workflow (Figure <a href="2-Intro-data-science.html#fig-ch2_DSW" class="quarto-xref"><span>2.3</span></a>). In earlier chapters, we cleaned and explored data, developed statistical reasoning, and prepared datasets for modeling. We now turn to building predictive models and evaluating how well they generalize. This chapter connects directly to Step 4 (Data Setup for Modeling) in Chapter <a href="6-Setup-data.html" class="quarto-xref"><span>6</span></a>, where we partitioned datasets and applied preprocessing choices such as encoding and scaling to support leakage-free evaluation.</p>
<section id="what-this-chapter-covers" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="what-this-chapter-covers">What This Chapter Covers</h3>
<p>We begin by defining classification and contrasting it with regression. We then introduce k-Nearest Neighbors (kNN), a distance-based method that predicts the class of a new observation by examining the labels of its closest neighbors in the training set. Because kNN relies on distance calculations, we also show why preprocessing decisions, particularly encoding and feature scaling, are essential for meaningful comparisons.</p>
<p>To demonstrate the complete workflow, we apply kNN to the <code>churn</code> dataset, where the goal is to predict whether a customer will discontinue a service. We work through data setup, selection of the hyperparameter <span class="math inline">\(k\)</span>, model fitting in R, and performance evaluation. The case study provides a reusable template for applying kNN to other classification problems.</p>
<p>By the end of this chapter, readers will understand how classification models generate predictions, how kNN translates similarity into a decision rule, and how to implement and evaluate kNN in a principled way.</p>
</section>
<section id="classification" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="classification"><span class="header-section-number">7.1</span> Classification</h2>
<p>How do email applications filter spam or banks detect fraudulent transactions in real time? Such systems rely on classification, a core task in supervised machine learning that assigns observations to one of several predefined categories based on observed patterns in labeled data.</p>
<p>In a classification problem, the goal is to predict a categorical outcome. For example, given customer attributes, a model may predict whether a customer is likely to churn. This differs from regression, where the outcome is numeric, such as income or house price.</p>
<p>The outcome variable in classification, often called the class or label, can take different forms. In binary classification, the outcome has two possible categories, such as churn versus no churn. In multiclass classification, the outcome includes more than two categories, such as identifying different object types in image recognition.</p>
<p>Classification plays a central role in many application domains. It supports decision-making in areas such as fraud detection, customer retention, medical diagnosis, and content recommendation. Across these settings, the common objective is to translate structured input data into meaningful, actionable predictions.</p>
<section id="how-classification-works" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="how-classification-works">How Classification Works</h3>
<p>Most classification methods follow a common conceptual framework. During the training stage, the model learns relationships between input features and known class labels using a labeled dataset. During the prediction stage, the trained model assigns class labels to new observations based on the learned patterns.</p>
<p>An effective classification model does more than reproduce the training data. It captures systematic structure that allows it to generalize, meaning that it produces accurate predictions for new observations not seen during training. This ability to generalize is a defining property of supervised learning and a key criterion for evaluating classification models.</p>
<p>As we will see in this chapter, not all classifiers implement these stages in the same way. In particular, k-Nearest Neighbors differs from many models by postponing most computation until predictions are made, an idea we examine in detail in the following sections.</p>
</section>
<section id="classification-algorithms-and-the-role-of-knn" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="classification-algorithms-and-the-role-of-knn">Classification Algorithms and the Role of kNN</h3>
<p>A wide range of algorithms can be used for classification. Each method is suited to different data characteristics and modeling objectives, and no single approach performs best in all settings. Common classification algorithms include:</p>
<ul>
<li><p>k-Nearest Neighbors (kNN) assigns class labels based on the closest observations in the training data and is the focus of this chapter.</p></li>
<li><p>Naive Bayes is a probabilistic classifier that performs well in high-dimensional settings such as text analysis (see Chapter <a href="9-Naive-Bayes.html" class="quarto-xref"><span>9</span></a>).</p></li>
<li><p>Logistic Regression models binary outcomes and offers clear interpretability of predictor effects (see Chapter <a href="10-Regression.html" class="quarto-xref"><span>10</span></a>).</p></li>
<li><p>Decision Trees and Random Forests capture nonlinear relationships and feature interactions (see Chapter <a href="11-Tree-based-models.html" class="quarto-xref"><span>11</span></a>).</p></li>
<li><p>Neural Networks are high-capacity models designed for complex or unstructured data (see Chapter <a href="12-Neural-networks.html" class="quarto-xref"><span>12</span></a>).</p></li>
</ul>
<p>The choice of a classification algorithm depends on factors such as dataset size, feature types, interpretability requirements, and computational constraints. For small to medium-sized tabular datasets, or when model transparency is important, simpler methods such as kNN or logistic regression are often appropriate. For large-scale or highly complex problems, more flexible models may offer superior performance.</p>
<p>Among these methods, kNN is particularly useful as an introductory classifier. It makes minimal assumptions about the underlying data and relies directly on the concept of similarity between observations. For this reason, kNN is often used as a baseline model that helps assess the intrinsic difficulty of a classification task and highlights the importance of preprocessing choices such as encoding and feature scaling.</p>
<p>In the sections that follow, we examine how kNN measures similarity, how the number of neighbors influences its behavior, and how the algorithm can be implemented and evaluated using the <code>churn</code> dataset in R.</p>
</section>
</section>
<section id="how-k-nearest-neighbors-works" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="how-k-nearest-neighbors-works"><span class="header-section-number">7.2</span> How k-Nearest Neighbors Works</h2>
<p>Imagine making a decision by consulting a small group of peers who have faced similar situations. The k-Nearest Neighbors (kNN) algorithm follows a comparable principle: it predicts outcomes based on the most similar observations observed in the past. This reliance on similarity makes kNN one of the most intuitive methods in classification.</p>
<p>Unlike many classification algorithms, kNN does not estimate model parameters during a dedicated training stage. Instead, it stores the training data and defers most computation until a prediction is required, a strategy commonly referred to as lazy learning. When a new observation is presented, the algorithm computes its distance to all training points, identifies the <em>k</em> closest neighbors, and assigns the class label that occurs most frequently among them. The value of <em>k</em>, which determines how many neighbors are considered, plays a central role in shaping the model’s behavior.</p>
<p>Because kNN shifts computation from training to prediction, it avoids explicit model fitting but incurs higher computational cost when classifying new observations. This trade-off is an important practical consideration when working with larger datasets.</p>
<section id="how-does-knn-classify-a-new-observation" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="how-does-knn-classify-a-new-observation">How Does kNN Classify a New Observation?</h3>
<p>To classify a new observation, the kNN algorithm computes its distance to each point in the training set, typically using Euclidean distance. The algorithm then selects the <em>k</em> nearest neighbors and assigns the class label that appears most frequently among them.</p>
<p>Figure <a href="#fig-ch7-knn-image" class="quarto-xref"><span>7.1</span></a> illustrates this idea using a simple two-dimensional dataset with two classes and a new data point to be classified. When <em>k</em> is small, the prediction depends on a limited number of nearby points. When <em>k</em> is larger, more neighbors influence the decision, potentially leading to a different classification outcome.</p>
<ul>
<li><p>For <span class="math inline">\(k = 3\)</span>, the majority of the nearest neighbors belong to one class, resulting in that class being assigned to the new observation.</p></li>
<li><p>For <span class="math inline">\(k = 6\)</span>, a different class becomes dominant among the nearest neighbors, leading to a different predicted label.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ch7-knn-image" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="H" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch7-knn-image-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/ch7_knn.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch7-knn-image-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: A two-dimensional toy dataset with two classes and a new data point, illustrating the kNN algorithm with k = 3 and k = 6.
</figcaption>
</figure>
</div>
</div>
</div>
<p>This example illustrates how the choice of <em>k</em> directly influences the classification result. Smaller values of <em>k</em> emphasize local structure and may be sensitive to noise, while larger values incorporate broader neighborhood information and produce smoother decision boundaries. Selecting an appropriate value of <em>k</em> is therefore essential, a topic we examine in more detail later in this chapter.</p>
</section>
<section id="strengths-and-limitations-of-knn" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="strengths-and-limitations-of-knn">Strengths and Limitations of kNN</h3>
<p>The kNN algorithm is valued for its simplicity and transparency. Because predictions are based directly on nearby observations, the reasoning behind each classification is easy to interpret. This makes kNN a natural starting point for understanding classification and a useful baseline for comparison with more complex models.</p>
<p>At the same time, kNN has important limitations. The algorithm is sensitive to irrelevant or noisy features, which can distort distance calculations and degrade performance. Since distances are computed to all training observations at prediction time, kNN can also become computationally expensive as the size of the training set grows.</p>
<p>The effectiveness of kNN therefore depends strongly on careful data preparation. Feature selection, appropriate scaling, and outlier handling all play a critical role in ensuring that distance calculations reflect meaningful structure in the data. These considerations motivate the preprocessing steps discussed in the following sections.</p>
</section>
</section>
<section id="a-simple-example-of-knn-classification" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="a-simple-example-of-knn-classification"><span class="header-section-number">7.3</span> A Simple Example of kNN Classification</h2>
<p>To illustrate how kNN operates in practice, we consider a simplified classification example involving drug prescriptions. We use a synthetic dataset of 200 patients that records each patient’s age, sodium-to-potassium (Na/K) ratio, and prescribed drug type. Although artificially generated, the dataset reflects patterns commonly encountered in clinical decision settings. It is available in the <strong>liver</strong> package under the name <code>drug</code>. Figure <a href="#fig-ch7-ex-drug-2" class="quarto-xref"><span>7.2</span></a> shows the distribution of patients in a two-dimensional feature space, where each point represents a patient and the drug type is indicated by color and shape.</p>
<p>Suppose three new patients arrive at the clinic, and we must determine which drug is most suitable for each based on age and Na/K ratio. Patient 1 is 40 years old with a Na/K ratio of 30.5. Patient 2 is 28 years old with a ratio of 9.6, and Patient 3 is 61 years old with a ratio of 10.5. These patients are shown as stars in Figure <a href="#fig-ch7-ex-drug-2" class="quarto-xref"><span>7.2</span></a>, together with their three nearest neighbors.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ch7-ex-drug-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="H" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch7-ex-drug-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-ex-drug-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch7-ex-drug-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Scatter plot of age versus sodium-to-potassium ratio for 200 patients, with drug type indicated by color and shape. The three new patients are shown as dark stars, and their three nearest neighbors are highlighted with gray circles.
</figcaption>
</figure>
</div>
</div>
</div>
<p>For Patient 1, the classification is straightforward. The patient lies well within a cluster of training observations that share the same drug label, and all nearest neighbors agree on the assigned class. In such cases, kNN produces a stable and confident prediction.</p>
<p>For Patient 2, the predicted class depends on the chosen value of <em>k</em>, as illustrated in the left panel of Figure <a href="#fig-ch7-ex-drug-3" class="quarto-xref"><span>7.3</span></a>. When <span class="math inline">\(k = 1\)</span>, the prediction is determined by a single neighbor. When <span class="math inline">\(k = 2\)</span>, the nearest neighbors belong to different classes, resulting in a tie. At <span class="math inline">\(k = 3\)</span>, a majority emerges and the prediction stabilizes. This example illustrates how small values of <em>k</em> can lead to unstable decisions and how increasing <em>k</em> can reduce sensitivity to individual observations.</p>
<p>For Patient 3, shown in the right panel of Figure <a href="#fig-ch7-ex-drug-3" class="quarto-xref"><span>7.3</span></a>, classification is inherently uncertain. The patient lies close to the boundary between multiple clusters, and the nearest neighbors represent different drug types. Even with <span class="math inline">\(k = 3\)</span>, no clear majority exists. Small changes in the patient’s features could shift the balance toward a different class. This behavior highlights a key limitation of kNN: predictions near class boundaries can be highly sensitive to both feature values and the choice of <em>k</em>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ch7-ex-drug-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="H" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch7-ex-drug-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-ex-drug-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch7-ex-drug-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: Zoomed-in views of new Patient 2 (left) and new Patient 3 (right) with their three nearest neighbors.
</figcaption>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p><em>Practice:</em> Using Figure <a href="#fig-ch7-ex-drug-2" class="quarto-xref"><span>7.2</span></a>, consider how kNN might classify a 50-year-old patient with a sodium-to-potassium ratio of 10. How would your reasoning change as the value of <span class="math inline">\(k\)</span> increases?</p>
</blockquote>
<p>This example illustrates several important aspects of kNN. The value of <em>k</em> influences the stability of predictions, observations near class boundaries are inherently harder to classify, and distance-based decisions are sensitive to the geometry of the feature space. These insights motivate the next sections, where we formalize how similarity is measured and examine principled strategies for choosing the value of <em>k</em>.</p>
</section>
<section id="sec-ch7-knn-distance-metrics" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="sec-ch7-knn-distance-metrics"><span class="header-section-number">7.4</span> How Does kNN Measure Similarity?</h2>
<p>Suppose you are a physician comparing two patients based on age and sodium-to-potassium (Na/K) ratio. One patient is 40 years old with a Na/K ratio of 30.5, and the other is 28 years old with a ratio of 9.6. Which of these patients is more similar to a new case you are evaluating?</p>
<p>In the kNN algorithm, classifying a new observation depends on identifying the most <em>similar</em> records in the training set. While similarity may seem intuitive, machine learning requires a precise definition. Specifically, similarity is quantified using a <em>distance metric</em>, which determines how close two observations are in a multidimensional feature space. These distances govern which records are chosen as neighbors and, ultimately, how a new observation is classified.</p>
<p>In this medical scenario, similarity is measured by comparing numerical features such as age and lab values. The smaller the computed distance between two patients, the more similar they are assumed to be, and the more influence they have on classification. Since kNN relies on the assumption that nearby points tend to share the same class label, choosing an appropriate distance metric is essential for accurate predictions.</p>
<section id="euclidean-distance" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="euclidean-distance"><span class="header-section-number">7.4.1</span> Euclidean Distance</h3>
<p>A widely used measure of similarity in kNN is <em>Euclidean distance</em>, which corresponds to the straight-line, or “as-the-crow-flies,” distance between two points. It is intuitive, easy to compute, and well-suited to numerical data with comparable scales.</p>
<p>Mathematically, the Euclidean distance between two points <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in <span class="math inline">\(n\)</span>-dimensional space is given by: <span class="math display">\[
\text{dist}(x, y) = \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \ldots + (x_n - y_n)^2},
\]</span> where <span class="math inline">\(x = (x_1, x_2, \ldots, x_n)\)</span> and <span class="math inline">\(y = (y_1, y_2, \ldots, y_n)\)</span> are the feature vectors.</p>
<p>For example, suppose we want to compute the Euclidean distance between two new patients from the previous section, using their <em>age</em> and <em>sodium-to-potassium (Na/K) ratio</em>. Patient 1 is 40 years old with a Na/K ratio of 30.5, and Patient 2 is 28 years old with a Na/K ratio of 9.6. The Euclidean distance between these two patients is visualized in <a href="#fig-ch7-euclidean-distance" class="quarto-xref">Figure&nbsp;<span>7.4</span></a> in a two-dimensional feature space, where each axis represents one of the features (age and Na/K ratio). The line connecting Patient 1 <span class="math inline">\((40, 30.5)\)</span> and Patient 2 <span class="math inline">\((28, 9.6)\)</span> represents their Euclidean distance: <span class="math display">\[
\text{dist}(x, y) = \sqrt{(40 - 28)^2 + (30.5 - 9.6)^2} = \sqrt{144 + 436.81} = 24.11
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ch7-euclidean-distance" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="H" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch7-euclidean-distance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-euclidean-distance-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch7-euclidean-distance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: Visual representation of Euclidean distance between two patients in 2D space.
</figcaption>
</figure>
</div>
</div>
</div>
<p>This value quantifies how dissimilar the patients are in the two-dimensional feature space, and it plays a key role in determining how the new patient would be classified by kNN.</p>
<p>Although other distance metrics exist, such as Manhattan distance, Hamming distance, or cosine similarity, Euclidean distance is the most commonly used in practice, especially when working with numerical features. Its geometric interpretation is intuitive and it works well when variables are measured on similar scales. In more specialized contexts, other distance metrics may be more appropriate depending on the structure of the data or the application domain. Readers interested in alternative metrics can explore resources such as the <strong>proxy</strong> package in R or consult advanced machine learning texts.</p>
<p>In the next section, we will examine how preprocessing steps like feature scaling ensure that Euclidean distance yields meaningful and balanced comparisons across features.</p>
</section>
</section>
<section id="sec-ch7-knn-prep" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="sec-ch7-knn-prep"><span class="header-section-number">7.5</span> Data Setup for kNN</h2>
<p>The performance of the kNN algorithm is highly sensitive to how the data is set up. Because kNN relies on distance calculations to assess similarity between observations, careful setup of the feature space is essential. Two key steps—encoding categorical variables and feature scaling—ensure that both categorical and numerical features are properly represented in these computations. These tasks belong to the <em>Data Setup for Modeling</em> phase introduced in Chapter <a href="6-Setup-data.html" class="quarto-xref"><span>6</span></a> (see <a href="2-Intro-data-science.html#fig-ch2_DSW" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>).</p>
<p>To make this idea concrete, imagine working with patient data that includes <em>age</em>, <em>sodium-to-potassium (Na/K) ratio</em>, <em>marital status</em>, and <em>education level</em>. While <em>age</em> and <em>Na/K ratio</em> are numeric, <em>marital status</em> and <em>education</em> are categorical. To prepare these features for a distance-based model, we must convert them into numerical form in a way that preserves their original meaning.</p>
<p>In most tabular datasets (such as the <code>churn</code> and <code>bank</code> datasets introduced earlier), features include a mix of categorical and numerical variables. A recommended approach is to first <em>encode</em> the categorical features into numeric format and then <em>scale</em> all numerical features. This sequence ensures that distance calculations occur on a unified numerical scale without introducing artificial distortions.</p>
<p>The appropriate encoding strategy depends on whether a variable is <em>binary</em>, <em>nominal</em>, or <em>ordinal</em>. These techniques were detailed in Chapter <a href="6-Setup-data.html" class="quarto-xref"><span>6</span></a>: general guidance in Section <a href="6-Setup-data.html#sec-ch6-encoding" class="quarto-xref"><span>6.7</span></a>, ordinal handling in Section <a href="6-Setup-data.html#sec-ch6-ordinal-encoding" class="quarto-xref"><span>6.8</span></a>, and one-hot encoding in Section <a href="6-Setup-data.html#sec-ch6-one-hot-encoding" class="quarto-xref"><span>6.9</span></a>.</p>
<p>Once categorical variables have been encoded, all numerical features—both original and derived—should be scaled so that they contribute fairly to similarity calculations. Even after encoding, features can differ widely in range. For example, <em>age</em> might vary from 20 to 70, while <em>income</em> could range from 20,000 to 150,000. Without proper scaling, features with larger magnitudes may dominate the distance computation, leading to biased neighbor selection.</p>
<p>Two widely used scaling methods address this issue: <em>min–max scaling</em> (introduced in Section <a href="6-Setup-data.html#sec-ch6-minmax" class="quarto-xref"><span>6.11</span></a>) and <em>z-score scaling</em> (introduced in Section <a href="6-Setup-data.html#sec-ch6-zscore" class="quarto-xref"><span>6.12</span></a>). Min–max scaling rescales values to a fixed range, typically <span class="math inline">\([0, 1]\)</span>, ensuring that all features contribute on the same numerical scale. Z-score scaling centers features at zero and scales them by their standard deviation, making it preferable when features have different units or contain outliers.</p>
<p>Min–max scaling is generally suitable when feature values are bounded and preserving relative distances is important. Z-score scaling is better when features are measured in different units or affected by outliers, as it reduces the influence of extreme values.</p>
<p>Before moving on, it is essential to apply scaling correctly, only after the dataset has been partitioned, to avoid <em>data leakage</em>. The next subsection explains this principle in detail.</p>
<section id="sec-ch7-knn-proper-scaling" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="sec-ch7-knn-proper-scaling"><span class="header-section-number">7.5.1</span> Preventing Data Leakage during Scaling</h3>
<p>Scaling should be performed <em>after</em> splitting the dataset into training and test sets. This prevents <em>data leakage</em>, a common pitfall in predictive modeling where information from the test set inadvertently influences the model during training. Specifically, parameters such as the mean, standard deviation, minimum, and maximum must be computed <em>only</em> from the training data and then applied to scale both the training and test sets.</p>
<p>The comparison in <a href="#fig-ch7-ex-proper-scaling" class="quarto-xref">Figure&nbsp;<span>7.5</span></a> visualizes the importance of applying scaling correctly. The middle panel shows proper scaling using training-derived parameters; the right panel shows the distortion caused by scaling the test data independently.</p>
<p>To illustrate, consider the drug classification task from earlier. Suppose <code>age</code> and <code>Na/K ratio</code> are the two predictors. The following code demonstrates both correct and incorrect approaches to scaling using the <code>minmax()</code> function from the <strong>liver</strong> package:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(liver)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Correct scaling: Apply train-derived parameters to test data</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>train_scaled <span class="ot">=</span> <span class="fu">minmax</span>(train_set, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"ratio"</span>))</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>test_scaled <span class="ot">=</span> <span class="fu">minmax</span>(test_set, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"ratio"</span>), </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">min =</span> <span class="fu">c</span>(<span class="fu">min</span>(train_set<span class="sc">$</span>age), <span class="fu">min</span>(train_set<span class="sc">$</span>ratio)), </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">max =</span> <span class="fu">c</span>(<span class="fu">max</span>(train_set<span class="sc">$</span>age), <span class="fu">max</span>(train_set<span class="sc">$</span>ratio))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Incorrect scaling: Apply separate scaling to test set</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>train_scaled_wrongly <span class="ot">=</span> <span class="fu">minmax</span>(train_set, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"ratio"</span>))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>test_scaled_wrongly  <span class="ot">=</span> <span class="fu">minmax</span>(test_set , <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"ratio"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-nrow="2" data-layout-align="center">
<div id="fig-ch7-ex-proper-scaling" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch7-ex-proper-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch7-ex-proper-scaling" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch7-ex-proper-scaling-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch7-ex-proper-scaling-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-ex-proper-scaling-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch7-ex-proper-scaling">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch7-ex-proper-scaling-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Without Scaling
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch7-ex-proper-scaling" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch7-ex-proper-scaling-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch7-ex-proper-scaling-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-ex-proper-scaling-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch7-ex-proper-scaling">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch7-ex-proper-scaling-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Proper Scaling
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch7-ex-proper-scaling" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch7-ex-proper-scaling-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch7-ex-proper-scaling-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-ex-proper-scaling-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch7-ex-proper-scaling">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch7-ex-proper-scaling-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Improper Scaling
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch7-ex-proper-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Visualization illustrating the difference between proper scaling and improper scaling. The left panel shows the original data without scaling. The middle panel shows the results of proper scaling. The right panel shows the results of improper scaling.
</figcaption>
</figure>
</div>
</div>
<p>Note that scaling parameters should always be derived from the training data and then applied consistently to both the training and test sets. Failing to do so can result in incompatible feature spaces, leading the kNN algorithm to identify misleading neighbors and produce unreliable predictions.</p>
<p>With similarity measurement and data preparation steps now complete, the next task is to determine an appropriate value of <span class="math inline">\(k\)</span>. The following section examines how this crucial hyperparameter influences the behavior and performance of the kNN algorithm.</p>
</section>
</section>
<section id="sec-ch7-knn-choose-k" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="sec-ch7-knn-choose-k"><span class="header-section-number">7.6</span> Choosing the Right Value of <em>k</em> in kNN</h2>
<p>Imagine you are new to a city and looking for a good coffee shop. If you ask just one person, you might get a recommendation based on their personal taste, which may differ from yours. If you ask too many people, you could be overwhelmed by conflicting opinions or suggestions that average out to a generic option. The sweet spot is asking a few individuals whose preferences align with your own. Similarly, in the kNN algorithm, selecting an appropriate number of neighbors (<span class="math inline">\(k\)</span>) requires balancing specificity and generalization.</p>
<p>The parameter <em>k</em>, which determines how many nearest neighbors are considered during classification, plays a central role in shaping model performance. There is no universally optimal value for <em>k</em>; the best choice depends on the structure of the dataset and the nature of the classification task. Selecting <em>k</em> involves navigating the trade-off between overfitting and underfitting.</p>
<p>When <em>k</em> is too small, such as <span class="math inline">\(k = 1\)</span>, the model becomes overly sensitive to individual training points. Each new observation is classified based solely on its nearest neighbor, making the model highly reactive to noise and outliers. This often leads to <em>overfitting</em>, where the model performs well on the training data but generalizes poorly to new cases. A small cluster of mislabeled examples, for instance, could disproportionately influence the results.</p>
<p>As <em>k</em> increases, the algorithm includes more neighbors in its classification decisions, smoothing the decision boundary and reducing the influence of noisy observations. However, when <em>k</em> becomes too large, the model may begin to overlook meaningful patterns, leading to <em>underfitting</em>. If <em>k</em> approaches the size of the training set, predictions may default to the majority class label.</p>
<p>To determine a suitable value of <em>k</em>, it is common to evaluate a range of options using a validation set or cross-validation. Performance metrics such as accuracy, precision, recall, and the F1-score can guide this choice. These metrics are discussed in detail in Chapter <a href="8-Model-evaluation.html" class="quarto-xref"><span>8</span></a>. For simplicity, we focus here on <em>accuracy</em> (also called the success rate), which measures the proportion of correct predictions.</p>
<p>As an example, Figure <a href="#fig-ch7-kNN-plot" class="quarto-xref"><span>7.6</span></a> presents the accuracy of the kNN classifier for <em>k</em> values ranging from 1 to 30, generated with the <code>kNN.plot()</code> function from the <strong>liver</strong> package in R. Accuracy fluctuates as <em>k</em> increases, with the best performance achieved at <span class="math inline">\(k = 5\)</span>, where the algorithm reaches its highest accuracy.</p>
<p>Choosing <em>k</em> is ultimately an empirical process informed by validation and domain knowledge. There is no universal rule, but careful experimentation helps identify a value that generalizes well for the problem at hand. A detailed case study in the following section revisits this example and walks through the complete modeling process.</p>
</section>
<section id="sec-ch7-knn-churn" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="sec-ch7-knn-churn"><span class="header-section-number">7.7</span> Case Study: Predicting Customer Churn with kNN</h2>
<p>In this case study, we apply the kNN algorithm to a practical classification problem using the <code>churn</code> dataset from the <strong>liver</strong> package in R. The goal is to predict whether a customer has churned (<code>yes</code>) or not (<code>no</code>) based on demographic information and service usage patterns. Readers unfamiliar with the dataset are encouraged to review the exploratory analysis in Section <a href="4-Exploratory-data-analysis.html#sec-ch4-EDA-churn" class="quarto-xref"><span>4.3</span></a>, which provides context and preliminary findings. We begin by inspecting the structure:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(liver)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(churn)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(churn)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">10127</span> obs. of  <span class="dv">21</span> variables<span class="sc">:</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="er">$</span> customer_ID          <span class="sc">:</span> int  <span class="dv">768805383</span> <span class="dv">818770008</span> <span class="dv">713982108</span> <span class="dv">769911858</span> <span class="dv">709106358</span> <span class="dv">713061558</span> <span class="dv">810347208</span> <span class="dv">818906208</span> <span class="dv">710930508</span> <span class="dv">719661558</span> ...</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> age                  <span class="sc">:</span> int  <span class="dv">45</span> <span class="dv">49</span> <span class="dv">51</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">44</span> <span class="dv">51</span> <span class="dv">32</span> <span class="dv">37</span> <span class="dv">48</span> ...</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> gender               <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"female"</span>,<span class="st">"male"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> ...</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education            <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">7</span> levels <span class="st">"uneducated"</span>,<span class="st">"highschool"</span>,..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">4</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">7</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">4</span> ...</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> marital              <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">4</span> levels <span class="st">"married"</span>,<span class="st">"single"</span>,..<span class="sc">:</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">2</span> ...</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income               <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">6</span> levels <span class="st">"&lt;40K"</span>,<span class="st">"40K-60K"</span>,..<span class="sc">:</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">4</span> ...</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> card_category        <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">4</span> levels <span class="st">"blue"</span>,<span class="st">"silver"</span>,..<span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> ...</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> dependent_count      <span class="sc">:</span> int  <span class="dv">3</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">4</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">4</span> <span class="dv">0</span> <span class="dv">3</span> <span class="dv">2</span> ...</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> months_on_book       <span class="sc">:</span> int  <span class="dv">39</span> <span class="dv">44</span> <span class="dv">36</span> <span class="dv">34</span> <span class="dv">21</span> <span class="dv">36</span> <span class="dv">46</span> <span class="dv">27</span> <span class="dv">36</span> <span class="dv">36</span> ...</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> relationship_count   <span class="sc">:</span> int  <span class="dv">5</span> <span class="dv">6</span> <span class="dv">4</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">6</span> <span class="dv">2</span> <span class="dv">5</span> <span class="dv">6</span> ...</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> months_inactive      <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">3</span> ...</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> contacts_count_12    <span class="sc">:</span> int  <span class="dv">3</span> <span class="dv">2</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">0</span> <span class="dv">3</span> ...</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> credit_limit         <span class="sc">:</span> num  <span class="dv">12691</span> <span class="dv">8256</span> <span class="dv">3418</span> <span class="dv">3313</span> <span class="dv">4716</span> ...</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> revolving_balance    <span class="sc">:</span> int  <span class="dv">777</span> <span class="dv">864</span> <span class="dv">0</span> <span class="dv">2517</span> <span class="dv">0</span> <span class="dv">1247</span> <span class="dv">2264</span> <span class="dv">1396</span> <span class="dv">2517</span> <span class="dv">1677</span> ...</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> available_credit     <span class="sc">:</span> num  <span class="dv">11914</span> <span class="dv">7392</span> <span class="dv">3418</span> <span class="dv">796</span> <span class="dv">4716</span> ...</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> transaction_amount_12<span class="sc">:</span> int  <span class="dv">1144</span> <span class="dv">1291</span> <span class="dv">1887</span> <span class="dv">1171</span> <span class="dv">816</span> <span class="dv">1088</span> <span class="dv">1330</span> <span class="dv">1538</span> <span class="dv">1350</span> <span class="dv">1441</span> ...</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> transaction_count_12 <span class="sc">:</span> int  <span class="dv">42</span> <span class="dv">33</span> <span class="dv">20</span> <span class="dv">20</span> <span class="dv">28</span> <span class="dv">24</span> <span class="dv">31</span> <span class="dv">36</span> <span class="dv">24</span> <span class="dv">32</span> ...</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> ratio_amount_Q4_Q1   <span class="sc">:</span> num  <span class="fl">1.33</span> <span class="fl">1.54</span> <span class="fl">2.59</span> <span class="fl">1.41</span> <span class="fl">2.17</span> ...</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> ratio_count_Q4_Q1    <span class="sc">:</span> num  <span class="fl">1.62</span> <span class="fl">3.71</span> <span class="fl">2.33</span> <span class="fl">2.33</span> <span class="fl">2.5</span> ...</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> utilization_ratio    <span class="sc">:</span> num  <span class="fl">0.061</span> <span class="fl">0.105</span> <span class="dv">0</span> <span class="fl">0.76</span> <span class="dv">0</span> <span class="fl">0.311</span> <span class="fl">0.066</span> <span class="fl">0.048</span> <span class="fl">0.113</span> <span class="fl">0.144</span> ...</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> churn                <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset is a data frame containing 10127 observations and 20 predictor variables, together with the binary outcome variable <code>churn</code>. Consistent with the earlier analysis in Chapter <a href="4-Exploratory-data-analysis.html" class="quarto-xref"><span>4</span></a>, we exclude <code>customer_ID</code>, which is an identifier, and we remove predictors that are deterministic functions of other credit variables (<code>available_credit</code> and <code>utilization_ratio</code>). Excluding such variables reduces redundancy and helps ensure that distance calculations are not dominated by multiple representations of the same information.</p>
<p>Before proceeding to Step 4 (Data Setup for Modeling) in Chapter <a href="6-Setup-data.html" class="quarto-xref"><span>6</span></a>, we prepare the dataset for modeling. To avoid data leakage (see Section <a href="6-Setup-data.html#sec-ch6-data-leakage" class="quarto-xref"><span>6.6</span></a>), preprocessing steps that depend on the data distribution, including imputation and scaling, will be applied after partitioning the dataset into training and test sets. We also ensure that the outcome is coded as a factor with levels <code>no</code> and <code>yes</code>, which is required by several modeling and evaluation functions.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure outcome coding is consistent</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>churn<span class="sc">$</span>churn <span class="ot">&lt;-</span> <span class="fu">factor</span>(churn<span class="sc">$</span>churn, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"no"</span>, <span class="st">"yes"</span>))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop any unused levels</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>churn <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(churn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the remainder of this case study, we proceed step by step: partitioning the data, applying preprocessing after the split to avoid leakage, selecting an appropriate value of <span class="math inline">\(k\)</span>, fitting the model, generating predictions, and evaluating performance. Because kNN is distance-based, each step in data setup directly affects how similarity is measured and, therefore, how predictions are formed.</p>
<section id="data-setup-for-knn" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="data-setup-for-knn"><span class="header-section-number">7.7.1</span> Data Setup for kNN</h3>
<p>To evaluate how well the kNN model generalizes to new observations, we begin by splitting the dataset into training and test sets. This separation provides an unbiased estimate of predictive performance by assessing the model on data not used during training.</p>
<p>We use the <code>partition()</code> function from the <strong>liver</strong> package to divide the data into an 80% training set and a 20% test set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data_sets <span class="ot">=</span> <span class="fu">partition</span>(<span class="at">data =</span> churn, <span class="at">ratio =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.2</span>), <span class="at">set.seed =</span> <span class="dv">42</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>train_set <span class="ot">=</span> data_sets<span class="sc">$</span>part1</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>test_set  <span class="ot">=</span> data_sets<span class="sc">$</span>part2</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>test_labels <span class="ot">=</span> test_set<span class="sc">$</span>churn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>partition()</code> function performs a random split while preserving the class distribution of the target variable. Readers may verify that the churn rate is similar across both sets (see Section <a href="6-Setup-data.html#sec-ch6-validate-partition" class="quarto-xref"><span>6.4</span></a>).</p>
<p>Preprocessing steps such as imputation depend on the data distribution, so they should be applied after partitioning to reduce the risk of data leakage (see Section <a href="6-Setup-data.html#sec-ch6-data-leakage" class="quarto-xref"><span>6.6</span></a>). In this case study, we apply the same random imputation strategy separately within each subset after splitting.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Treat "unknown" as missing</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>train_set[train_set <span class="sc">==</span> <span class="st">"unknown"</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>test_set[test_set <span class="sc">==</span> <span class="st">"unknown"</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Random imputation (applied separately within each set)</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>train_set<span class="sc">$</span>education <span class="ot">&lt;-</span> <span class="fu">impute</span>(train_set<span class="sc">$</span>education, <span class="st">"random"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>train_set<span class="sc">$</span>income    <span class="ot">&lt;-</span> <span class="fu">impute</span>(train_set<span class="sc">$</span>income, <span class="st">"random"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>train_set<span class="sc">$</span>marital   <span class="ot">&lt;-</span> <span class="fu">impute</span>(train_set<span class="sc">$</span>marital, <span class="st">"random"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>test_set<span class="sc">$</span>education <span class="ot">&lt;-</span> <span class="fu">impute</span>(test_set<span class="sc">$</span>education, <span class="st">"random"</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>test_set<span class="sc">$</span>income    <span class="ot">&lt;-</span> <span class="fu">impute</span>(test_set<span class="sc">$</span>income, <span class="st">"random"</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>test_set<span class="sc">$</span>marital   <span class="ot">&lt;-</span> <span class="fu">impute</span>(test_set<span class="sc">$</span>marital, <span class="st">"random"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>train_set <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(train_set)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>test_set  <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(test_set)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p><em>Practice:</em> Repartition the <code>churn</code> dataset into a 70% training set and a 30% test set. Apply the same imputation strategy to each subset after splitting and verify that the class distribution of <code>churn</code> is preserved across both sets.</p>
</blockquote>
<section id="encoding-categorical-features-for-knn" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="encoding-categorical-features-for-knn">Encoding Categorical Features for kNN</h4>
<p>Because the kNN algorithm relies on distance calculations between observations, all input features must be numeric. Therefore, categorical variables need to be transformed into numerical representations. In the <code>churn</code> dataset, the variables <code>gender</code>, <code>education</code>, <code>marital</code>, <code>income</code>, and <code>card_category</code> are categorical and require encoding. The <code>one.hot()</code> function from the <strong>liver</strong> package automates this step by generating binary indicator variables:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"gender"</span>, <span class="st">"education"</span>, <span class="st">"marital"</span>, <span class="st">"income"</span>, <span class="st">"card_category"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>train_onehot <span class="ot">=</span> <span class="fu">one.hot</span>(train_set, <span class="at">cols =</span> categorical_features)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>test_onehot  <span class="ot">=</span> <span class="fu">one.hot</span>(test_set,  <span class="at">cols =</span> categorical_features)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(test_onehot)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">2025</span> obs. of  <span class="dv">41</span> variables<span class="sc">:</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="er">$</span> customer_ID            <span class="sc">:</span> int  <span class="dv">713061558</span> <span class="dv">816082233</span> <span class="dv">709327383</span> <span class="dv">806165208</span> <span class="dv">804424383</span> <span class="dv">709029408</span> <span class="dv">788658483</span> <span class="dv">715318008</span> <span class="dv">827111283</span> <span class="dv">720572508</span> ...</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> age                    <span class="sc">:</span> int  <span class="dv">44</span> <span class="dv">35</span> <span class="dv">45</span> <span class="dv">47</span> <span class="dv">63</span> <span class="dv">41</span> <span class="dv">53</span> <span class="dv">55</span> <span class="dv">45</span> <span class="dv">38</span> ...</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> gender                 <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"female"</span>,<span class="st">"male"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> ...</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> gender_female          <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> ...</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> gender_male            <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> ...</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education              <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">6</span> levels <span class="st">"uneducated"</span>,<span class="st">"highschool"</span>,..<span class="sc">:</span> <span class="dv">4</span> <span class="dv">4</span> <span class="dv">4</span> <span class="dv">6</span> <span class="dv">2</span> <span class="dv">4</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">4</span> <span class="dv">4</span> ...</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education_uneducated   <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education_highschool   <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education_college      <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education_graduate     <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> ...</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education_post<span class="sc">-</span>graduate<span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> education_doctorate    <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> marital                <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">3</span> levels <span class="st">"married"</span>,<span class="st">"single"</span>,..<span class="sc">:</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> ...</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> marital_married        <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> marital_single         <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> ...</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> marital_divorced       <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income                 <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">5</span> levels <span class="st">"&lt;40K"</span>,<span class="st">"40K-60K"</span>,..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">5</span> ...</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income_<span class="sc">&lt;</span><span class="dv">40</span>K            <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income_40K<span class="dv">-60</span>K         <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income_60K<span class="dv">-80</span>K         <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income_80K<span class="dv">-120</span>K        <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> ...</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> income_<span class="sc">&gt;</span><span class="dv">120</span>K           <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> ...</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> card_category          <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">4</span> levels <span class="st">"blue"</span>,<span class="st">"silver"</span>,..<span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> ...</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> card_category_blue     <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> ...</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> card_category_silver   <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> card_category_gold     <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> card_category_platinum <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> dependent_count        <span class="sc">:</span> int  <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">4</span> ...</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> months_on_book         <span class="sc">:</span> int  <span class="dv">36</span> <span class="dv">30</span> <span class="dv">37</span> <span class="dv">42</span> <span class="dv">56</span> <span class="dv">36</span> <span class="dv">38</span> <span class="dv">36</span> <span class="dv">41</span> <span class="dv">28</span> ...</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> relationship_count     <span class="sc">:</span> int  <span class="dv">3</span> <span class="dv">5</span> <span class="dv">6</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">4</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">2</span> ...</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> months_inactive        <span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">3</span> ...</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> contacts_count_12      <span class="sc">:</span> int  <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">0</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">3</span> ...</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> credit_limit           <span class="sc">:</span> num  <span class="dv">4010</span> <span class="dv">8547</span> <span class="dv">14470</span> <span class="dv">20979</span> <span class="dv">10215</span> ...</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> revolving_balance      <span class="sc">:</span> int  <span class="dv">1247</span> <span class="dv">1666</span> <span class="dv">1157</span> <span class="dv">1800</span> <span class="dv">1010</span> <span class="dv">2517</span> <span class="dv">1490</span> <span class="dv">1914</span> <span class="dv">578</span> <span class="dv">2055</span> ...</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> available_credit       <span class="sc">:</span> num  <span class="dv">2763</span> <span class="dv">6881</span> <span class="dv">13313</span> <span class="dv">19179</span> <span class="dv">9205</span> ...</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> transaction_amount_12  <span class="sc">:</span> int  <span class="dv">1088</span> <span class="dv">1311</span> <span class="dv">1207</span> <span class="dv">1178</span> <span class="dv">1904</span> <span class="dv">1589</span> <span class="dv">1411</span> <span class="dv">1407</span> <span class="dv">1109</span> <span class="dv">1042</span> ...</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> transaction_count_12   <span class="sc">:</span> int  <span class="dv">24</span> <span class="dv">33</span> <span class="dv">21</span> <span class="dv">27</span> <span class="dv">40</span> <span class="dv">24</span> <span class="dv">28</span> <span class="dv">43</span> <span class="dv">28</span> <span class="dv">23</span> ...</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> ratio_amount_Q4_Q1     <span class="sc">:</span> num  <span class="fl">1.376</span> <span class="fl">1.163</span> <span class="fl">0.966</span> <span class="fl">0.906</span> <span class="fl">0.843</span> ...</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> ratio_count_Q4_Q1      <span class="sc">:</span> num  <span class="fl">0.846</span> <span class="dv">2</span> <span class="fl">0.909</span> <span class="fl">0.929</span> <span class="dv">1</span> ...</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> utilization_ratio      <span class="sc">:</span> num  <span class="fl">0.311</span> <span class="fl">0.195</span> <span class="fl">0.08</span> <span class="fl">0.086</span> <span class="fl">0.099</span> <span class="fl">0.282</span> <span class="fl">0.562</span> <span class="fl">0.544</span> <span class="fl">0.018</span> <span class="fl">0.209</span> ...</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> churn                  <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"no"</span>,<span class="st">"yes"</span><span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For each categorical variable with <span class="math inline">\(m\)</span> categories, the function creates <span class="math inline">\(m\)</span> binary columns (dummy variables). In practice, it is often preferable to use <span class="math inline">\(m - 1\)</span> dummy variables to avoid redundancy and multicollinearity, while maintaining interpretability and compatibility with distance-based algorithms.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> After applying <code>one.hot()</code> to the training data, inspect the structure of <code>train_onehot</code>. Which categorical variables generate the largest number of binary indicators? How could this influence similarity calculations in kNN?</p>
</blockquote>
<blockquote class="blockquote">
<p><em>Practice:</em> Using a 70%–30% train–test split, apply one-hot encoding to the categorical variables in both sets. Check whether the resulting encoded datasets have the same set of predictor variables. Why is this consistency important for distance-based methods such as kNN?</p>
</blockquote>
</section>
<section id="feature-scaling-for-knn" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="feature-scaling-for-knn">Feature Scaling for kNN</h4>
<p>To ensure that all numerical variables contribute equally to distance calculations, we apply <em>min–max scaling</em>. This technique rescales each variable to the <span class="math inline">\([0, 1]\)</span> range based on the minimum and maximum values computed from the training set. The same scaling parameters are then applied to the test set to prevent data leakage:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"dependent_count"</span>, <span class="st">"months_on_book"</span>, <span class="st">"relationship_count"</span>, <span class="st">"months_inactive"</span>, <span class="st">"contacts_count_12"</span>, <span class="st">"credit_limit"</span>, <span class="st">"revolving_balance"</span>, <span class="st">"transaction_amount_12"</span>, <span class="st">"transaction_count_12"</span>, <span class="st">"ratio_amount_Q4_Q1"</span>, <span class="st">"ratio_count_Q4_Q1"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Column-wise minimums</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>min_train <span class="ot">=</span> <span class="fu">sapply</span>(train_set[, numeric_features], min)  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Column-wise maximums</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>max_train <span class="ot">=</span> <span class="fu">sapply</span>(train_set[, numeric_features], max)   </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>train_scaled <span class="ot">=</span> <span class="fu">minmax</span>(train_onehot, <span class="at">col =</span> numeric_features, <span class="at">min =</span> min_train, <span class="at">max =</span> max_train)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>test_scaled  <span class="ot">=</span> <span class="fu">minmax</span>(test_onehot,  <span class="at">col =</span> numeric_features, <span class="at">min =</span> min_train, <span class="at">max =</span> max_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, <code>sapply()</code> computes the column-wise minimum and maximum values across the selected numeric variables in the training set. These values define the scaling range. The <code>minmax()</code> function from the <strong>liver</strong> package then applies min–max scaling to both the training and test sets, using the training-set values as reference.</p>
<p>This step places all variables on a comparable scale, ensuring that those with larger ranges do not dominate the distance calculations. For further discussion of scaling methods and their implications, see Section <a href="6-Setup-data.html#sec-ch6-feature-scaling" class="quarto-xref"><span>6.10</span></a> and the preparation overview in Section <a href="#sec-ch7-knn-prep" class="quarto-xref"><span>7.5</span></a>. With the data now encoded and scaled, we can proceed to determine the optimal number of neighbors (<span class="math inline">\(k\)</span>) for the kNN model.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> After creating a 70%–30% train–test split, verify that the minimum and maximum values used for scaling are computed only from the training data. What could go wrong if the test set were scaled independently?</p>
</blockquote>
</section>
</section>
<section id="finding-the-best-value-for-k" class="level3" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="finding-the-best-value-for-k"><span class="header-section-number">7.7.2</span> Finding the Best Value for <span class="math inline">\(k\)</span></h3>
<p>The number of neighbors (<span class="math inline">\(k\)</span>) is a key hyperparameter in the kNN algorithm. Choosing a very small <span class="math inline">\(k\)</span> can make the model overly sensitive to noise, whereas a very large <span class="math inline">\(k\)</span> can oversmooth decision boundaries and obscure meaningful local patterns.</p>
<p>In R, there are several ways to identify the optimal value of <span class="math inline">\(k\)</span>. A common approach is to assess model accuracy across a range of values (for example, from 1 to 30) and select the <span class="math inline">\(k\)</span> that yields the highest performance. This can be implemented manually with a <code>for</code> loop that records the accuracy for each value of <span class="math inline">\(k\)</span>.</p>
<p>The <strong>liver</strong> package simplifies this process with the <code>kNN.plot()</code> function, which automatically computes accuracy across a specified range of <span class="math inline">\(k\)</span> values and visualizes the results. This enables quick identification of the best-performing model.</p>
<p>Before running the function, we define a <code>formula</code> object that specifies the relationship between the target variable (<code>churn</code>) and the predictor variables. The predictors include all scaled numeric variables and the binary indicators generated through one-hot encoding, such as <code>gender_female</code>, <code>education_uneducated</code>, and others:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>formula <span class="ot">=</span> churn <span class="sc">~</span> gender_female <span class="sc">+</span> age <span class="sc">+</span> education_uneducated  <span class="sc">+</span> education_highschool <span class="sc">+</span> education_college  <span class="sc">+</span> education_graduate <span class="sc">+</span> <span class="st">`</span><span class="at">education_post-graduate</span><span class="st">`</span> <span class="sc">+</span> marital_married <span class="sc">+</span> marital_single <span class="sc">+</span> <span class="st">`</span><span class="at">income_&lt;40K</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">income_40K-60K</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">income_60K-80K</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">income_80K-120K</span><span class="st">`</span> <span class="sc">+</span> card_category_blue <span class="sc">+</span> card_category_silver <span class="sc">+</span> card_category_gold <span class="sc">+</span> dependent_count <span class="sc">+</span> months_on_book <span class="sc">+</span> relationship_count <span class="sc">+</span> months_inactive <span class="sc">+</span> contacts_count_12 <span class="sc">+</span> credit_limit <span class="sc">+</span> revolving_balance <span class="sc">+</span> transaction_amount_12 <span class="sc">+</span> transaction_count_12 <span class="sc">+</span> ratio_amount_Q4_Q1 <span class="sc">+</span> ratio_count_Q4_Q1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now apply the <code>kNN.plot()</code> function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">kNN.plot</span>(<span class="at">formula =</span> formula, </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">train =</span> train_scaled, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">test =</span> test_scaled, </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">k.max =</span> <span class="dv">20</span>, </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">reference =</span> <span class="st">"yes"</span>, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">set.seed =</span> <span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-ch7-kNN-plot" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="H" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch7-kNN-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="7-Classification-kNN_files/figure-html/fig-ch7-kNN-plot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch7-kNN-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.6: Accuracy of the kNN algorithm on the churn dataset for values of k ranging from 1 to 20.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The arguments in <code>kNN.plot()</code> control various aspects of the evaluation. The <code>train</code> and <code>test</code> inputs specify the scaled datasets, ensuring comparable feature scales for distance computation. The argument <code>k.max = 20</code> defines the largest number of neighbors to test, allowing us to visualize model performance over a meaningful range. Setting <code>reference = "yes"</code> designates the <code>"yes"</code> class as the positive outcome (customer churn), and <code>set.seed = 42</code> ensures reproducibility.</p>
<p>The resulting plot shows how model accuracy changes with <span class="math inline">\(k\)</span>. In this case, accuracy peaks at <span class="math inline">\(k = 5\)</span>, suggesting that this value strikes a good balance between capturing local patterns and maintaining generalization. With the optimal <span class="math inline">\(k\)</span> determined, we can now apply the kNN model to classify new customer records in the test set.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Using a 70%–30% train–test split, apply <code>kNN.plot()</code> to select an appropriate value of <span class="math inline">\(k\)</span>. Compare the resulting accuracy curve with the one obtained using the 80%–20% split. Does the value of <span class="math inline">\(k\)</span> that maximizes accuracy remain the same? What does this tell you about the stability of hyperparameter tuning in kNN?</p>
</blockquote>
</section>
<section id="applying-the-knn-classifier" class="level3" data-number="7.7.3">
<h3 data-number="7.7.3" class="anchored" data-anchor-id="applying-the-knn-classifier"><span class="header-section-number">7.7.3</span> Applying the kNN Classifier</h3>
<p>With the optimal value <span class="math inline">\(k = 5\)</span> identified, we now apply the kNN algorithm to classify customer churn in the test set. This step brings together the work from the previous sections—data preparation, feature encoding, scaling, and hyperparameter tuning. Unlike many machine learning algorithms, kNN does not build an explicit predictive model during training. Instead, it retains the training data and performs classification <em>on demand</em> by computing distances to identify the closest training observations.</p>
<p>In R, we use the <code>kNN()</code> function from the <strong>liver</strong> package to implement the k-Nearest Neighbors algorithm. This function provides a formula-based interface consistent with other modeling functions in R, making the syntax more readable and the workflow more transparent. An alternative is the <code>knn()</code> function from the class package, which requires specifying input matrices and class labels manually. While effective, this approach is less intuitive for beginners and is not used in this book:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>kNN_predict <span class="ot">=</span> <span class="fu">kNN</span>(<span class="at">formula =</span> formula, </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">train =</span> train_scaled, </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">test =</span> test_scaled, </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">k =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this command, <code>formula</code> defines the relationship between the response variable (<code>churn</code>) and the predictors. The <code>train</code> and <code>test</code> arguments specify the scaled datasets prepared in earlier steps. The parameter <code>k = 5</code> sets the number of nearest neighbors, as determined in the tuning step. The <code>kNN()</code> function classifies each test observation by computing its distance to all training records and assigning the majority class among the <em>five</em> nearest neighbors.</p>
</section>
<section id="evaluating-model-performance-of-the-knn-model" class="level3" data-number="7.7.4">
<h3 data-number="7.7.4" class="anchored" data-anchor-id="evaluating-model-performance-of-the-knn-model"><span class="header-section-number">7.7.4</span> Evaluating Model Performance of the kNN Model</h3>
<p>With predictions in hand, the final step is to assess how well the kNN model performs. A fundamental and intuitive evaluation tool is the confusion matrix, which summarizes the correspondence between predicted and actual class labels in the test set. We use the <code>conf.mat.plot()</code> function from the <strong>liver</strong> package to compute and visualize this matrix. The argument <code>reference = "yes"</code> specifies that the positive class refers to customers who have churned:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">conf.mat.plot</span>(kNN_predict, test_labels, <span class="at">reference =</span> <span class="st">"yes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="7-Classification-kNN_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:30.0%" data-fig-pos="H"></p>
</figure>
</div>
</div>
</div>
<p>conf_max_knn_churn = conf.mat(kNN_predict, test_labels, reference = “yes”)</p>
<p>The resulting matrix displays the number of true positives, true negatives, false positives, and false negatives. In this example, the model correctly classified 1765 observations and misclassified 260.</p>
<p>While the confusion matrix provides a useful snapshot of model performance, it does not capture all aspects of classification quality. In Chapter <a href="8-Model-evaluation.html" class="quarto-xref"><span>8</span></a>, we introduce additional evaluation metrics, including accuracy, precision, recall, and F1-score, that offer a more nuanced assessment.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Using a 70%–30% train–test split, fit a kNN model by following the same workflow as in this subsection and compute the corresponding confusion matrix. Compare it with the confusion matrix obtained using the 80%–20% split. Which types of errors change, and what does this tell you about the stability of model evaluation?</p>
</blockquote>
<p>This case study has demonstrated the complete kNN modeling workflow, from data setup and preprocessing to hyperparameter tuning and evaluation. It provides a concrete foundation for the broader discussion of model assessment and comparison in the next chapter.</p>
</section>
</section>
<section id="chapter-summary-and-takeaways" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="chapter-summary-and-takeaways"><span class="header-section-number">7.8</span> Chapter Summary and Takeaways</h2>
<p>This chapter introduced the k-Nearest Neighbors (kNN) algorithm as an intuitive and accessible approach to classification. We revisited the role of classification in supervised learning and examined how kNN assigns class labels by comparing new observations to nearby points in the feature space.</p>
<p>A central theme of the chapter was the importance of data preparation for distance-based methods. We showed how encoding categorical variables and scaling numerical features are essential for meaningful distance calculations. We also discussed how the choice of the number of neighbors (<span class="math inline">\(k\)</span> affects model behavior, highlighting the trade-off between sensitivity to local patterns and robustness to noise. These ideas were illustrated through a complete case study using the <code>churn</code> dataset from the <strong>liver</strong> package, which demonstrated the full modeling workflow from data setup to evaluation.</p>
<p>The simplicity and transparency of kNN make it a valuable baseline model and a useful starting point for classification tasks. At the same time, the chapter highlighted key limitations of the method, including sensitivity to noise and irrelevant features, dependence on careful preprocessing, and increasing computational cost as the dataset grows. These limitations help explain why kNN is often used as a reference model rather than a final solution in large-scale applications.</p>
<p>Although our focus has been on classification, the kNN framework extends naturally to other tasks. In kNN regression, predictions for numeric outcomes are obtained by averaging the responses of nearby observations. kNN can also be used for imputing missing values by borrowing information from similar cases. Both extensions rely on the same notion of similarity that underpins kNN classification.</p>
<p>In the chapters that follow, we turn to more advanced classification methods, beginning with Naive Bayes (Chapter <a href="9-Naive-Bayes.html" class="quarto-xref"><span>9</span></a>), followed by Logistic Regression (Chapter <a href="10-Regression.html" class="quarto-xref"><span>10</span></a>) and Decision Trees (Chapter <a href="11-Tree-based-models.html" class="quarto-xref"><span>11</span></a>). These models address many of the practical limitations encountered with kNN and provide more scalable and flexible tools for real-world predictive modeling.</p>
</section>
<section id="sec-ch7-exercises" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="sec-ch7-exercises"><span class="header-section-number">7.9</span> Exercises</h2>
<p>The following exercises reinforce key ideas introduced in this chapter. Begin with conceptual questions to test your understanding, continue with hands-on modeling tasks using the <code>bank</code> dataset, and conclude with reflective prompts and real-world considerations for applying kNN.</p>
<section id="conceptual-questions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="conceptual-questions">Conceptual Questions</h4>
<ol type="1">
<li><p>Explain the fundamental difference between classification and regression. Provide an example of each.</p></li>
<li><p>What are the key steps in applying the kNN algorithm?</p></li>
<li><p>Why is the choice of <span class="math inline">\(k\)</span> important in kNN, and what happens when <span class="math inline">\(k\)</span> is too small or too large?</p></li>
<li><p>Describe the role of distance metrics in kNN classification. Why is Euclidean distance commonly used?</p></li>
<li><p>What are the limitations of kNN compared to other classification algorithms?</p></li>
<li><p>How does feature scaling impact the performance of kNN? Why is it necessary?</p></li>
<li><p>How is one-hot encoding used in kNN, and why is it necessary for categorical variables?</p></li>
<li><p>How does kNN handle missing values? What strategies can be used to deal with missing data?</p></li>
<li><p>Explain the difference between <em>lazy learning</em> (such as kNN) and <em>eager learning</em> (such as decision trees or logistic regression). Give one advantage of each.</p></li>
<li><p>Why is kNN considered a non-parametric algorithm? What advantages and disadvantages does this bring?</p></li>
</ol>
</section>
<section id="hands-on-practice-applying-knn-to-the-bank-dataset" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="hands-on-practice-applying-knn-to-the-bank-dataset">Hands-On Practice: Applying kNN to the <code>bank</code> Dataset</h4>
<p>The following tasks apply the kNN algorithm to the <code>bank</code> dataset from the <strong>liver</strong> package. This dataset includes customer demographics and banking history, with the goal of predicting whether a customer subscribed to a term deposit. These exercises follow the same modeling steps as the churn case study and offer opportunities to deepen your practical understanding.</p>
<section id="data-exploration-and-preparation" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="data-exploration-and-preparation">Data Exploration and Preparation</h5>
<ol start="11" type="1">
<li><p>Load the <code>bank</code> dataset and display its structure. Identify the target variable and the predictor variables.</p></li>
<li><p>Perform an initial EDA:</p>
<ul>
<li>What are the distributions of key numeric variables like <code>age</code>, <code>balance</code>, and <code>duration</code>?</li>
<li>Are there any unusually high or low values that might influence distance calculations in kNN?</li>
</ul></li>
<li><p>Explore potential associations:</p>
<ul>
<li>Are there noticeable differences in numeric features (e.g., <code>balance</code>, <code>duration</code>) between customers who subscribed to a deposit versus those who did not?</li>
<li>Are there categorical features (e.g., <code>job</code>, <code>marital</code>) that seem associated with the outcome?</li>
</ul></li>
<li><p>Count the number of instances where a customer subscribed to a term deposit (<em>deposit = “yes”</em>) versus those who did not (<em>deposit = “no”</em>). What does this tell you about class imbalance?</p></li>
<li><p>Identify nominal variables in the dataset. Apply one-hot encoding using the <code>one.hot()</code> function. Retain only one dummy variable per categorical feature to avoid redundancy and multicollinearity.</p></li>
<li><p>Partition the dataset into 80% training and 20% testing sets using the <code>partition()</code> function. Ensure the target variable remains proportionally distributed in both sets.</p></li>
<li><p>Validate the partitioning by comparing the class distribution of the target variable in the training and test sets.</p></li>
<li><p>Apply min-max scaling to numerical variables in both training and test sets. Ensure that the scaling parameters are derived from the training set only.</p></li>
</ol>
</section>
<section id="diagnosing-the-impact-of-preprocessing" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="diagnosing-the-impact-of-preprocessing">Diagnosing the Impact of Preprocessing</h5>
<ol start="19" type="1">
<li><p>What happens if you skip feature scaling before applying kNN? Train a model without scaling and compare its accuracy to the scaled version.</p></li>
<li><p>What happens if you leave categorical variables as strings without applying one-hot encoding? Does the model return an error, or does performance decline? Explain why.</p></li>
</ol>
</section>
<section id="choosing-the-optimal-k" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="choosing-the-optimal-k">Choosing the Optimal k</h5>
<ol start="21" type="1">
<li><p>Use the <code>kNN.plot()</code> function to determine the optimal <span class="math inline">\(k\)</span> value for classifying <code>deposit</code> in the <code>bank</code> dataset.</p></li>
<li><p>What is the best <span class="math inline">\(k\)</span> value based on accuracy? How does accuracy change as <span class="math inline">\(k\)</span> increases?</p></li>
<li><p>Interpret the meaning of the accuracy curve generated by <code>kNN.plot()</code>. What patterns do you observe?</p></li>
</ol>
</section>
<section id="building-and-evaluating-the-knn-model" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="building-and-evaluating-the-knn-model">Building and Evaluating the kNN Model</h5>
<ol start="24" type="1">
<li><p>Train a kNN model using the optimal <span class="math inline">\(k\)</span> and make predictions on the test set.</p></li>
<li><p>Generate a confusion matrix for the kNN model predictions using the <code>conf.mat()</code> function. Interpret the results.</p></li>
<li><p>Calculate the accuracy of the kNN model. How well does it perform in predicting <em>deposit</em>?</p></li>
<li><p>Compare the performance of kNN with different values of <span class="math inline">\(k\)</span> (e.g., <span class="math inline">\(k = 1, 5, 15, 25\)</span>). How does changing <span class="math inline">\(k\)</span> affect the classification results?</p></li>
<li><p>Train a kNN model using only a subset of features: <code>age</code>, <code>balance</code>, <code>duration</code>, and <code>campaign</code>. Compare its accuracy with the full-feature model. What does this tell you about feature selection?</p></li>
<li><p>Compare the accuracy of kNN when using min-max scaling versus z-score standardization. How does the choice of scaling method impact model performance?</p></li>
</ol>
</section>
</section>
<section id="critical-thinking-and-real-world-applications" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="critical-thinking-and-real-world-applications">Critical Thinking and Real-World Applications</h4>
<ol start="30" type="1">
<li><p>Suppose you are building a fraud detection system for a bank. Would kNN be a suitable algorithm? What are its advantages and limitations in this context?</p></li>
<li><p>How would you handle imbalanced classes in the <code>bank</code> dataset? What strategies could improve classification performance?</p></li>
<li><p>In a high-dimensional dataset with hundreds of features, would kNN still be an effective approach? Why or why not?</p></li>
<li><p>Imagine you are working with a dataset where new observations are collected continuously. What challenges would kNN face, and how could they be addressed?</p></li>
<li><p>If a financial institution wants to classify customers into different risk categories for loan approval, what preprocessing steps would be essential before applying kNN?</p></li>
<li><p>In a dataset where some features are irrelevant or redundant, how could you improve kNN’s performance? What feature selection methods would you use?</p></li>
<li><p>If computation time is a concern, what strategies could you apply to make kNN more efficient for large datasets?</p></li>
<li><p>Suppose kNN is performing poorly on the <code>bank</code> dataset. What possible reasons could explain this, and how would you troubleshoot the issue?</p></li>
</ol>
</section>
<section id="self-reflection" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="self-reflection">Self-Reflection</h4>
<ol start="38" type="1">
<li><p>What did you find most intuitive about the kNN algorithm? What aspects required more effort to understand?</p></li>
<li><p>How did the visualizations (e.g., scatter plots, accuracy curves, and confusion matrices) help you understand the behavior of the model?</p></li>
<li><p>If you were to explain how kNN works to a colleague or friend, how would you describe it in your own words?</p></li>
<li><p>How would you decide whether kNN is a good choice for a new dataset or project you are working on?</p></li>
<li><p>Which data preprocessing steps, such as encoding or scaling, felt most important in improving kNN’s performance?</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/book-data-science-r\.netlify\.app");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./6-Setup-data.html" class="pagination-link" aria-label="Data Setup for Modeling">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Setup for Modeling</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./8-Model-evaluation.html" class="pagination-link" aria-label="Model Evaluation and Performance Assessment">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Model Evaluation and Performance Assessment</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Data Science Foundations and Machine Learning with R was written by <a href="https://www.uva.nl/profile/a.mohammadi"><span style="color:#0056B3">Reza Mohammadi</span></a>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/edit/main/7-Classification-kNN.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>