<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Reza Mohammadi">

<title>10&nbsp; Regression Analysis: Foundations and Applications – &lt;span style='color:#0056B3'&gt;Data Science Foundations and Machine Learning with R: From Data to Decisions&lt;/span&gt;</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./11-Tree-based-models.html" rel="next">
<link href="./9-Naive-Bayes.html" rel="prev">
<link href="./images/logo.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5c395c020fa0215c66c8d962dcba7617.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-Regression.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regression Analysis: Foundations and Applications</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"><span style="color:#0056B3">Data Science Foundations and Machine Learning with R: From Data to Decisions</span></a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/RezaMoammadi/Book-Data-Science-R" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./-span-style=-color--0056B3--Data-Science-Foundations-and-Machine-Learning-with-R--From-Data-to-Decisions--span-.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./-span-style=-color--0056B3--Data-Science-Foundations-and-Machine-Learning-with-R--From-Data-to-Decisions--span-.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-Intro-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">R Foundations for Data Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-Intro-data-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Data Science Workflow and the Role of Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-Data-preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Preparation in Practice: From Raw Data to Insight</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-Exploratory-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Exploratory Data Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-Statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Statistical Inference and Hypothesis Testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6-Setup-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Setup for Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7-Classification-kNN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification Using k-Nearest Neighbors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8-Model-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Model Evaluation and Performance Assessment</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9-Naive-Bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Naive Bayes Classifier</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-Regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regression Analysis: Foundations and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-Tree-based-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Decision Trees and Random Forests</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-Neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Neural Networks: Foundations of Artificial Intelligence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Clustering for Insight: Segmenting Data Without Labels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-References.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-this-chapter-covers" id="toc-what-this-chapter-covers" class="nav-link active" data-scroll-target="#what-this-chapter-covers">What This Chapter Covers</a></li>
  <li><a href="#sec-simple-regression" id="toc-sec-simple-regression" class="nav-link" data-scroll-target="#sec-simple-regression"><span class="header-section-number">10.1</span> Simple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#fitting-a-simple-linear-regression-model" id="toc-fitting-a-simple-linear-regression-model" class="nav-link" data-scroll-target="#fitting-a-simple-linear-regression-model">Fitting a Simple Linear Regression Model</a></li>
  <li><a href="#fitting-the-simple-regression-model-in-r" id="toc-fitting-the-simple-regression-model-in-r" class="nav-link" data-scroll-target="#fitting-the-simple-regression-model-in-r">Fitting the Simple Regression Model in R</a></li>
  <li><a href="#making-predictions-with-the-regression-line" id="toc-making-predictions-with-the-regression-line" class="nav-link" data-scroll-target="#making-predictions-with-the-regression-line">Making Predictions with the Regression Line</a></li>
  <li><a href="#residuals-and-model-fit" id="toc-residuals-and-model-fit" class="nav-link" data-scroll-target="#residuals-and-model-fit">Residuals and Model Fit</a></li>
  </ul></li>
  <li><a href="#hypothesis-testing-in-simple-linear-regression" id="toc-hypothesis-testing-in-simple-linear-regression" class="nav-link" data-scroll-target="#hypothesis-testing-in-simple-linear-regression"><span class="header-section-number">10.2</span> Hypothesis Testing in Simple Linear Regression</a></li>
  <li><a href="#measuring-the-quality-of-a-regression-model" id="toc-measuring-the-quality-of-a-regression-model" class="nav-link" data-scroll-target="#measuring-the-quality-of-a-regression-model"><span class="header-section-number">10.3</span> Measuring the Quality of a Regression Model</a>
  <ul class="collapse">
  <li><a href="#residual-standard-error" id="toc-residual-standard-error" class="nav-link" data-scroll-target="#residual-standard-error">Residual Standard Error</a></li>
  <li><a href="#r-squared" id="toc-r-squared" class="nav-link" data-scroll-target="#r-squared">R-squared</a></li>
  <li><a href="#adjusted-r-squared" id="toc-adjusted-r-squared" class="nav-link" data-scroll-target="#adjusted-r-squared">Adjusted R-squared</a></li>
  <li><a href="#interpreting-model-quality" id="toc-interpreting-model-quality" class="nav-link" data-scroll-target="#interpreting-model-quality">Interpreting Model Quality</a></li>
  </ul></li>
  <li><a href="#sec-ch10-multiple-regression" id="toc-sec-ch10-multiple-regression" class="nav-link" data-scroll-target="#sec-ch10-multiple-regression"><span class="header-section-number">10.4</span> Multiple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#fitting-and-using-a-multiple-regression-model-in-r" id="toc-fitting-and-using-a-multiple-regression-model-in-r" class="nav-link" data-scroll-target="#fitting-and-using-a-multiple-regression-model-in-r">Fitting and Using a Multiple Regression Model in R</a></li>
  <li><a href="#evaluating-model-performance" id="toc-evaluating-model-performance" class="nav-link" data-scroll-target="#evaluating-model-performance">Evaluating Model Performance</a></li>
  <li><a href="#simpsons-paradox" id="toc-simpsons-paradox" class="nav-link" data-scroll-target="#simpsons-paradox">Simpson’s Paradox</a></li>
  </ul></li>
  <li><a href="#generalized-linear-models" id="toc-generalized-linear-models" class="nav-link" data-scroll-target="#generalized-linear-models"><span class="header-section-number">10.5</span> Generalized Linear Models</a></li>
  <li><a href="#sec-ch10-logistic-regression" id="toc-sec-ch10-logistic-regression" class="nav-link" data-scroll-target="#sec-ch10-logistic-regression"><span class="header-section-number">10.6</span> Logistic Regression for Binary Classification</a>
  <ul class="collapse">
  <li><a href="#fitting-a-logistic-regression-model-in-r" id="toc-fitting-a-logistic-regression-model-in-r" class="nav-link" data-scroll-target="#fitting-a-logistic-regression-model-in-r">Fitting a Logistic Regression Model in R</a></li>
  </ul></li>
  <li><a href="#poisson-regression-for-modeling-count-data" id="toc-poisson-regression-for-modeling-count-data" class="nav-link" data-scroll-target="#poisson-regression-for-modeling-count-data"><span class="header-section-number">10.7</span> Poisson Regression for Modeling Count Data</a>
  <ul class="collapse">
  <li><a href="#fitting-a-poisson-regression-model-in-r" id="toc-fitting-a-poisson-regression-model-in-r" class="nav-link" data-scroll-target="#fitting-a-poisson-regression-model-in-r">Fitting a Poisson Regression Model in R</a></li>
  </ul></li>
  <li><a href="#sec-ch10-stepwise" id="toc-sec-ch10-stepwise" class="nav-link" data-scroll-target="#sec-ch10-stepwise"><span class="header-section-number">10.8</span> Stepwise Regression for Predictor Selection</a>
  <ul class="collapse">
  <li><a href="#how-aic-guides-model-selection" id="toc-how-aic-guides-model-selection" class="nav-link" data-scroll-target="#how-aic-guides-model-selection">How AIC Guides Model Selection</a></li>
  <li><a href="#stepwise-regression-in-practice-using-step-in-r" id="toc-stepwise-regression-in-practice-using-step-in-r" class="nav-link" data-scroll-target="#stepwise-regression-in-practice-using-step-in-r">Stepwise Regression in Practice: Using <code>step()</code> in R</a></li>
  <li><a href="#considerations-for-stepwise-regression" id="toc-considerations-for-stepwise-regression" class="nav-link" data-scroll-target="#considerations-for-stepwise-regression">Considerations for Stepwise Regression</a></li>
  </ul></li>
  <li><a href="#modeling-non-linear-relationships" id="toc-modeling-non-linear-relationships" class="nav-link" data-scroll-target="#modeling-non-linear-relationships"><span class="header-section-number">10.9</span> Modeling Non-Linear Relationships</a>
  <ul class="collapse">
  <li><a href="#the-need-for-non-linear-regression" id="toc-the-need-for-non-linear-regression" class="nav-link" data-scroll-target="#the-need-for-non-linear-regression">The Need for Non-Linear Regression</a></li>
  </ul></li>
  <li><a href="#polynomial-regression-in-practice" id="toc-polynomial-regression-in-practice" class="nav-link" data-scroll-target="#polynomial-regression-in-practice"><span class="header-section-number">10.10</span> Polynomial Regression in Practice</a></li>
  <li><a href="#diagnosing-and-validating-regression-models" id="toc-diagnosing-and-validating-regression-models" class="nav-link" data-scroll-target="#diagnosing-and-validating-regression-models"><span class="header-section-number">10.11</span> Diagnosing and Validating Regression Models</a></li>
  <li><a href="#sec-ch10-case-study" id="toc-sec-ch10-case-study" class="nav-link" data-scroll-target="#sec-ch10-case-study"><span class="header-section-number">10.12</span> Case Study: Customer Churn Prediction Models</a>
  <ul class="collapse">
  <li><a href="#data-setup-for-modeling" id="toc-data-setup-for-modeling" class="nav-link" data-scroll-target="#data-setup-for-modeling">Data Setup for Modeling</a></li>
  <li><a href="#training-the-logistic-regression-model" id="toc-training-the-logistic-regression-model" class="nav-link" data-scroll-target="#training-the-logistic-regression-model">Training the Logistic Regression Model</a></li>
  <li><a href="#training-the-naive-bayes-model" id="toc-training-the-naive-bayes-model" class="nav-link" data-scroll-target="#training-the-naive-bayes-model">Training the Naive Bayes Model</a></li>
  <li><a href="#training-the-knn-model" id="toc-training-the-knn-model" class="nav-link" data-scroll-target="#training-the-knn-model">Training the kNN Model</a></li>
  <li><a href="#model-evaluation-and-comparison" id="toc-model-evaluation-and-comparison" class="nav-link" data-scroll-target="#model-evaluation-and-comparison">Model Evaluation and Comparison</a></li>
  </ul></li>
  <li><a href="#sec-ch10-summary" id="toc-sec-ch10-summary" class="nav-link" data-scroll-target="#sec-ch10-summary"><span class="header-section-number">10.13</span> Chapter Summary and Takeaways</a></li>
  <li><a href="#sec-ch10-exercises" id="toc-sec-ch10-exercises" class="nav-link" data-scroll-target="#sec-ch10-exercises"><span class="header-section-number">10.14</span> Exercises</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/edit/main/10-Regression.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-ch10-regression" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Regression Analysis: Foundations and Applications</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="chapterquote">
<p>Everything should be made as simple as possible, but not simpler.</p>
<div class="author">
<p>— Albert Einstein</p>
</div>
</div>
<p>How can a company estimate the impact of digital advertising on daily sales? How do age, income, and smoking habits relate to healthcare costs? Can housing prices be predicted from a home’s age, size, and location? Questions such as these lie at the heart of regression analysis, one of the most widely used tools in data science. Regression models allow us to quantify relationships between variables, assess their strength and direction, and generate predictions grounded in observed data.</p>
<p>The origins of regression analysis date back to the late nineteenth century, when Sir Francis Galton introduced the term <em>regression</em> to describe how offspring heights tend to move toward the population mean. Its mathematical foundations were later formalized by Legendre and Gauss through the method of least squares, establishing a systematic approach for estimating relationships from data. What began as a study of heredity has since evolved into a central framework for modeling, inference, and prediction across a wide range of scientific and applied domains. Advances in computing and tools such as R have further expanded the practical reach of regression methods, making them accessible for large-scale and complex data analysis.</p>
<p>Today, regression models play a critical role in fields such as economics, medicine, engineering, and business analytics. They are used to estimate causal effects, predict future outcomes, and identify risk factors that inform decision-making. As Charles Wheelan notes in <em>Naked Statistics</em> <span class="citation" data-cites="wheelan2013naked">(<a href="14-References.html#ref-wheelan2013naked" role="doc-biblioref">Wheelan 2013</a>)</span>, <em>“Regression modeling is the hydrogen bomb of the statistics arsenal.”</em> Used carefully, regression can provide powerful insights; used uncritically, it can lead to misleading conclusions. Sound regression analysis therefore requires both statistical rigor and thoughtful interpretation.</p>
<p>In this chapter, we build on the <em>Data Science Workflow</em> introduced in Chapter <a href="2-Intro-data-science.html" class="quarto-xref"><span>2</span></a> and illustrated in <a href="2-Intro-data-science.html#fig-ch2_DSW" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>. Earlier chapters focused on data preparation, exploratory analysis, and classification methods such as k-Nearest Neighbors (Chapter <a href="7-Classification-kNN.html" class="quarto-xref"><span>7</span></a>) and Naive Bayes (Chapter <a href="9-Naive-Bayes.html" class="quarto-xref"><span>9</span></a>), along with tools for evaluating predictive performance (Chapter <a href="8-Model-evaluation.html" class="quarto-xref"><span>8</span></a>). Regression extends this workflow to supervised learning problems where the response variable is numeric, enabling both prediction and explanation.</p>
<p>This chapter also connects directly to the statistical foundations developed in Chapter <a href="5-Statistics.html" class="quarto-xref"><span>5</span></a>, particularly the discussion of correlation and inference in Section <a href="5-Statistics.html#sec-ch5-correlation-test" class="quarto-xref"><span>5.11</span></a>. Regression generalizes these ideas by quantifying relationships while accounting for multiple predictors and by supporting formal hypothesis testing about individual effects within a multivariable framework.</p>
<section id="what-this-chapter-covers" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="what-this-chapter-covers">What This Chapter Covers</h3>
<p>This chapter develops regression analysis as a core modeling framework within the data science workflow. While earlier chapters emphasized classification tasks, regression models address problems where the outcome is numeric and continuous, such as revenue, cost, or price.</p>
<p>We begin with simple linear regression to establish fundamental concepts and intuition. The discussion then extends to multiple regression and generalized linear models, including logistic and Poisson regression, which allow regression ideas to be applied to binary and count outcomes. Polynomial regression is introduced as a practical extension for modeling non-linear relationships while preserving interpretability.</p>
<p>Throughout the chapter, we work with real-world datasets, including <em>marketing</em>, <em>house</em>, and <em>insurance</em>, to illustrate how regression models are built, interpreted, and evaluated in practice. We also examine how to assess model assumptions, evaluate performance, and select predictors using tools such as residual analysis and stepwise regression.</p>
<p>By the end of this chapter, you will be able to build, interpret, and critically evaluate regression models in R, and to distinguish between linear, generalized, and non-linear approaches based on modeling goals and data characteristics. We begin with simple linear regression, which provides the foundation for the more advanced models developed later in the chapter.</p>
</section>
<section id="sec-simple-regression" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="sec-simple-regression"><span class="header-section-number">10.1</span> Simple Linear Regression</h2>
<p>Simple linear regression is the most fundamental form of regression modeling. It provides a formal framework for quantifying the relationship between a <em>single predictor</em> and a <em>response variable</em>. By examining one predictor at a time, we build intuition about how regression models estimate effects, evaluate fit, and generate predictions, before extending these ideas to models with multiple predictors.</p>
<p>To illustrate these concepts, we use the <code>marketing</code> dataset from the <strong>liver</strong> package. This dataset records daily digital marketing activity alongside corresponding revenue outcomes, making it well suited for studying the relationship between advertising effort and financial performance. The variables capture key aspects of an online marketing campaign, including spending, user engagement, and conversion behavior.</p>
<p>We begin by loading the dataset and inspecting its structure:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(liver)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(marketing, <span class="at">package =</span> <span class="st">"liver"</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(marketing)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">40</span> obs. of  <span class="dv">8</span> variables<span class="sc">:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="er">$</span> spend          <span class="sc">:</span> num  <span class="fl">22.6</span> <span class="fl">37.3</span> <span class="fl">55.6</span> <span class="fl">45.4</span> <span class="fl">50.2</span> ...</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> clicks         <span class="sc">:</span> int  <span class="dv">165</span> <span class="dv">228</span> <span class="dv">291</span> <span class="dv">247</span> <span class="dv">290</span> <span class="dv">172</span> <span class="dv">68</span> <span class="dv">112</span> <span class="dv">306</span> <span class="dv">300</span> ...</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> impressions    <span class="sc">:</span> int  <span class="dv">8672</span> <span class="dv">11875</span> <span class="dv">14631</span> <span class="dv">11709</span> <span class="dv">14768</span> <span class="dv">8698</span> <span class="dv">2924</span> <span class="dv">5919</span> <span class="dv">14789</span> <span class="dv">14818</span> ...</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> display        <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> transactions   <span class="sc">:</span> int  <span class="dv">2</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">3</span> ...</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> click_rate     <span class="sc">:</span> num  <span class="fl">1.9</span> <span class="fl">1.92</span> <span class="fl">1.99</span> <span class="fl">2.11</span> <span class="fl">1.96</span> <span class="fl">1.98</span> <span class="fl">2.33</span> <span class="fl">1.89</span> <span class="fl">2.07</span> <span class="fl">2.02</span> ...</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> conversion_rate<span class="sc">:</span> num  <span class="fl">1.21</span> <span class="fl">0.88</span> <span class="fl">1.03</span> <span class="fl">0.81</span> <span class="fl">1.03</span> <span class="fl">1.16</span> <span class="fl">1.47</span> <span class="fl">0.89</span> <span class="fl">0.98</span> <span class="dv">1</span> ...</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> revenue        <span class="sc">:</span> num  <span class="fl">58.9</span> <span class="fl">44.9</span> <span class="fl">141.6</span> <span class="fl">209.8</span> <span class="fl">197.7</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset contains 8 variables and 40 observations. The response variable, <code>revenue</code>, is continuous, while the other variables serve as potential predictors. The variables are summarized as follows:</p>
<ul>
<li><code>revenue</code>: Total daily revenue (response variable).</li>
<li><code>spend</code>: Daily expenditure on pay-per-click (PPC) advertising.</li>
<li><code>clicks</code>: Number of clicks on advertisements.</li>
<li><code>impressions</code>: Number of times ads were displayed to users.</li>
<li><code>transactions</code>: Number of completed transactions per day.</li>
<li><code>click_rate</code>: Click-through rate (CTR), calculated as the proportion of impressions resulting in clicks.</li>
<li><code>conversion_rate</code>: Conversion rate, representing the proportion of clicks leading to transactions.</li>
<li><code>display</code>: Whether a display campaign was active (<code>yes</code> or <code>no</code>).</li>
</ul>
<p>To motivate and justify a regression model, it is essential to explore the relationships between variables. This exploratory step, introduced earlier in the data science workflow, helps assess key modeling assumptions such as linearity and highlights predictors that may be strongly associated with the response. It also provides an initial view of how variables relate to one another, revealing patterns, group differences, or potential anomalies.</p>
<p>A concise way to examine pairwise relationships is the <code>pairs.panels()</code> function from the <strong>psych</strong> package, which combines correlation coefficients, scatter plots, and marginal distributions in a single display:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs.panels</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  marketing[, <span class="sc">-</span><span class="dv">4</span>],</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">bg =</span> <span class="fu">c</span>(<span class="st">"#F4A582"</span>, <span class="st">"#92C5DE"</span>)[marketing<span class="sc">$</span>display <span class="sc">+</span> <span class="dv">1</span>],  <span class="co"># color by display</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">21</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="cn">NA</span>,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">smooth =</span> <span class="cn">FALSE</span>,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ellipses =</span> <span class="cn">FALSE</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">hist.col =</span> <span class="st">"#CCEBC5"</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">"Pairwise Relationships in the 'marketing' Data"</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="10-Regression_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H"></p>
</figure>
</div>
</div>
</div>
<p>In this visualization, the binary variable <code>display</code> (column 4) is excluded from the matrix itself and used only to color the observations, allowing differences between display and non-display days to be visually distinguished. The matrix presents correlation coefficients in the upper triangle, scatter plots in the lower triangle, and histograms along the diagonal.</p>
<p>From the correlation coefficients, we observe a strong positive association between <code>spend</code> and <code>revenue</code>, with a correlation of 0.79. This suggests that higher advertising expenditure tends to be associated with higher revenue, making <code>spend</code> a natural candidate for further modeling. This observation aligns with the discussion of correlation and linear association in Section <a href="5-Statistics.html#sec-ch5-correlation-test" class="quarto-xref"><span>5.11</span></a>, where we introduced correlation as a descriptive measure of association. In the next section, we move beyond exploratory analysis and formalize this relationship using a simple linear regression model.</p>
<section id="fitting-a-simple-linear-regression-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="fitting-a-simple-linear-regression-model">Fitting a Simple Linear Regression Model</h3>
<p>A natural starting point in regression analysis is to model the relationship between a single predictor and a response variable. This setting allows us to focus on how one variable relates to another and to develop intuition for how regression models quantify effects, before extending these ideas to more complex models. Here, we examine how advertising expenditure (<code>spend</code>) is associated with daily revenue (<code>revenue</code>) using a simple linear regression model.</p>
<p>Before fitting the model, it is useful to visualize the relationship between the two variables to assess whether a linear assumption is reasonable. A scatter plot with a fitted least-squares regression line provides a first indication of the strength and direction of the association:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-scatter-plot-simple-reg" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" data-fig-pos="H">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scatter-plot-simple-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-scatter-plot-simple-reg-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatter-plot-simple-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.1: Scatter plot of daily revenue (euros) versus daily spend (euros) for 40 observations, with the fitted least-squares regression line (orange) showing the linear relationship.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-scatter-plot-simple-reg" class="quarto-xref">Figure&nbsp;<span>10.1</span></a> shows a clear positive association between <code>spend</code> and <code>revenue</code> in the <code>marketing</code> dataset, suggesting that higher advertising expenditure is generally associated with higher revenue. This pattern is consistent with a linear relationship and motivates formal modeling.</p>
<p>We represent this relationship using a <em>simple linear regression model</em>: <span class="math display">\[
\hat{y} = b_0 + b_1 x,
\]</span> where <span class="math inline">\(\hat{y}\)</span> denotes the predicted value of the response variable (<code>revenue</code>), <span class="math inline">\(x\)</span> is the predictor (<code>spend</code>), <span class="math inline">\(b_0\)</span> is the intercept, and <span class="math inline">\(b_1\)</span> is the slope. The slope <span class="math inline">\(b_1\)</span> quantifies the expected change in revenue associated with a one-unit increase in advertising spend.</p>
<p>To build further intuition, <a href="#fig-simple-regression" class="quarto-xref">Figure&nbsp;<span>10.2</span></a> presents a conceptual illustration of the model. The fitted regression line summarizes the systematic relationship between the variables, while the vertical distance between an observed value <span class="math inline">\(y_i\)</span> and its prediction <span class="math inline">\(\hat{y}_i = b_0 + b_1 x_i\)</span> represents a <em>residual</em>. Residuals capture the portion of the response not explained by the model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-simple-regression" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" data-fig-pos="H">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simple-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/ch10_simple-regression.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simple-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.2: Conceptual view of a simple regression model: the red line shows the fitted regression line, blue points represent observed data, and the vertical line illustrates a residual (error), calculated as the difference between the observed value and its predicted value.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In the next subsection, we estimate the regression coefficients in R and interpret their meaning in the context of digital advertising and revenue.</p>
</section>
<section id="fitting-the-simple-regression-model-in-r" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="fitting-the-simple-regression-model-in-r">Fitting the Simple Regression Model in R</h3>
<p>Having established the conceptual form of a simple linear regression model, we now estimate its parameters using R. To do so, we use the <code>lm()</code> function, which fits linear models by ordinary least squares. This function is part of base R and will be used throughout the chapter for both simple and multiple regression models.</p>
<p>The general syntax for fitting a linear regression model is:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(response_variable <span class="sc">~</span> predictor_variable, <span class="at">data =</span> dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In our case, we model daily revenue as a function of advertising spend:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>simple_reg <span class="ot">=</span> <span class="fu">lm</span>(revenue <span class="sc">~</span> spend, <span class="at">data =</span> marketing)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once the model is fitted, the <code>summary()</code> function provides a compact overview of the estimated model:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_reg)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> revenue <span class="sc">~</span> spend, <span class="at">data =</span> marketing)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        Min       <span class="dv">1</span>Q   Median       <span class="dv">3</span>Q      Max </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">175.640</span>  <span class="sc">-</span><span class="fl">56.226</span>    <span class="fl">1.448</span>   <span class="fl">65.235</span>  <span class="fl">210.987</span> </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>               Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>   (Intercept)  <span class="fl">15.7058</span>    <span class="fl">35.1727</span>   <span class="fl">0.447</span>    <span class="fl">0.658</span>    </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>   spend         <span class="fl">5.2517</span>     <span class="fl">0.6624</span>   <span class="fl">7.928</span> <span class="fl">1.42e-09</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">93.82</span> on <span class="dv">38</span> degrees of freedom</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6232</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6133</span> </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">62.86</span> on <span class="dv">1</span> and <span class="dv">38</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">1.415e-09</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>At the core of this output is the estimated regression equation: <span class="math display">\[
\widehat{\text{revenue}} = 15.71 + 5.25 \times \text{spend}.
\]</span></p>
<p>The intercept (<span class="math inline">\(b_0\)</span>) represents the estimated daily revenue when no advertising spend is incurred, while the slope (<span class="math inline">\(b_1\)</span>) quantifies the expected change in revenue associated with a one-euro increase in advertising expenditure. In this model, the estimated slope indicates that each additional euro spent on advertising is associated with an average increase of approximately 5.25 euros in revenue.</p>
<p>Beyond the point estimates, the summary output provides information that supports statistical inference and model interpretation. The standard errors reflect the uncertainty associated with each coefficient estimate, while the reported <em>t</em>-statistics and <em>p</em>-values assess whether the estimated effects differ meaningfully from zero. In this case, the small <em>p</em>-value for the slope provides strong evidence of a statistically significant association between advertising spend and revenue.</p>
<p>The summary also reports measures of overall model fit. The coefficient of determination, <span class="math inline">\(R^2 =\)</span> 0.623, indicates that approximately 62.3% of the variability in daily revenue is accounted for by the linear model using advertising spend as a predictor. The <em>residual standard error (RSE)</em> provides an estimate of the typical size of prediction errors, measured in the same units as the response variable. Here, <span class="math inline">\(RSE =\)</span> 93.82.</p>
<p>Taken together, these results suggest that advertising expenditure is both a statistically significant and practically relevant predictor of revenue in this dataset. Model estimation, however, is only the first step. In the following sections, we examine how to use the fitted model for prediction, analyze residuals, and assess whether the assumptions underlying linear regression are adequately satisfied.</p>
<blockquote class="blockquote">
<p><em>Practice.</em> Repeat the modeling steps, in this section, using <code>click_rate</code> as the predictor instead of <code>spend</code>. Fit a simple linear regression model with <code>revenue</code> as the response variable and <code>click_rate</code> as the predictor, and examine the estimated intercept and slope. Use the <code>summary()</code> output to assess whether the relationship is statistically significant and to interpret the estimated effect in context.</p>
</blockquote>
</section>
<section id="making-predictions-with-the-regression-line" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="making-predictions-with-the-regression-line">Making Predictions with the Regression Line</h3>
<p>One of the primary uses of a fitted regression model is prediction. Once the relationship between advertising spend and revenue has been estimated, the regression line can be used to estimate expected revenue for new expenditure levels. This predictive perspective complements the inferential interpretation of coefficients discussed earlier.</p>
<p>Suppose a company wishes to estimate the expected daily revenue when 25 euros are spent on pay-per-click (PPC) advertising. Using the fitted regression equation, we obtain:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\widehat{\text{revenue}} &amp; = b_0 + b_1 \times 25 \\
                     &amp; = 15.71 + 5.25 \times 25 \\
                     &amp; = 147
\end{split}
\end{equation}\]</span></p>
<p>The model therefore predicts a daily revenue of approximately <em>147 euros</em> when advertising spend is set to 25 euros. Such predictions can support operational decisions, such as evaluating alternative advertising budgets or assessing expected returns under different spending scenarios.</p>
<p>Predictions from a regression model are most reliable when the predictor values lie within the range observed in the original data and when the underlying model assumptions, including linearity and constant variance, are reasonably satisfied. Predictions far outside the observed range rely on extrapolation and should be interpreted with caution.</p>
<p>To reinforce this idea, consider how the predicted revenue changes when advertising spend is increased to 40 euros or 100 euros. Comparing these predictions to the 25-euro case highlights both the linear nature of the model and the risks associated with extending it beyond the data-supported region.</p>
<p>In applied work, predictions are typically generated using the <code>predict()</code> function in R rather than by manually evaluating the regression equation. As with earlier classification models, <code>predict()</code> provides a unified interface for obtaining model-based predictions once a model has been fitted. For example, the predicted revenue corresponding to a daily spend of 25 euros can be obtained as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(simple_reg, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">spend =</span> <span class="dv">25</span>)), <span class="dv">2</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>     <span class="dv">1</span> </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>   <span class="dv">147</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This matches the value obtained earlier through direct evaluation of the regression equation. Predictions for multiple spending levels can be computed simultaneously by supplying a data frame of new values:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(simple_reg, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">spend =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">100</span>))), <span class="dv">2</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span>      <span class="dv">2</span>      <span class="dv">3</span> </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>   <span class="fl">147.00</span> <span class="fl">225.78</span> <span class="fl">540.88</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This approach scales naturally to larger datasets and integrates easily into automated analytical workflows.</p>
</section>
<section id="residuals-and-model-fit" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="residuals-and-model-fit">Residuals and Model Fit</h3>
<p>Residuals quantify the discrepancy between observed and predicted values and serve as a primary diagnostic tool for assessing how well a regression model fits the data. For a given observation <span class="math inline">\(i\)</span>, the residual is defined as: <span class="math display">\[
e_i = y_i - \hat{y}_i,
\]</span> where <span class="math inline">\(y_i\)</span> is the observed response and <span class="math inline">\(\hat{y}_i\)</span> is the corresponding predicted value from the regression model. In <a href="#fig-residual-simple-reg" class="quarto-xref">Figure&nbsp;<span>10.3</span></a>, residuals are visualized as dashed vertical lines connecting observed outcomes to the fitted regression line.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-residual-simple-reg" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" data-fig-pos="H">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-residual-simple-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-residual-simple-reg-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-residual-simple-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.3: Scatter plot of daily revenue (euros) versus daily spend (euros) for 40 observations. The orange line shows the fitted regression line, and the gray dashed lines indicate residuals, representing the vertical distances between the observed values and the predictions from the line.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To make this concrete, consider an observation with a marketing spend of 25 euros and an observed revenue of 185.36. The residual is computed as the difference between the observed revenue and the value predicted by the regression line. A positive residual indicates underprediction by the model, while a negative residual indicates overprediction.</p>
<p>Residuals provide essential insight into model adequacy. When a linear model is appropriate, residuals should be randomly scattered around zero with no systematic structure. Patterns such as curvature, clustering, or increasing spread suggest violations of modeling assumptions and may indicate the need for additional predictors, variable transformations, or non-linear extensions.</p>
<p>The regression line itself is estimated using the <em>least squares</em> method, which selects coefficient values that minimize the <em>sum of squared residuals</em>, also known as the <em>sum of squared errors (SSE)</em>: <span id="eq-sse"><span class="math display">\[
\text{SSE} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2,
\tag{10.1}\]</span></span> where <span class="math inline">\(n\)</span> denotes the number of observations. This criterion corresponds to minimizing the total squared length of the dashed residual lines shown in <a href="#fig-residual-simple-reg" class="quarto-xref">Figure&nbsp;<span>10.3</span></a> and provides a precise definition of what it means for the model to “fit” the data.</p>
<p>In summary, residuals offer a window into both model fit and potential shortcomings of the regression specification. Understanding their behavior is essential before drawing inferential conclusions or extending the model. Having examined residual behavior and overall fit, we now turn to the question of whether the observed relationship between advertising spend and revenue is statistically reliable.</p>
</section>
</section>
<section id="hypothesis-testing-in-simple-linear-regression" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="hypothesis-testing-in-simple-linear-regression"><span class="header-section-number">10.2</span> Hypothesis Testing in Simple Linear Regression</h2>
<p>Once a regression model has been estimated, a natural next question is whether the observed relationship reflects a genuine association or could plausibly have arisen by chance. This question is addressed through hypothesis testing, a core inferential concept introduced in Chapter <a href="5-Statistics.html" class="quarto-xref"><span>5</span></a> and applied here to regression models.</p>
<p>In simple linear regression, inference focuses on the slope coefficient. Specifically, we assess whether the estimated slope <span class="math inline">\(b_1\)</span> provides evidence of a linear association in the population, where the corresponding population parameter is denoted by <span class="math inline">\(\beta_1\)</span>. The population regression model is given by <span class="math display">\[
y = \beta_0 + \beta_1 x + \epsilon,
\]</span> where <span class="math inline">\(\beta_0\)</span> is the population intercept, <span class="math inline">\(\beta_1\)</span> is the population slope, and <span class="math inline">\(\epsilon\)</span> represents random variability not explained by the model.</p>
<p>The central inferential question is whether <span class="math inline">\(\beta_1\)</span> differs from zero. If <span class="math inline">\(\beta_1 = 0\)</span>, then the predictor <span class="math inline">\(x\)</span> has no linear effect on the response, and the model simplifies to <span class="math display">\[
y = \beta_0 + \epsilon.
\]</span></p>
<p>We formalize this question using the hypotheses <span class="math display">\[
\begin{cases}
H_0: \beta_1 = 0 &amp; \text{(no linear relationship between $x$ and $y$)}, \\
H_a: \beta_1 \neq 0 &amp; \text{(a linear relationship exists)}.
\end{cases}
\]</span></p>
<p>To test these hypotheses, we compute a t-statistic for the slope, <span class="math display">\[
t = \frac{b_1}{SE(b_1)},
\]</span> where <span class="math inline">\(SE(b_1)\)</span> is the standard error of the slope estimate. Under the null hypothesis, this statistic follows a t-distribution with <span class="math inline">\(n - 2\)</span> degrees of freedom, reflecting the estimation of two parameters in simple linear regression. The associated <em>p</em>-value quantifies how likely it would be to observe a slope as extreme as <span class="math inline">\(b_1\)</span> if <span class="math inline">\(H_0\)</span> were true.</p>
<p>Returning to the regression model predicting <code>revenue</code> from <code>spend</code> in the <code>marketing</code> dataset, we examine the model summary:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_reg)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> revenue <span class="sc">~</span> spend, <span class="at">data =</span> marketing)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        Min       <span class="dv">1</span>Q   Median       <span class="dv">3</span>Q      Max </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">175.640</span>  <span class="sc">-</span><span class="fl">56.226</span>    <span class="fl">1.448</span>   <span class="fl">65.235</span>  <span class="fl">210.987</span> </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>               Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>   (Intercept)  <span class="fl">15.7058</span>    <span class="fl">35.1727</span>   <span class="fl">0.447</span>    <span class="fl">0.658</span>    </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>   spend         <span class="fl">5.2517</span>     <span class="fl">0.6624</span>   <span class="fl">7.928</span> <span class="fl">1.42e-09</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">93.82</span> on <span class="dv">38</span> degrees of freedom</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6232</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6133</span> </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">62.86</span> on <span class="dv">1</span> and <span class="dv">38</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">1.415e-09</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>From this output, the estimated slope is <span class="math inline">\(b_1 =\)</span> 5.25, with a corresponding t-statistic of 7.93 and a <em>p</em>-value of 0. Since this <em>p</em>-value is well below the conventional significance level <span class="math inline">\(\alpha = 0.05\)</span>, we reject the null hypothesis.</p>
<p>This result provides strong statistical evidence of a linear association between advertising spend and revenue. Interpreted in context, the estimated slope indicates that each additional euro spent on advertising is associated with an average increase of approximately 5.25 euros in daily revenue.</p>
<p>It is important to emphasize that statistical significance does not imply causation. The observed association may be influenced by unmeasured variables, confounding effects, or modeling assumptions. Hypothesis testing addresses whether an effect is unlikely to be zero, not whether it represents a causal mechanism or yields accurate predictions.</p>
<p>Inference tells us <em>whether</em> a relationship is statistically reliable; it does not tell us <em>how well</em> the model performs. In the next section, we therefore shift focus from statistical significance to <em>model quality</em>, introducing measures that assess explanatory power and predictive accuracy. We then build on this foundation by extending the framework to multiple regression models.</p>
</section>
<section id="measuring-the-quality-of-a-regression-model" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="measuring-the-quality-of-a-regression-model"><span class="header-section-number">10.3</span> Measuring the Quality of a Regression Model</h2>
<p>Suppose a regression model indicates that advertising spend has a statistically significant effect on daily revenue. While this establishes the presence of an association, it does not tell us whether the model provides useful or accurate predictions. Hypothesis tests address <em>whether</em> a relationship exists, but they do not assess <em>how well</em> the model captures variability in the data or supports practical decision-making.</p>
<p>To evaluate a model’s overall performance, we therefore need additional criteria. This section introduces two fundamental measures of regression quality: the residual standard error (RSE), which summarizes the typical size of prediction errors, and the coefficient of determination, <span class="math inline">\(R^2\)</span>, which quantifies the proportion of variability in the response explained by the model. Together, these metrics provide a broader assessment of model adequacy that complements statistical inference.</p>
<section id="residual-standard-error" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="residual-standard-error">Residual Standard Error</h3>
<p>The residual standard error (RSE) quantifies how closely a regression model’s predictions align with the observed data. It summarizes the typical size of the residuals: the differences between observed and predicted values, illustrated by the dashed lines in <a href="#fig-residual-simple-reg" class="quarto-xref">Figure&nbsp;<span>10.3</span></a>. In effect, RSE provides a measure of the model’s average deviation from the data.</p>
<p>The RSE is defined as <span class="math display">\[
RSE = \sqrt{\frac{SSE}{n - m - 1}},
\]</span> where <span class="math inline">\(SSE\)</span> is the sum of squared errors defined in <a href="#eq-sse" class="quarto-xref">Equation&nbsp;<span>10.1</span></a>, <span class="math inline">\(n\)</span> is the number of observations, and <span class="math inline">\(m\)</span> is the number of predictors. The denominator <span class="math inline">\(n - m - 1\)</span> reflects the model’s degrees of freedom and accounts for the number of estimated parameters.</p>
<p>A smaller RSE indicates that, on average, the model’s predictions lie closer to the observed values. For the simple linear regression model fitted to the <code>marketing</code> dataset, the RSE is computed as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>rse_value <span class="ot">=</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(simple_reg<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">summary</span>(simple_reg)<span class="sc">$</span>df[<span class="dv">2</span>])</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(rse_value, <span class="dv">2</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">93.82</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This value represents the typical magnitude of prediction errors, expressed in the same units as the response variable (euros). Interpretation should therefore always be contextual. An RSE of 20 euros may be negligible when daily revenue is measured in thousands, but substantial if revenues are typically much smaller.</p>
</section>
<section id="r-squared" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="r-squared">R-squared</h3>
<p>The coefficient of determination, <span class="math inline">\(R^2\)</span>, measures how much of the variability in the response variable is explained by the regression model. It summarizes how well the fitted regression line captures the overall variation in the data.</p>
<p>Formally, <span class="math inline">\(R^2\)</span> is defined as <span class="math display">\[
R^2 = 1 - \frac{SSE}{SST},
\]</span> where <span class="math inline">\(SSE\)</span> is the sum of squared residuals defined in <a href="#eq-sse" class="quarto-xref">Equation&nbsp;<span>10.1</span></a> and <span class="math inline">\(SST\)</span> is the total sum of squares, representing the total variation in the response. The value of <span class="math inline">\(R^2\)</span> ranges between 0 and 1. A value of 1 indicates that the model explains all observed variation, while a value of 0 indicates that it explains none.</p>
<p>In the simple linear regression of <code>revenue</code> on <code>spend</code>, the value of <span class="math inline">\(R^2\)</span> is</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">summary</span>(simple_reg)<span class="sc">$</span>r.squared, <span class="dv">3</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">0.623</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This means that approximately 62.3% of the variation in daily revenue is explained by advertising spend. Visually, this corresponds to how closely the regression line in <a href="#fig-scatter-plot-simple-reg" class="quarto-xref">Figure&nbsp;<span>10.1</span></a> follows the overall pattern of the data.</p>
<p>In simple linear regression, <span class="math inline">\(R^2\)</span> has a direct relationship with the Pearson correlation coefficient introduced in Section <a href="5-Statistics.html#sec-ch5-correlation-test" class="quarto-xref"><span>5.11</span></a> of Chapter <a href="5-Statistics.html" class="quarto-xref"><span>5</span></a>. Specifically, <span class="math display">\[
R^2 = r^2,
\]</span> where <span class="math inline">\(r\)</span> is the correlation between the predictor and the response. In the <code>marketing</code> dataset, this relationship can be verified directly:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cor</span>(marketing<span class="sc">$</span>spend, marketing<span class="sc">$</span>revenue), <span class="dv">2</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">0.79</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Squaring this value yields the same <span class="math inline">\(R^2\)</span> statistic, reinforcing that in simple regression, <span class="math inline">\(R^2\)</span> reflects the strength of the linear association between two variables.</p>
<p>While larger values of <span class="math inline">\(R^2\)</span> indicate that a greater proportion of variability is explained by the model, they do not guarantee good predictive performance or valid inference. A model may achieve a high <span class="math inline">\(R^2\)</span> while violating regression assumptions or overfitting the data. Consequently, <span class="math inline">\(R^2\)</span> should always be interpreted alongside residual diagnostics and other measures of model quality.</p>
</section>
<section id="adjusted-r-squared" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="adjusted-r-squared">Adjusted R-squared</h3>
<p>In regression modeling, adding predictors will always increase <span class="math inline">\(R^2\)</span>, even when the additional variables contribute little meaningful information. For this reason, <span class="math inline">\(R^2\)</span> alone can be misleading when comparing models of differing complexity. <em>Adjusted</em> <span class="math inline">\(R^2\)</span> addresses this limitation by explicitly accounting for the number of predictors included in the model.</p>
<p>Adjusted <span class="math inline">\(R^2\)</span> is defined as <span class="math display">\[
\text{Adjusted } R^2 = 1 - \left(1 - R^2\right) \times \frac{n - 1}{n - m - 1},
\]</span> where <span class="math inline">\(n\)</span> denotes the number of observations and <span class="math inline">\(m\)</span> the number of predictors. Unlike <span class="math inline">\(R^2\)</span>, Adjusted <span class="math inline">\(R^2\)</span> may increase or decrease when a new predictor is added, depending on whether that predictor improves the model sufficiently to justify its inclusion.</p>
<p>In simple linear regression, where <span class="math inline">\(m = 1\)</span>, Adjusted <span class="math inline">\(R^2\)</span> is typically very close to <span class="math inline">\(R^2\)</span>. However, as models become more complex, Adjusted <span class="math inline">\(R^2\)</span> becomes a more informative measure. It penalizes unnecessary complexity and helps determine whether additional predictors genuinely improve explanatory power rather than merely inflating apparent fit.</p>
<p>Adjusted <span class="math inline">\(R^2\)</span> is therefore especially useful when comparing alternative regression models with different sets of predictors, a situation that arises frequently in multiple regression and model selection.</p>
</section>
<section id="interpreting-model-quality" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="interpreting-model-quality">Interpreting Model Quality</h3>
<p>Assessing the quality of a regression model requires balancing several complementary measures rather than relying on a single statistic. In general, a well-performing model exhibits a <em>low residual standard error (RSE)</em>, indicating that predictions are close to observed values, alongside relatively <em>high values of</em> <span class="math inline">\(R^2\)</span> and <em>Adjusted</em> <span class="math inline">\(R^2\)</span>, suggesting that the model explains a substantial proportion of the variability in the response without unnecessary complexity.</p>
<p>However, these metrics should never be interpreted in isolation. A high <span class="math inline">\(R^2\)</span> may arise from overfitting or be unduly influenced by outliers, while a low RSE does not guarantee that key modeling assumptions have been satisfied. In applied analysis, measures of fit must therefore be considered alongside residual diagnostics, graphical checks, and, where appropriate, validation techniques such as cross-validation.</p>
<p><a href="#tbl-reg-quality-metrics" class="quarto-xref">Table&nbsp;<span>10.1</span></a> summarizes the primary regression quality metrics discussed in this section and highlights their interpretation and intended use. Together, these tools provide a more nuanced view of model adequacy and help guard against overly simplistic conclusions.</p>
<div id="tbl-reg-quality-metrics" class="table quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-reg-quality-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.1: Overview of commonly used regression model quality metrics.
</figcaption>
<div aria-describedby="tbl-reg-quality-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table caption-top">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>What It Tells You</th>
<th>What to Look For</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RSE (Residual Std. Error)</td>
<td>Typical prediction error</td>
<td>Lower is better</td>
</tr>
<tr class="even">
<td><span class="math inline">\(R^2\)</span></td>
<td>Proportion of variance explained</td>
<td>Higher is better</td>
</tr>
<tr class="odd">
<td>Adjusted <span class="math inline">\(R^2\)</span></td>
<td><span class="math inline">\(R^2\)</span> adjusted for model complexity</td>
<td>Higher, but not inflated</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Having established how to evaluate model quality in simple linear regression, we now extend the framework to <em>multiple regression</em>, where several predictors are used simultaneously to explain variation in the response.</p>
<blockquote class="blockquote">
<p><em>Practice.</em> Repeat the modeling and evaluation steps in this section using <code>click_rate</code> as the predictor instead of <code>spend</code>. Fit a simple linear regression model for <code>revenue</code>, compute the RSE, <span class="math inline">\(R^2\)</span>, and Adjusted <span class="math inline">\(R^2\)</span>, and compare these values to those obtained for the original model. Based on these metrics and residual behavior, which predictor appears to provide a better explanation of revenue in this dataset?</p>
</blockquote>
</section>
</section>
<section id="sec-ch10-multiple-regression" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="sec-ch10-multiple-regression"><span class="header-section-number">10.4</span> Multiple Linear Regression</h2>
<p>We now move beyond simple linear regression and consider models with more than one predictor. This leads to <em>multiple linear regression</em>, a framework that allows us to model the simultaneous effects of several variables on an outcome. In real-world applications, responses are rarely driven by a single factor, and multiple regression provides a principled way to capture this complexity.</p>
<p>To illustrate, we extend the previous model by adding a second predictor. In addition to advertising spend (<code>spend</code>), we include <code>display</code>, an indicator of whether a display advertising campaign was active. Incorporating multiple predictors allows us to assess the effect of each variable <em>while holding the others constant</em>, a key advantage of multiple regression.</p>
<p>The general form of a multiple regression model with <span class="math inline">\(m\)</span> predictors is <span class="math display">\[
\hat{y} = b_0 + b_1 x_1 + b_2 x_2 + \dots + b_m x_m,
\]</span> where <span class="math inline">\(b_0\)</span> is the intercept and <span class="math inline">\(b_1, b_2, \dots, b_m\)</span> represent the estimated effects of the predictors on the response.</p>
<p>In our case, the model with two predictors is <span class="math display">\[
\widehat{\text{revenue}} = b_0 + b_1 \times \text{spend} + b_2 \times \text{display}.
\]</span> Here, <code>spend</code> denotes daily advertising expenditure, and <code>display</code> is a categorical variable indicating whether a display campaign was active. When fitting the model in R, this variable is automatically converted into a binary indicator, with the first factor level (<code>no</code>) used as the reference category by default. The coefficient for <code>display</code> therefore represents the expected difference in revenue between days with and without a display campaign, holding advertising spend constant.</p>
<section id="fitting-and-using-a-multiple-regression-model-in-r" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="fitting-and-using-a-multiple-regression-model-in-r">Fitting and Using a Multiple Regression Model in R</h3>
<p>To fit a multiple regression model in R, we again use the <code>lm()</code> function introduced earlier. The key difference from simple regression is that multiple predictors are included on the right-hand side of the model formula:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>multiple_reg <span class="ot">=</span> <span class="fu">lm</span>(revenue <span class="sc">~</span> spend <span class="sc">+</span> display, <span class="at">data =</span> marketing)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(multiple_reg)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> revenue <span class="sc">~</span> spend <span class="sc">+</span> display, <span class="at">data =</span> marketing)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        Min       <span class="dv">1</span>Q   Median       <span class="dv">3</span>Q      Max </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">189.420</span>  <span class="sc">-</span><span class="fl">45.527</span>    <span class="fl">5.566</span>   <span class="fl">54.943</span>  <span class="fl">154.340</span> </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>               Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>   (Intercept) <span class="sc">-</span><span class="fl">41.4377</span>    <span class="fl">32.2789</span>  <span class="sc">-</span><span class="fl">1.284</span> <span class="fl">0.207214</span>    </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>   spend         <span class="fl">5.3556</span>     <span class="fl">0.5523</span>   <span class="fl">9.698</span> <span class="fl">1.05e-11</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>   display     <span class="fl">104.2878</span>    <span class="fl">24.7353</span>   <span class="fl">4.216</span> <span class="fl">0.000154</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">78.14</span> on <span class="dv">37</span> degrees of freedom</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7455</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7317</span> </span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">54.19</span> on <span class="dv">2</span> and <span class="dv">37</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">1.012e-11</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This specification fits a model in which both advertising spend (<code>spend</code>) and the presence of a display campaign (<code>display</code>) are used to explain variation in daily revenue. The estimated regression equation is <span class="math display">\[
\widehat{\text{revenue}} =
-41.44 +
5.36 \times \text{spend} +
104.29 \times \text{display}.
\]</span></p>
<p>The intercept (<span class="math inline">\(b_0\)</span>), equal to -41.44, represents the expected daily revenue when advertising spend is zero and no display campaign is active. The coefficient for <code>spend</code> (<span class="math inline">\(b_1\)</span>), equal to 5.36, indicates the expected change in revenue associated with a one-euro increase in advertising expenditure, assuming the display campaign status does not change. Similarly, the coefficient for <code>display</code> (<span class="math inline">\(b_2\)</span>), equal to 104.29, measures the expected difference in revenue between days with and without a display campaign for a fixed level of advertising spend. Together, these interpretations highlight a defining feature of multiple regression: each coefficient represents the effect of a predictor after accounting for the influence of the others.</p>
<p>Once the model has been fitted and interpreted, it can be used to generate predictions for specific scenarios. Consider a scenario in which the company spends 25 euros on advertising while running a display campaign (<code>display = 1</code>). Using the fitted multiple regression model, the predicted revenue is <span class="math display">\[
\widehat{\text{revenue}} =
-41.44 +
5.36 \times 25 +
104.29 \times 1
= 196.74.
\]</span></p>
<p>The model therefore predicts a daily revenue of approximately 196.74 euros under these conditions.</p>
<p>For a specific observation, the residual (or prediction error) is defined as the difference between the observed and predicted revenue, <span class="math display">\[
\text{Residual} = y - \hat{y}.
\]</span> For example, for observation 21 in the dataset, the residual is <span class="math display">\[
\text{Residual} = y - \hat{y} = 185.36 - 196.74 = -11.49,
\]</span> illustrating how the model’s prediction deviates from the observed outcome for an individual day.</p>
<p>While residuals help assess prediction accuracy at the observation level, conclusions about overall predictive performance should be based on aggregate measures such as the residual standard error or validation-based metrics, rather than on individual cases.</p>
<p>In practice, predictions are typically generated using the <code>predict()</code> function in R rather than by manually evaluating the regression equation. For example, the predicted revenue for a day with 25 euros in advertising spend and an active display campaign can be obtained as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(multiple_reg, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">spend =</span> <span class="dv">25</span>, <span class="at">display =</span> <span class="dv">1</span>)), <span class="dv">2</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span> </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>   <span class="fl">196.74</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This approach is especially useful when generating predictions for multiple scenarios or integrating regression models into automated workflows.</p>
<blockquote class="blockquote">
<p><em>Practice.</em> Estimate the predicted daily revenue under two additional scenarios: (i) spending 40 euros with a display campaign (<code>display = 1</code>), and (ii) spending 100 euros with no display campaign (<code>display = 0</code>). Use either the regression equation or the <code>predict()</code> function. Interpret the results and consider whether these predictions fall within a reasonable range given the observed data.</p>
</blockquote>
</section>
<section id="evaluating-model-performance" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="evaluating-model-performance">Evaluating Model Performance</h3>
<p>How can we assess whether adding a new predictor, such as <code>display</code>, genuinely improves a regression model? In the previous section, <a href="#tbl-reg-quality-metrics" class="quarto-xref">Table&nbsp;<span>10.1</span></a> introduced three complementary measures of model quality: the residual standard error (RSE), <span class="math inline">\(R^2\)</span>, and Adjusted <span class="math inline">\(R^2\)</span>. Here, we apply these metrics to compare the simple and multiple regression models and evaluate whether the added complexity is justified.</p>
<p>For the simple regression model, the residual standard error is <span class="math inline">\(RSE =\)</span> 93.82, whereas for the multiple regression model it is <span class="math inline">\(RSE =\)</span> 78.14. The lower RSE in the multiple regression model indicates that, on average, its predictions are closer to the observed revenue values.</p>
<p>The coefficient of determination also increases when <code>display</code> is added. In the simple regression model, <span class="math inline">\(R^2 =\)</span> 62.3%, while in the multiple regression model it rises to <span class="math inline">\(R^2 =\)</span> 74.6%. This suggests that including <code>display</code> allows the model to explain a larger proportion of the variability in daily revenue.</p>
<p>Adjusted <span class="math inline">\(R^2\)</span>, which penalizes unnecessary predictors, provides a more cautious assessment. Its value increases from 61.3% in the simple regression model to 73.2% in the multiple regression model. This increase indicates that the additional predictor improves model performance beyond what would be expected from increased complexity alone.</p>
<p>Taken together, these results illustrate how model evaluation metrics support principled comparison between competing models. Rather than maximizing fit indiscriminately, they help balance explanatory power against model simplicity and guard against overfitting.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Add another predictor, such as <code>clicks</code>, to the model. How do the RSE, <span class="math inline">\(R^2\)</span>, and Adjusted <span class="math inline">\(R^2\)</span> change? What do these changes suggest about the added value of this predictor?</p>
</blockquote>
<p>These comparisons naturally raise a broader modeling question: should all available predictors be included, or is there an optimal subset that balances simplicity and performance? We address this issue in Section <a href="#sec-ch10-stepwise" class="quarto-xref"><span>10.8</span></a>, where we introduce stepwise regression and related model selection strategies.</p>
</section>
<section id="simpsons-paradox" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="simpsons-paradox">Simpson’s Paradox</h3>
<p>As we incorporate more variables into regression models, we must remain attentive to how relationships can change when data are aggregated or stratified. A classic cautionary example is <em>Simpson’s Paradox</em>. Suppose a university observes that within every department, female applicants are admitted at higher rates than male applicants. Yet, when admissions data are aggregated across departments, it appears that male applicants are admitted more often. How can such a reversal occur?</p>
<p>This phenomenon is known as Simpson’s Paradox: a situation in which trends observed within groups reverse or disappear when the groups are combined. The paradox typically arises when an important grouping variable influences both the predictor and the response but is omitted from the analysis.</p>
<p>In <a href="#fig-ch10-Simpson-Paradox" class="quarto-xref">Figure&nbsp;<span>10.4</span></a>, the left panel shows a regression line fitted to the aggregated data, yielding an overall correlation of -0.74 that ignores the underlying group structure. The right panel reveals a very different picture: within each group, the association between the predictor and response is positive (Group 1: 0.79, Group 2: 0.71, Group 3: 0.62, Group 4: 0.66, Group 5: 0.75). This contrast illustrates how aggregation can obscure meaningful within-group relationships.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ch10-Simpson-Paradox" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" data-fig-pos="H">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch10-Simpson-Paradox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-ch10-Simpson-Paradox-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch10-Simpson-Paradox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.4: Simpson’s Paradox: The left plot shows a regression line fitted to the full dataset, ignoring group structure. The right plot fits separate regression lines for each group, revealing positive trends within groups that are hidden when data are aggregated.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Simpson’s Paradox highlights the importance of including relevant variables in regression models. By conditioning on multiple predictors simultaneously, multiple regression helps disentangle relationships that may otherwise be confounded. This insight connects directly to our analysis of the <code>marketing</code> dataset. In the simple regression model, we examined revenue as a function of advertising spend alone. After introducing <code>display</code> as an additional predictor, the interpretation of the <code>spend</code> coefficient changed, reflecting the influence of campaign context. More generally, Simpson’s Paradox reminds us that a variable’s apparent effect may weaken, disappear, or even reverse once other important predictors are taken into account. Careful exploratory analysis and thoughtful model specification are therefore essential for drawing reliable conclusions.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Can you think of a situation in your domain (such as public health, marketing, or education) where combining groups might obscure meaningful differences? How would you detect and guard against this risk in your analysis?</p>
</blockquote>
</section>
</section>
<section id="generalized-linear-models" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="generalized-linear-models"><span class="header-section-number">10.5</span> Generalized Linear Models</h2>
<p>Many practical modeling problems involve outcomes that are not continuous. For example, we may wish to predict whether a customer will churn (a binary outcome) or model the number of daily transactions (a count outcome). In such settings, traditional linear regression is no longer appropriate. Its assumptions of normally distributed errors, constant variance, and an unbounded linear relationship between predictors and the response are violated when working with binary or count data.</p>
<p>Generalized Linear Models (GLMs) extend the familiar regression framework to accommodate these situations. They retain the idea of modeling a response variable using a linear predictor but introduce additional structure that allows for a broader class of outcome types. In particular, GLMs incorporate:</p>
<ul>
<li><p>a <em>random component</em>, which specifies a probability distribution for the response variable drawn from the exponential family (such as the normal, binomial, or Poisson distributions);</p></li>
<li><p>a <em>systematic component</em>, which represents the linear combination of predictor variables;</p></li>
<li><p>and a <em>link function</em>, which connects the expected value of the response variable to the linear predictor.</p></li>
</ul>
<p>Through the choice of an appropriate distribution and link function, GLMs allow the variance of the response to depend on its mean and ensure that model predictions respect the natural constraints of the data (such as probabilities lying between 0 and 1 or counts being non-negative).</p>
<p>These extensions make GLMs a flexible and interpretable modeling framework that is widely used in fields such as finance, healthcare, social sciences, and marketing. In the following sections, we focus on two commonly used generalized linear models: logistic regression, designed for binary outcomes (such as churn versus no churn), and Poisson regression, which is well suited for modeling count data (such as the number of customer service calls).</p>
<p>By extending regression beyond continuous responses, generalized linear models broaden the scope of problems that can be addressed using regression-based methods. The next sections introduce their theoretical foundations and demonstrate their practical implementation in R.</p>
</section>
<section id="sec-ch10-logistic-regression" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="sec-ch10-logistic-regression"><span class="header-section-number">10.6</span> Logistic Regression for Binary Classification</h2>
<p>Predicting whether an event occurs or not is a central task in data science. For example, we may wish to predict whether a customer will leave a service based on usage behavior. Such problems involve <em>binary outcomes</em> and were first introduced in Chapter <a href="7-Classification-kNN.html" class="quarto-xref"><span>7</span></a> using k-Nearest Neighbors (kNN), and later revisited in Chapter <a href="9-Naive-Bayes.html" class="quarto-xref"><span>9</span></a> with the Naive Bayes classifier. These approaches emphasized flexible, data-driven classification. We now turn to a complementary perspective: a model-based approach grounded in statistical inference, known as <em>logistic regression</em>.</p>
<p>Logistic regression is a generalized linear model designed specifically for binary response variables. Rather than modeling the outcome directly, it models the <em>log-odds</em> of the event as a linear function of the predictors: <span class="math display">\[
\text{logit}(p) = \ln\left(\frac{p}{1 - p}\right)
= b_0 + b_1 x_1 + b_2 x_2 + \dots + b_m x_m,
\]</span> where <span class="math inline">\(p\)</span> denotes the probability that the outcome equals 1. By linking the linear predictor to the response through the logit function, logistic regression ensures that predicted probabilities lie in the interval <span class="math inline">\([0, 1]\)</span>, while allowing the predictors themselves to vary freely on the real line.</p>
<p>Compared to kNN and Naive Bayes, logistic regression offers a different set of advantages. Its coefficients have a clear interpretation in terms of changes in log-odds, it integrates naturally with the regression framework developed earlier in this chapter, and it provides a foundation for many extensions used in modern statistical learning.</p>
<p>In the next subsection, we apply logistic regression in R using the <code>churn_mlc</code> dataset. We show how to fit the model, interpret its coefficients, and evaluate its usefulness for practical decision-making.</p>
<section id="fitting-a-logistic-regression-model-in-r" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="fitting-a-logistic-regression-model-in-r">Fitting a Logistic Regression Model in R</h3>
<p>We now implement logistic regression in R and interpret its output in a practical setting. We use the <code>churn_mlc</code> dataset from the <strong>liver</strong> package, which contains information on customer behavior, including account characteristics, usage patterns, and customer service interactions. The objective is to model whether a customer has churned (<code>yes</code>) or not (<code>no</code>) based on these predictors. We begin by inspecting the structure of the dataset:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(churn_mlc)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(churn_mlc)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">5000</span> obs. of  <span class="dv">20</span> variables<span class="sc">:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="er">$</span> state         <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">51</span> levels <span class="st">"AK"</span>,<span class="st">"AL"</span>,<span class="st">"AR"</span>,..<span class="sc">:</span> <span class="dv">17</span> <span class="dv">36</span> <span class="dv">32</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">2</span> <span class="dv">20</span> <span class="dv">25</span> <span class="dv">19</span> <span class="dv">50</span> ...</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> area_code     <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">3</span> levels <span class="st">"area_code_408"</span>,..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> ...</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> account_length<span class="sc">:</span> int  <span class="dv">128</span> <span class="dv">107</span> <span class="dv">137</span> <span class="dv">84</span> <span class="dv">75</span> <span class="dv">118</span> <span class="dv">121</span> <span class="dv">147</span> <span class="dv">117</span> <span class="dv">141</span> ...</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> voice_plan    <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> ...</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> voice_messages<span class="sc">:</span> int  <span class="dv">25</span> <span class="dv">26</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">24</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">37</span> ...</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_plan     <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> ...</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_mins     <span class="sc">:</span> num  <span class="dv">10</span> <span class="fl">13.7</span> <span class="fl">12.2</span> <span class="fl">6.6</span> <span class="fl">10.1</span> <span class="fl">6.3</span> <span class="fl">7.5</span> <span class="fl">7.1</span> <span class="fl">8.7</span> <span class="fl">11.2</span> ...</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_calls    <span class="sc">:</span> int  <span class="dv">3</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">7</span> <span class="dv">3</span> <span class="dv">6</span> <span class="dv">7</span> <span class="dv">6</span> <span class="dv">4</span> <span class="dv">5</span> ...</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_charge   <span class="sc">:</span> num  <span class="fl">2.7</span> <span class="fl">3.7</span> <span class="fl">3.29</span> <span class="fl">1.78</span> <span class="fl">2.73</span> <span class="fl">1.7</span> <span class="fl">2.03</span> <span class="fl">1.92</span> <span class="fl">2.35</span> <span class="fl">3.02</span> ...</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> day_mins      <span class="sc">:</span> num  <span class="dv">265</span> <span class="dv">162</span> <span class="dv">243</span> <span class="dv">299</span> <span class="dv">167</span> ...</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> day_calls     <span class="sc">:</span> int  <span class="dv">110</span> <span class="dv">123</span> <span class="dv">114</span> <span class="dv">71</span> <span class="dv">113</span> <span class="dv">98</span> <span class="dv">88</span> <span class="dv">79</span> <span class="dv">97</span> <span class="dv">84</span> ...</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> day_charge    <span class="sc">:</span> num  <span class="fl">45.1</span> <span class="fl">27.5</span> <span class="fl">41.4</span> <span class="fl">50.9</span> <span class="fl">28.3</span> ...</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> eve_mins      <span class="sc">:</span> num  <span class="fl">197.4</span> <span class="fl">195.5</span> <span class="fl">121.2</span> <span class="fl">61.9</span> <span class="fl">148.3</span> ...</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> eve_calls     <span class="sc">:</span> int  <span class="dv">99</span> <span class="dv">103</span> <span class="dv">110</span> <span class="dv">88</span> <span class="dv">122</span> <span class="dv">101</span> <span class="dv">108</span> <span class="dv">94</span> <span class="dv">80</span> <span class="dv">111</span> ...</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> eve_charge    <span class="sc">:</span> num  <span class="fl">16.78</span> <span class="fl">16.62</span> <span class="fl">10.3</span> <span class="fl">5.26</span> <span class="fl">12.61</span> ...</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> night_mins    <span class="sc">:</span> num  <span class="dv">245</span> <span class="dv">254</span> <span class="dv">163</span> <span class="dv">197</span> <span class="dv">187</span> ...</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> night_calls   <span class="sc">:</span> int  <span class="dv">91</span> <span class="dv">103</span> <span class="dv">104</span> <span class="dv">89</span> <span class="dv">121</span> <span class="dv">118</span> <span class="dv">118</span> <span class="dv">96</span> <span class="dv">90</span> <span class="dv">97</span> ...</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> night_charge  <span class="sc">:</span> num  <span class="fl">11.01</span> <span class="fl">11.45</span> <span class="fl">7.32</span> <span class="fl">8.86</span> <span class="fl">8.41</span> ...</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> customer_calls<span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">0</span> <span class="dv">3</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> ...</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> churn         <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset contains 5000 observations and 19 predictor variables. Based on earlier exploration, we select the following features for the logistic regression model:</p>
<p><code>account_length</code>, <code>voice_plan</code>, <code>voice_messages</code>, <code>intl_plan</code>, <code>intl_mins</code>, <code>day_mins</code>, <code>eve_mins</code>, <code>night_mins</code>, and <code>customer_calls</code>.</p>
<p>We specify the model using a formula that relates the binary response variable <code>churn</code> to these predictors:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>formula <span class="ot">=</span> churn <span class="sc">~</span> account_length <span class="sc">+</span> voice_messages <span class="sc">+</span> day_mins <span class="sc">+</span> eve_mins <span class="sc">+</span> night_mins <span class="sc">+</span> intl_mins <span class="sc">+</span> customer_calls <span class="sc">+</span> intl_plan <span class="sc">+</span> voice_plan</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To fit the logistic regression model, we use the <code>glm()</code> function, which stands for <em>generalized linear model</em>. By setting <code>family = binomial</code>, we indicate that the response follows a binomial distribution with a logit link function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>glm_churn <span class="ot">=</span> <span class="fu">glm</span>(<span class="at">formula =</span> formula, <span class="at">data =</span> churn_mlc, <span class="at">family =</span> binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A summary of the fitted model can be obtained using:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_churn)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">glm</span>(<span class="at">formula =</span> formula, <span class="at">family =</span> binomial, <span class="at">data =</span> churn_mlc)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>                    Estimate Std. Error z value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>z<span class="sc">|</span>)    </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>   (Intercept)     <span class="fl">8.8917584</span>  <span class="fl">0.6582188</span>  <span class="fl">13.509</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>   account_length <span class="sc">-</span><span class="fl">0.0013811</span>  <span class="fl">0.0011453</span>  <span class="sc">-</span><span class="fl">1.206</span>   <span class="fl">0.2279</span>    </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>   voice_messages <span class="sc">-</span><span class="fl">0.0355317</span>  <span class="fl">0.0150397</span>  <span class="sc">-</span><span class="fl">2.363</span>   <span class="fl">0.0182</span> <span class="sc">*</span>  </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>   day_mins       <span class="sc">-</span><span class="fl">0.0136547</span>  <span class="fl">0.0009103</span> <span class="sc">-</span><span class="fl">15.000</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>   eve_mins       <span class="sc">-</span><span class="fl">0.0071210</span>  <span class="fl">0.0009419</span>  <span class="sc">-</span><span class="fl">7.561</span> <span class="fl">4.02e-14</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>   night_mins     <span class="sc">-</span><span class="fl">0.0040518</span>  <span class="fl">0.0009048</span>  <span class="sc">-</span><span class="fl">4.478</span> <span class="fl">7.53e-06</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>   intl_mins      <span class="sc">-</span><span class="fl">0.0882514</span>  <span class="fl">0.0170578</span>  <span class="sc">-</span><span class="fl">5.174</span> <span class="fl">2.30e-07</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>   customer_calls <span class="sc">-</span><span class="fl">0.5183958</span>  <span class="fl">0.0328652</span> <span class="sc">-</span><span class="fl">15.773</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>   intl_planno     <span class="fl">2.0958198</span>  <span class="fl">0.1214476</span>  <span class="fl">17.257</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>   voice_planno   <span class="sc">-</span><span class="fl">2.1637477</span>  <span class="fl">0.4836735</span>  <span class="sc">-</span><span class="fl">4.474</span> <span class="fl">7.69e-06</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>   (Dispersion parameter <span class="cf">for</span> binomial family taken to be <span class="dv">1</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>       Null deviance<span class="sc">:</span> <span class="fl">4075.0</span>  on <span class="dv">4999</span>  degrees of freedom</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>   Residual deviance<span class="sc">:</span> <span class="fl">3174.3</span>  on <span class="dv">4990</span>  degrees of freedom</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>   AIC<span class="sc">:</span> <span class="fl">3194.3</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>   Number of Fisher Scoring iterations<span class="sc">:</span> <span class="dv">6</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The output includes coefficient estimates that describe the effect of each predictor on the <em>log-odds of churn</em>, along with standard errors, <em>z</em>-statistics, and corresponding <em>p</em>-values. Predictors with small <em>p</em>-values (typically below 0.05) provide evidence of a statistically significant association with churn, while predictors with large <em>p</em>-values may contribute little to the model and could be candidates for removal.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Remove one or more predictors with large <em>p</em>-values (for example, <code>account_length</code>) and refit the model. Compare the coefficient estimates and statistical significance to those of the original model. What changes, and what remains stable?</p>
</blockquote>
<p>At this stage, we fit the logistic regression model using the full dataset. Unlike the classification examples in Chapter <a href="7-Classification-kNN.html" class="quarto-xref"><span>7</span></a>, our primary focus here is on understanding model specification and coefficient interpretation rather than evaluating out-of-sample predictive performance. Model validation and comparison will be addressed later in the chapter.</p>
<p>Note that we did not manually create dummy variables for the binary predictors <code>intl_plan</code> and <code>voice_plan</code>. When fitting a logistic regression model, R automatically converts factor variables into indicator variables, using the first factor level (alphabetically, by default) as the reference category.</p>
<p>As with linear regression models fitted using <code>lm()</code>, predictions from a logistic regression model are obtained using the <code>predict()</code> function. When <code>type = "response"</code> is specified, <code>predict()</code> returns predicted probabilities for the <em>non-reference class</em> of the response variable. The choice of reference category depends on the ordering of factor levels and can be explicitly controlled using the <code>relevel()</code> function. We examine how to interpret and evaluate these predicted probabilities in the following sections.</p>
</section>
</section>
<section id="poisson-regression-for-modeling-count-data" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="poisson-regression-for-modeling-count-data"><span class="header-section-number">10.7</span> Poisson Regression for Modeling Count Data</h2>
<p>Many data science problems involve outcomes that record <em>how many times</em> an event occurs within a fixed interval, rather than measuring a continuous quantity. Examples include the number of customer service calls in a month, the number of website visits per hour, or the number of products purchased by a customer. When the response variable represents such counts, Poisson regression provides a natural and principled modeling framework.</p>
<p>The Poisson distribution was introduced in the nineteenth century to describe the frequency of rare events. One of its most well-known early applications was by Ladislaus Bortkiewicz, who modeled the number of soldiers in the Prussian army fatally kicked by horses. Although unusual, this example demonstrated how a carefully chosen statistical model can reveal structure in seemingly random event counts.</p>
<p>Poisson regression builds on this idea by embedding the Poisson distribution within the generalized linear model framework. It is specifically designed for <em>count data</em>, where the response variable takes non-negative integer values and represents the number of events occurring in a fixed period or region. Common applications include modeling call volumes, transaction counts, and incident frequencies.</p>
<p>Unlike linear regression, which assumes normally distributed errors, Poisson regression assumes that the conditional distribution of the response variable follows a Poisson distribution, with the mean equal to the variance. This assumption makes the model particularly suitable for event counts, although it also highlights the need to check for potential overdispersion in practice.</p>
<p>As a generalized linear model, Poisson regression links the expected event count to a linear predictor using the natural logarithm: <span class="math display">\[
\ln(\lambda) = b_0 + b_1 x_1 + b_2 x_2 + \dots + b_m x_m,
\]</span> where <span class="math inline">\(\lambda\)</span> denotes the expected number of events. The log link ensures that predicted counts are always positive and allows multiplicative effects on the original scale to be modeled as additive effects on the log scale. In this formulation, each predictor influences the <em>rate</em> at which events are expected to occur.</p>
<p>In the next subsection, we fit a Poisson regression model in R using the <code>churn_mlc</code> dataset to investigate factors associated with customer service call frequency.</p>
<section id="fitting-a-poisson-regression-model-in-r" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="fitting-a-poisson-regression-model-in-r">Fitting a Poisson Regression Model in R</h3>
<p>We now fit a Poisson regression model to analyze customer service call frequency, a typical example of count data. The response variable <code>customer_calls</code> records how many times a customer contacted support, making Poisson regression more appropriate than linear regression. Because the response is a non-negative integer, modeling it within the generalized linear model framework allows us to respect both its distributional properties and its natural constraints.</p>
<p>We use the <code>churn_mlc</code> dataset and model the expected number of customer service calls as a function of customer characteristics and usage behavior. As with logistic regression, Poisson regression is fitted using the <code>glm()</code> function. The general syntax is:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(response_variable <span class="sc">~</span> predictor_variables, <span class="at">data =</span> dataset, <span class="at">family =</span> poisson)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here, <code>family = poisson</code> specifies that the response follows a Poisson distribution, implying that the conditional mean and variance are equal.</p>
<p>We fit the model as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>formula_calls <span class="ot">=</span> customer_calls <span class="sc">~</span> churn <span class="sc">+</span> voice_messages <span class="sc">+</span> day_mins <span class="sc">+</span> eve_mins <span class="sc">+</span> night_mins <span class="sc">+</span> intl_mins <span class="sc">+</span> intl_plan <span class="sc">+</span> voice_plan</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>reg_pois <span class="ot">=</span> <span class="fu">glm</span>(<span class="at">formula =</span> formula_calls, <span class="at">data =</span> churn_mlc, <span class="at">family =</span> poisson)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A summary of the fitted model is obtained using:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg_pois)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">glm</span>(<span class="at">formula =</span> formula_calls, <span class="at">family =</span> poisson, <span class="at">data =</span> churn_mlc)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>                    Estimate Std. Error z value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>z<span class="sc">|</span>)    </span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>   (Intercept)     <span class="fl">0.9957186</span>  <span class="fl">0.1323004</span>   <span class="fl">7.526</span> <span class="fl">5.22e-14</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>   churnno        <span class="sc">-</span><span class="fl">0.5160641</span>  <span class="fl">0.0304013</span> <span class="sc">-</span><span class="fl">16.975</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>   voice_messages  <span class="fl">0.0034062</span>  <span class="fl">0.0028294</span>   <span class="fl">1.204</span> <span class="fl">0.228646</span>    </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>   day_mins       <span class="sc">-</span><span class="fl">0.0006875</span>  <span class="fl">0.0002078</span>  <span class="sc">-</span><span class="fl">3.309</span> <span class="fl">0.000938</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>   eve_mins       <span class="sc">-</span><span class="fl">0.0005649</span>  <span class="fl">0.0002237</span>  <span class="sc">-</span><span class="fl">2.525</span> <span class="fl">0.011554</span> <span class="sc">*</span>  </span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>   night_mins     <span class="sc">-</span><span class="fl">0.0003602</span>  <span class="fl">0.0002245</span>  <span class="sc">-</span><span class="fl">1.604</span> <span class="fl">0.108704</span>    </span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>   intl_mins      <span class="sc">-</span><span class="fl">0.0075034</span>  <span class="fl">0.0040886</span>  <span class="sc">-</span><span class="fl">1.835</span> <span class="fl">0.066475</span> .  </span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>   intl_planno     <span class="fl">0.2085330</span>  <span class="fl">0.0407760</span>   <span class="fl">5.114</span> <span class="fl">3.15e-07</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>   voice_planno    <span class="fl">0.0735515</span>  <span class="fl">0.0878175</span>   <span class="fl">0.838</span> <span class="fl">0.402284</span>    </span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>   (Dispersion parameter <span class="cf">for</span> poisson family taken to be <span class="dv">1</span>)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>       Null deviance<span class="sc">:</span> <span class="fl">5991.1</span>  on <span class="dv">4999</span>  degrees of freedom</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>   Residual deviance<span class="sc">:</span> <span class="fl">5719.5</span>  on <span class="dv">4991</span>  degrees of freedom</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>   AIC<span class="sc">:</span> <span class="dv">15592</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>   Number of Fisher Scoring iterations<span class="sc">:</span> <span class="dv">5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The output reports coefficient estimates, standard errors, <em>z</em>-statistics, and <em>p</em>-values. Each coefficient represents the effect of a predictor on the <em>log of the expected number of customer service calls</em>. Predictors with small <em>p</em>-values provide evidence of a statistically significant association with call frequency, while predictors with large <em>p</em>-values may contribute little explanatory value.</p>
<p>Unlike linear regression, Poisson regression coefficients are interpreted on a multiplicative scale. A one-unit increase in a predictor multiplies the expected count by <span class="math inline">\(e^{b}\)</span>, where <span class="math inline">\(b\)</span> is the corresponding coefficient. For example, if the coefficient for <code>intl_plan</code> is 0.3, then <span class="math display">\[
e^{0.3} - 1 \approx 0.35,
\]</span> indicating that customers with an international plan are expected to make approximately 35% more service calls than those without one, holding all other variables constant.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Suppose a predictor has a coefficient of <span class="math inline">\(-0.2\)</span>. Compute <span class="math inline">\(e^{-0.2} - 1\)</span> and interpret the result as a percentage change in the expected number of service calls.</p>
</blockquote>
<p>One important modeling assumption in Poisson regression is that the variance of the response equals its mean. When the variance is substantially larger, a phenomenon known as <em>overdispersion</em>, the standard Poisson model may underestimate uncertainty. In such cases, alternatives such as quasi-Poisson or negative binomial regression are often more appropriate. Although we do not explore these extensions in detail here, they are commonly used in applied count data analysis.</p>
<p>As with other generalized linear models, predictions from a Poisson regression model can be obtained using the <code>predict()</code> function. These predictions represent expected event counts and are useful for estimating call volumes for new customer profiles.</p>
<p>Poisson regression thus extends the regression framework to outcomes involving event frequencies, providing an interpretable and statistically principled approach to modeling count data.</p>
</section>
</section>
<section id="sec-ch10-stepwise" class="level2" data-number="10.8">
<h2 data-number="10.8" class="anchored" data-anchor-id="sec-ch10-stepwise"><span class="header-section-number">10.8</span> Stepwise Regression for Predictor Selection</h2>
<p>An important practical question in regression modeling is deciding which predictors to include in the model. Including too few variables may omit important relationships, while including too many can lead to overfitting, reduced interpretability, and poor generalization to new data. Effective predictor selection is therefore essential for building regression models that are both informative and reliable.</p>
<p>This process, often referred to as <em>model specification</em> or <em>feature selection</em>, aims to balance explanatory power with simplicity. A well-specified model captures the key drivers of the response variable without being unnecessarily complex. Achieving this balance becomes increasingly challenging in real-world datasets, where analysts are often confronted with a large number of potential predictors.</p>
<p><em>Stepwise regression</em> is one commonly used approach for addressing this challenge. It is an iterative, algorithmic procedure that adds or removes predictors one at a time based on their contribution to model quality, as measured by statistical criteria. Rather than relying solely on subjective judgment, stepwise regression provides a systematic way to explore subsets of predictors and assess their relevance.</p>
<p>This approach builds naturally on earlier stages of the data science workflow. In Chapter <a href="4-Exploratory-data-analysis.html" class="quarto-xref"><span>4</span></a>, exploratory analysis helped identify promising relationships among variables. In Chapter <a href="5-Statistics.html" class="quarto-xref"><span>5</span></a>, formal hypothesis tests quantified these associations. Stepwise regression extends these ideas by automating predictor selection using model-based evaluation metrics.</p>
<p>Stepwise methods are particularly useful for small to medium-sized datasets, where exhaustive search over all possible predictor combinations is impractical but computational efficiency remains important. In the following subsections, we demonstrate how to perform stepwise regression in R, introduce model selection criteria such as the Akaike Information Criterion (AIC), and discuss both the advantages and limitations of this approach.</p>
<section id="how-aic-guides-model-selection" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="how-aic-guides-model-selection">How AIC Guides Model Selection</h3>
<p>When comparing competing regression models, we need a principled way to decide whether a simpler model is preferable to a more complex one. Model selection criteria address this challenge by balancing goodness of fit against model complexity, discouraging the inclusion of predictors that offer little explanatory value.</p>
<p>One widely used criterion is the <em>Akaike Information Criterion (AIC)</em>. AIC evaluates models based on a trade-off between fit and complexity, with lower values indicating a more favorable balance. For linear regression models, AIC can be expressed as <span class="math display">\[
AIC = 2m + n \log\left(\frac{SSE}{n}\right),
\]</span> where <span class="math inline">\(m\)</span> denotes the number of estimated parameters in the model, <span class="math inline">\(n\)</span> is the number of observations, and <span class="math inline">\(SSE\)</span> is the sum of squared errors (introduced in <a href="#eq-sse" class="quarto-xref">Equation&nbsp;<span>10.1</span></a>), which measures the unexplained variability in the response variable.</p>
<p>Unlike <span class="math inline">\(R^2\)</span>, which increases whenever additional predictors are added, AIC explicitly penalizes model complexity through the term <span class="math inline">\(2m\)</span>. This penalty helps guard against overfitting by favoring models that achieve a good fit using as few parameters as possible. Importantly, AIC is a <em>relative</em> measure: it is meaningful only when comparing models fitted to the same dataset, and the model with the smallest AIC is preferred among the candidates under consideration.</p>
<p>An alternative criterion is the <em>Bayesian Information Criterion (BIC)</em>, defined as <span class="math display">\[
BIC = \log(n)\, m + n \log\left(\frac{SSE}{n}\right),
\]</span> where the notation is the same as above. Compared to AIC, BIC imposes a stronger penalty for model complexity, particularly as the sample size <span class="math inline">\(n\)</span> increases. As a result, BIC tends to favor more parsimonious models and is often used when the primary goal is identifying a simpler underlying structure rather than maximizing predictive accuracy.</p>
<p>Both AIC and BIC embody the same fundamental principle: model selection should balance explanatory power with simplicity. In this chapter, we focus on AIC, which is the default criterion used by the <code>step()</code> function in R. In the next subsection, we demonstrate how AIC is applied in practice to guide stepwise regression.</p>
</section>
<section id="stepwise-regression-in-practice-using-step-in-r" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="stepwise-regression-in-practice-using-step-in-r">Stepwise Regression in Practice: Using <code>step()</code> in R</h3>
<p>After introducing model selection criteria such as AIC, we now apply them in practice using stepwise regression. In R, the <code>step()</code> function (part of base R) automates predictor selection by iteratively adding or removing variables to improve the AIC score. The function operates on an already fitted model object, such as one produced by <code>lm()</code> or <code>glm()</code>. Its general syntax is:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(object, <span class="at">direction =</span> <span class="fu">c</span>(<span class="st">"both"</span>, <span class="st">"backward"</span>, <span class="st">"forward"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>where <code>object</code> is a model of class <code>"lm"</code> or <code>"glm"</code>. The <code>direction</code> argument specifies the selection strategy. Forward selection (<code>direction = "forward"</code>) starts from a minimal model and adds predictors, backward elimination (<code>direction = "backward"</code>) begins with a full model and removes predictors, and <code>"both"</code> allows movement in either direction.</p>
<p>To illustrate the procedure, we return to the <code>marketing</code> dataset, which contains several potentially correlated predictors of <code>revenue</code>. Our goal is to identify a parsimonious and interpretable regression model.</p>
<p>We begin by fitting a full linear regression model that includes all available predictors:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(marketing, <span class="at">package =</span> <span class="st">"liver"</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">=</span> <span class="fu">lm</span>(revenue <span class="sc">~</span> ., <span class="at">data =</span> marketing)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(full_model)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> revenue <span class="sc">~</span> ., <span class="at">data =</span> marketing)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>       Min      <span class="dv">1</span>Q  Median      <span class="dv">3</span>Q     Max </span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">138.00</span>  <span class="sc">-</span><span class="fl">59.12</span>   <span class="fl">15.16</span>   <span class="fl">54.58</span>  <span class="fl">106.99</span> </span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>                     Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>   (Intercept)     <span class="sc">-</span><span class="fl">25.260020</span> <span class="fl">246.988978</span>  <span class="sc">-</span><span class="fl">0.102</span>    <span class="fl">0.919</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>   spend            <span class="sc">-</span><span class="fl">0.025807</span>   <span class="fl">2.605645</span>  <span class="sc">-</span><span class="fl">0.010</span>    <span class="fl">0.992</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>   clicks            <span class="fl">1.211912</span>   <span class="fl">1.630953</span>   <span class="fl">0.743</span>    <span class="fl">0.463</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>   impressions      <span class="sc">-</span><span class="fl">0.005308</span>   <span class="fl">0.021588</span>  <span class="sc">-</span><span class="fl">0.246</span>    <span class="fl">0.807</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>   display          <span class="fl">79.835729</span> <span class="fl">117.558849</span>   <span class="fl">0.679</span>    <span class="fl">0.502</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>   transactions     <span class="sc">-</span><span class="fl">7.012069</span>  <span class="fl">66.383251</span>  <span class="sc">-</span><span class="fl">0.106</span>    <span class="fl">0.917</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>   click_rate      <span class="sc">-</span><span class="fl">10.951493</span> <span class="fl">106.833894</span>  <span class="sc">-</span><span class="fl">0.103</span>    <span class="fl">0.919</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>   conversion_rate  <span class="fl">19.926588</span> <span class="fl">135.746632</span>   <span class="fl">0.147</span>    <span class="fl">0.884</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">77.61</span> on <span class="dv">32</span> degrees of freedom</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7829</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7354</span> </span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">16.48</span> on <span class="dv">7</span> and <span class="dv">32</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">5.498e-09</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Although the full model incorporates all predictors, many coefficient estimates exhibit large <em>p</em>-values. For example, the <em>p</em>-value associated with <code>spend</code> is 0.992. This does not necessarily imply that the predictors are irrelevant, but rather that their <em>individual</em> effects are difficult to disentangle when several variables convey overlapping information.</p>
<p>Such behavior is commonly associated with <em>multicollinearity</em>, a situation in which predictors are strongly correlated with one another. Multicollinearity inflates standard errors and complicates coefficient interpretation, even when the model as a whole explains a substantial proportion of the variability in the response. Importantly, while multicollinearity does not bias coefficient estimates, it can obscure which predictors are most informative.</p>
<p>This motivates the use of automated model selection techniques. We apply stepwise regression using AIC as the selection criterion and allowing both forward and backward moves:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>stepwise_model <span class="ot">=</span> <span class="fu">step</span>(full_model, <span class="at">direction =</span> <span class="st">"both"</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>   Start<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">355.21</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>   revenue <span class="sc">~</span> spend <span class="sc">+</span> clicks <span class="sc">+</span> impressions <span class="sc">+</span> display <span class="sc">+</span> transactions <span class="sc">+</span> </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>       click_rate <span class="sc">+</span> conversion_rate</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                     Df Sum of Sq    RSS    AIC</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> spend            <span class="dv">1</span>       <span class="fl">0.6</span> <span class="dv">192760</span> <span class="fl">353.21</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> click_rate       <span class="dv">1</span>      <span class="fl">63.3</span> <span class="dv">192822</span> <span class="fl">353.23</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> transactions     <span class="dv">1</span>      <span class="fl">67.2</span> <span class="dv">192826</span> <span class="fl">353.23</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> conversion_rate  <span class="dv">1</span>     <span class="fl">129.8</span> <span class="dv">192889</span> <span class="fl">353.24</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> impressions      <span class="dv">1</span>     <span class="fl">364.2</span> <span class="dv">193123</span> <span class="fl">353.29</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> display          <span class="dv">1</span>    <span class="fl">2778.1</span> <span class="dv">195537</span> <span class="fl">353.79</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> clicks           <span class="dv">1</span>    <span class="fl">3326.0</span> <span class="dv">196085</span> <span class="fl">353.90</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>   <span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="dv">192759</span> <span class="fl">355.21</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>   Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">353.21</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>   revenue <span class="sc">~</span> clicks <span class="sc">+</span> impressions <span class="sc">+</span> display <span class="sc">+</span> transactions <span class="sc">+</span> click_rate <span class="sc">+</span> </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>       conversion_rate</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>                     Df Sum of Sq    RSS    AIC</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> click_rate       <span class="dv">1</span>      <span class="fl">67.9</span> <span class="dv">192828</span> <span class="fl">351.23</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> transactions     <span class="dv">1</span>      <span class="fl">75.1</span> <span class="dv">192835</span> <span class="fl">351.23</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> conversion_rate  <span class="dv">1</span>     <span class="fl">151.5</span> <span class="dv">192911</span> <span class="fl">351.24</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> impressions      <span class="dv">1</span>     <span class="fl">380.8</span> <span class="dv">193141</span> <span class="fl">351.29</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> display          <span class="dv">1</span>    <span class="fl">2787.2</span> <span class="dv">195547</span> <span class="fl">351.79</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> clicks           <span class="dv">1</span>    <span class="fl">3325.6</span> <span class="dv">196085</span> <span class="fl">351.90</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>   <span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="dv">192760</span> <span class="fl">353.21</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> spend            <span class="dv">1</span>       <span class="fl">0.6</span> <span class="dv">192759</span> <span class="fl">355.21</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>   Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">351.23</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>   revenue <span class="sc">~</span> clicks <span class="sc">+</span> impressions <span class="sc">+</span> display <span class="sc">+</span> transactions <span class="sc">+</span> conversion_rate</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>                     Df Sum of Sq    RSS    AIC</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> transactions     <span class="dv">1</span>      <span class="fl">47.4</span> <span class="dv">192875</span> <span class="fl">349.24</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> conversion_rate  <span class="dv">1</span>     <span class="fl">129.0</span> <span class="dv">192957</span> <span class="fl">349.25</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> impressions      <span class="dv">1</span>     <span class="fl">312.9</span> <span class="dv">193141</span> <span class="fl">349.29</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> clicks           <span class="dv">1</span>    <span class="fl">3425.7</span> <span class="dv">196253</span> <span class="fl">349.93</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> display          <span class="dv">1</span>    <span class="fl">3747.1</span> <span class="dv">196575</span> <span class="fl">350.00</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>   <span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="dv">192828</span> <span class="fl">351.23</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> click_rate       <span class="dv">1</span>      <span class="fl">67.9</span> <span class="dv">192760</span> <span class="fl">353.21</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> spend            <span class="dv">1</span>       <span class="fl">5.2</span> <span class="dv">192822</span> <span class="fl">353.23</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>   Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">349.24</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>   revenue <span class="sc">~</span> clicks <span class="sc">+</span> impressions <span class="sc">+</span> display <span class="sc">+</span> conversion_rate</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>                     Df Sum of Sq    RSS    AIC</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> conversion_rate  <span class="dv">1</span>      <span class="fl">89.6</span> <span class="dv">192965</span> <span class="fl">347.26</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> impressions      <span class="dv">1</span>     <span class="fl">480.9</span> <span class="dv">193356</span> <span class="fl">347.34</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> display          <span class="dv">1</span>    <span class="fl">5437.2</span> <span class="dv">198312</span> <span class="fl">348.35</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>   <span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="dv">192875</span> <span class="fl">349.24</span></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> transactions     <span class="dv">1</span>      <span class="fl">47.4</span> <span class="dv">192828</span> <span class="fl">351.23</span></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> click_rate       <span class="dv">1</span>      <span class="fl">40.2</span> <span class="dv">192835</span> <span class="fl">351.23</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> spend            <span class="dv">1</span>      <span class="fl">13.6</span> <span class="dv">192861</span> <span class="fl">351.23</span></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> clicks           <span class="dv">1</span>   <span class="fl">30863.2</span> <span class="dv">223738</span> <span class="fl">353.17</span></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>   Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">347.26</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>   revenue <span class="sc">~</span> clicks <span class="sc">+</span> impressions <span class="sc">+</span> display</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>                     Df Sum of Sq    RSS    AIC</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> impressions      <span class="dv">1</span>       <span class="dv">399</span> <span class="dv">193364</span> <span class="fl">345.34</span></span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>   <span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="dv">192965</span> <span class="fl">347.26</span></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> display          <span class="dv">1</span>     <span class="dv">14392</span> <span class="dv">207357</span> <span class="fl">348.13</span></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> conversion_rate  <span class="dv">1</span>        <span class="dv">90</span> <span class="dv">192875</span> <span class="fl">349.24</span></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> click_rate       <span class="dv">1</span>        <span class="dv">52</span> <span class="dv">192913</span> <span class="fl">349.24</span></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> spend            <span class="dv">1</span>        <span class="dv">33</span> <span class="dv">192932</span> <span class="fl">349.25</span></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> transactions     <span class="dv">1</span>         <span class="dv">8</span> <span class="dv">192957</span> <span class="fl">349.25</span></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> clicks           <span class="dv">1</span>     <span class="dv">35038</span> <span class="dv">228002</span> <span class="fl">351.93</span></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>   Step<span class="sc">:</span>  AIC<span class="ot">=</span><span class="fl">345.34</span></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>   revenue <span class="sc">~</span> clicks <span class="sc">+</span> display</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>                     Df Sum of Sq    RSS    AIC</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>   <span class="sc">&lt;</span>none<span class="sc">&gt;</span>                         <span class="dv">193364</span> <span class="fl">345.34</span></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> impressions      <span class="dv">1</span>       <span class="dv">399</span> <span class="dv">192965</span> <span class="fl">347.26</span></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> transactions     <span class="dv">1</span>       <span class="dv">215</span> <span class="dv">193149</span> <span class="fl">347.29</span></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> conversion_rate  <span class="dv">1</span>         <span class="dv">8</span> <span class="dv">193356</span> <span class="fl">347.34</span></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> click_rate       <span class="dv">1</span>         <span class="dv">6</span> <span class="dv">193358</span> <span class="fl">347.34</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>   <span class="sc">+</span> spend            <span class="dv">1</span>         <span class="dv">2</span> <span class="dv">193362</span> <span class="fl">347.34</span></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> display          <span class="dv">1</span>     <span class="dv">91225</span> <span class="dv">284589</span> <span class="fl">358.80</span></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span> clicks           <span class="dv">1</span>    <span class="dv">606800</span> <span class="dv">800164</span> <span class="fl">400.15</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The algorithm evaluates alternative models by adding or removing predictors, retaining changes only when they reduce the AIC. This process continues until no further improvement is possible. Across iterations, AIC decreases from an initial value of 355.21 for the full model to 345.34 for the final selected model, indicating a more favorable balance between fit and complexity.</p>
<p>We examine the resulting model using:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stepwise_model)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> revenue <span class="sc">~</span> clicks <span class="sc">+</span> display, <span class="at">data =</span> marketing)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>       Min      <span class="dv">1</span>Q  Median      <span class="dv">3</span>Q     Max </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">141.89</span>  <span class="sc">-</span><span class="fl">55.92</span>   <span class="fl">16.44</span>   <span class="fl">52.70</span>  <span class="fl">115.46</span> </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>                Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>   (Intercept) <span class="sc">-</span><span class="fl">33.63248</span>   <span class="fl">28.68893</span>  <span class="sc">-</span><span class="fl">1.172</span> <span class="fl">0.248564</span>    </span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>   clicks        <span class="fl">0.89517</span>    <span class="fl">0.08308</span>  <span class="fl">10.775</span> <span class="fl">5.76e-13</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>   display      <span class="fl">95.51462</span>   <span class="fl">22.86126</span>   <span class="fl">4.178</span> <span class="fl">0.000172</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">72.29</span> on <span class="dv">37</span> degrees of freedom</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7822</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7704</span> </span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">66.44</span> on <span class="dv">2</span> and <span class="dv">37</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">5.682e-13</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The stepwise procedure selects a reduced model containing two predictors, <code>clicks</code> and <code>display</code>, yielding the regression equation <span class="math display">\[
\widehat{\text{revenue}} =
-33.63 +
0.9 \times \text{clicks} +
95.51 \times \text{display}.
\]</span></p>
<p>Compared to the full model, this reduced model achieves a lower residual standard error, decreasing from 77.61 to 72.29, and a higher Adjusted <span class="math inline">\(R^2\)</span>, increasing from 73.5% to 77%. These changes indicate an improvement in both predictive efficiency and interpretability.</p>
<p>Stepwise regression thus provides a practical tool for navigating predictor selection in the presence of correlated variables. However, it remains a heuristic approach and should be complemented with subject-matter knowledge, diagnostic checks, and validation whenever possible.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Apply stepwise regression using <code>"forward"</code> and <code>"backward"</code> selection instead of <code>"both"</code>. Do all approaches lead to the same final model? How do their AIC values compare?</p>
</blockquote>
</section>
<section id="considerations-for-stepwise-regression" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="considerations-for-stepwise-regression">Considerations for Stepwise Regression</h3>
<p>Stepwise regression provides a structured and computationally efficient approach to predictor selection. By iteratively adding or removing variables based on a model selection criterion, it offers a practical alternative to exhaustive subset search, particularly for moderate-sized datasets. When used appropriately, it can yield simpler and more interpretable models.</p>
<p>At the same time, stepwise regression has important limitations that must be kept in mind. Because the procedure evaluates predictors sequentially rather than jointly, it may overlook combinations of variables or interaction effects that improve model performance only when considered together. The method is also sensitive to sampling variability: small changes in the data can lead to different selected models. Moreover, when many predictors are available relative to the sample size, stepwise regression can contribute to overfitting, capturing random noise rather than stable relationships. Multicollinearity among predictors further complicates interpretation by inflating standard errors and obscuring individual effects.</p>
<p>In settings with many predictors or complex dependency structures, regularization methods such as <em>LASSO</em> (Least Absolute Shrinkage and Selection Operator) and <em>Ridge Regression</em> are often preferable. These approaches shrink coefficient estimates toward zero through explicit penalty terms, leading to more stable models and improved predictive performance. A comprehensive introduction to these techniques is provided in <em>An Introduction to Statistical Learning with Applications in R</em> <span class="citation" data-cites="gareth2013introduction">(<a href="14-References.html#ref-gareth2013introduction" role="doc-biblioref">Gareth et al. 2013</a>)</span>.</p>
<p>Ultimately, predictor selection should be guided by a combination of statistical criteria, domain knowledge, and validation on representative data. While stepwise regression should not be viewed as a definitive solution to model selection, it remains a useful exploratory tool when applied with care and a clear understanding of its assumptions and limitations.</p>
</section>
</section>
<section id="modeling-non-linear-relationships" class="level2" data-number="10.9">
<h2 data-number="10.9" class="anchored" data-anchor-id="modeling-non-linear-relationships"><span class="header-section-number">10.9</span> Modeling Non-Linear Relationships</h2>
<p>Many real-world relationships are not well described by straight lines. Consider predicting house prices using the age of a property. Prices may decline as a house ages, but very old or historic homes can command a premium. Such patterns exhibit curvature rather than a constant rate of change, yet standard linear regression assumes exactly that: a linear relationship between predictors and the response.</p>
<p>Linear regression remains a powerful and widely used modeling tool due to its simplicity and interpretability. When relationships are approximately linear, it performs well and yields easily interpretable results. However, when the underlying association is non-linear, a linear model may fail to capture important structure in the data, leading to systematic prediction errors and misleading conclusions.</p>
<p>Earlier in this chapter, we used stepwise regression (Section <a href="#sec-ch10-stepwise" class="quarto-xref"><span>10.8</span></a>) to refine model specification by selecting a subset of relevant predictors. While this approach helps determine <em>which</em> variables to include, it does not address <em>how</em> those variables relate to the outcome. Stepwise regression assumes linear effects and therefore cannot accommodate curvature or other non-linear patterns.</p>
<p>To model such relationships while retaining the familiar regression framework, we turn to <em>polynomial regression</em>. This approach extends linear regression by transforming predictors to allow non-linear trends to be captured, without sacrificing interpretability or requiring fundamentally new modeling machinery.</p>
<section id="the-need-for-non-linear-regression" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="the-need-for-non-linear-regression">The Need for Non-Linear Regression</h3>
<p>Linear regression assumes a constant rate of change between a predictor and the response, represented by a straight line. In practice, however, many real-world relationships exhibit curvature. This is illustrated in <a href="#fig-scatter-plot-non-reg" class="quarto-xref">Figure&nbsp;<span>10.5</span></a>, which shows the relationship between <code>unit_price</code> (price per unit area) and <code>house_age</code> in the <em>house</em> dataset. The dashed orange line corresponds to a simple linear regression fit, which clearly fails to capture the curved pattern in the data.</p>
<p>From the plot, we see that the linear model tends to underestimate prices for very new homes and overestimate prices for older ones. These systematic deviations indicate that the assumption of linearity is violated and that a more flexible model is needed.</p>
<p>One way to address this limitation is to introduce non-linear transformations of the predictor while retaining the linear regression framework. If the relationship follows a curved pattern, a quadratic model may be appropriate: <span class="math display">\[
\mathrm{unit\_price} = b_0 + b_1 \times \mathrm{house\_age} + b_2 \times \mathrm{house\_age}^2.
\]</span></p>
<p>This model includes both the original predictor and its squared term, allowing the fitted relationship to bend and adapt to the data. Although the relationship between <code>house_age</code> and <code>unit_price</code> is now non-linear, the model remains a <em>linear regression model</em> because it is linear in the parameters (<span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, and <span class="math inline">\(b_2\)</span>). As a result, the coefficients can still be estimated using ordinary least squares.</p>
<p>The blue curve in <a href="#fig-scatter-plot-non-reg" class="quarto-xref">Figure&nbsp;<span>10.5</span></a> shows the fitted quadratic regression model. Compared to the straight-line fit, it follows the observed curvature more closely, leading to a visually and substantively improved representation of the data.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-scatter-plot-non-reg" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" data-fig-pos="H">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scatter-plot-non-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-scatter-plot-non-reg-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" data-fig-pos="H">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatter-plot-non-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.5: Scatter plot of house price ($) versus house age (years) for the house dataset, with the fitted simple linear regression line in dashed orange and the quadratic regression curve in blue.
</figcaption>
</figure>
</div>
</div>
</div>
<p>This example illustrates why adapting model structure is essential when the linearity assumption does not hold. Polynomial regression expands the range of relationships we can model while preserving interpretability and analytical tractability.</p>
<p>It is important to emphasize that, despite modeling curved relationships, polynomial regression models are still linear models in a statistical sense because they are linear in their parameters. Consequently, familiar tools such as least squares estimation and information criteria like AIC remain applicable.</p>
<p>Having established the motivation for non-linear regression, we now turn to the practical implementation of polynomial regression in R. In the next section, we fit polynomial models, interpret their coefficients, and compare their performance to simpler linear alternatives.</p>
</section>
</section>
<section id="polynomial-regression-in-practice" class="level2" data-number="10.10">
<h2 data-number="10.10" class="anchored" data-anchor-id="polynomial-regression-in-practice"><span class="header-section-number">10.10</span> Polynomial Regression in Practice</h2>
<p>Polynomial regression extends linear regression by augmenting predictors with higher-degree terms, such as squared (<span class="math inline">\(x^2\)</span>) or cubic (<span class="math inline">\(x^3\)</span>) components. This added flexibility allows the model to capture curved relationships while remaining <em>linear in the coefficients</em>, so estimation can still be carried out using ordinary least squares. A polynomial regression model of degree <span class="math inline">\(d\)</span> takes the general form <span class="math display">\[
\hat{y} = b_0 + b_1 x + b_2 x^2 + \dots + b_d x^d.
\]</span> Although higher-degree polynomials increase flexibility, choosing an excessively large degree can lead to overfitting, particularly near the boundaries of the predictor range. In practice, low-degree polynomials are often sufficient to capture meaningful curvature.</p>
<p>To illustrate polynomial regression in practice, we use the <em>house</em> dataset from the <strong>liver</strong> package. This dataset contains information on housing prices and related features, including the age of the property. Our objective is to model <code>unit_price</code> (price per unit area) as a function of <code>house_age</code> and to compare a simple linear model with a polynomial alternative.</p>
<p>We begin by loading the dataset and inspecting its structure:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(house)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(house)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">414</span> obs. of  <span class="dv">6</span> variables<span class="sc">:</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    <span class="er">$</span> house_age      <span class="sc">:</span> num  <span class="dv">32</span> <span class="fl">19.5</span> <span class="fl">13.3</span> <span class="fl">13.3</span> <span class="dv">5</span> <span class="fl">7.1</span> <span class="fl">34.5</span> <span class="fl">20.3</span> <span class="fl">31.7</span> <span class="fl">17.9</span> ...</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> distance_to_MRT<span class="sc">:</span> num  <span class="fl">84.9</span> <span class="fl">306.6</span> <span class="dv">562</span> <span class="dv">562</span> <span class="fl">390.6</span> ...</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> stores_number  <span class="sc">:</span> int  <span class="dv">10</span> <span class="dv">9</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">7</span> <span class="dv">6</span> <span class="dv">1</span> <span class="dv">3</span> ...</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> latitude       <span class="sc">:</span> num  <span class="dv">25</span> <span class="dv">25</span> <span class="dv">25</span> <span class="dv">25</span> <span class="dv">25</span> ...</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> longitude      <span class="sc">:</span> num  <span class="dv">122</span> <span class="dv">122</span> <span class="dv">122</span> <span class="dv">122</span> <span class="dv">122</span> ...</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> unit_price     <span class="sc">:</span> num  <span class="fl">37.9</span> <span class="fl">42.2</span> <span class="fl">47.3</span> <span class="fl">54.8</span> <span class="fl">43.1</span> <span class="fl">32.1</span> <span class="fl">40.3</span> <span class="fl">46.7</span> <span class="fl">18.8</span> <span class="fl">22.1</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset contains 414 observations and 6 variables. The response variable is <code>unit_price</code>, and the available predictors include <code>house_age</code>, <code>distance_to_MRT</code>, <code>stores_number</code>, <code>latitude</code>, and <code>longitude</code>.</p>
<p>As a baseline, we first fit a simple linear regression model relating <code>unit_price</code> to <code>house_age</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>simple_reg_house <span class="ot">=</span> <span class="fu">lm</span>(unit_price <span class="sc">~</span> house_age, <span class="at">data =</span> house)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_reg_house)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> unit_price <span class="sc">~</span> house_age, <span class="at">data =</span> house)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>       Min      <span class="dv">1</span>Q  Median      <span class="dv">3</span>Q     Max </span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">31.113</span> <span class="sc">-</span><span class="fl">10.738</span>   <span class="fl">1.626</span>   <span class="fl">8.199</span>  <span class="fl">77.781</span> </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>               Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>   (Intercept) <span class="fl">42.43470</span>    <span class="fl">1.21098</span>  <span class="fl">35.042</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>   house_age   <span class="sc">-</span><span class="fl">0.25149</span>    <span class="fl">0.05752</span>  <span class="sc">-</span><span class="fl">4.372</span> <span class="fl">1.56e-05</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">13.32</span> on <span class="dv">412</span> degrees of freedom</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.04434</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.04202</span> </span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">19.11</span> on <span class="dv">1</span> and <span class="dv">412</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">1.56e-05</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The coefficient of determination for this model is <span class="math inline">\(R^2 =\)</span> 0.04, indicating that approximately 4.43% of the variability in housing prices is explained by a linear effect of house age. This relatively modest value suggests that a straight-line relationship may not adequately capture the underlying pattern.</p>
<p>We next fit a quadratic polynomial regression model to allow for curvature: <span class="math display">\[
\mathrm{unit_price} = b_0 + b_1,\mathrm{house_age} + b_2,\mathrm{house_age}^2.
\]</span></p>
<p>In R, this can be implemented using the <code>poly()</code> function, which fits orthogonal polynomials by default. Orthogonal polynomials improve numerical stability but yield coefficients that are less directly interpretable than raw polynomial terms:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>reg_nonlinear_house <span class="ot">=</span> <span class="fu">lm</span>(unit_price <span class="sc">~</span> <span class="fu">poly</span>(house_age, <span class="dv">2</span>), <span class="at">data =</span> house)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg_nonlinear_house)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>   Call<span class="sc">:</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(<span class="at">formula =</span> unit_price <span class="sc">~</span> <span class="fu">poly</span>(house_age, <span class="dv">2</span>), <span class="at">data =</span> house)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>   Residuals<span class="sc">:</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>       Min      <span class="dv">1</span>Q  Median      <span class="dv">3</span>Q     Max </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span><span class="fl">26.542</span>  <span class="sc">-</span><span class="fl">9.085</span>  <span class="sc">-</span><span class="fl">0.445</span>   <span class="fl">8.260</span>  <span class="fl">79.961</span> </span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>   Coefficients<span class="sc">:</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>                       Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>   (Intercept)           <span class="fl">37.980</span>      <span class="fl">0.599</span>  <span class="fl">63.406</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>   <span class="fu">poly</span>(house_age, <span class="dv">2</span>)<span class="dv">1</span>  <span class="sc">-</span><span class="fl">58.225</span>     <span class="fl">12.188</span>  <span class="sc">-</span><span class="fl">4.777</span> <span class="fl">2.48e-06</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>   <span class="fu">poly</span>(house_age, <span class="dv">2</span>)<span class="dv">2</span>  <span class="fl">109.635</span>     <span class="fl">12.188</span>   <span class="fl">8.995</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>   Residual standard error<span class="sc">:</span> <span class="fl">12.19</span> on <span class="dv">411</span> degrees of freedom</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>   Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.2015</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.1977</span> </span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>   F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">51.87</span> on <span class="dv">2</span> and <span class="dv">411</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="er">&lt;</span> <span class="fl">2.2e-16</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The quadratic model achieves a higher Adjusted <span class="math inline">\(R^2\)</span> of 0.2 and a lower residual standard error, decreasing from 13.32 to 12.19. Together, these improvements indicate that allowing for curvature leads to a better balance between model fit and complexity.</p>
<p>Polynomial regression thus offers a natural extension of linear regression when non-linear patterns are present. At the same time, careful selection of the polynomial degree remains essential to avoid overfitting. More flexible approaches, such as splines and generalized additive models, provide additional control over model complexity and are discussed in Chapter 7 of <em>An Introduction to Statistical Learning with Applications in R</em> <span class="citation" data-cites="gareth2013introduction">(<a href="14-References.html#ref-gareth2013introduction" role="doc-biblioref">Gareth et al. 2013</a>)</span>.</p>
<p>In the following sections, we turn to diagnostic and validation techniques that help assess the reliability of regression models and guide further refinement.</p>
</section>
<section id="diagnosing-and-validating-regression-models" class="level2" data-number="10.11">
<h2 data-number="10.11" class="anchored" data-anchor-id="diagnosing-and-validating-regression-models"><span class="header-section-number">10.11</span> Diagnosing and Validating Regression Models</h2>
<p>Before relying on a regression model for inference or prediction, it is essential to assess whether its underlying assumptions are reasonably satisfied. Ignoring these assumptions can undermine the validity of coefficient estimates, confidence intervals, and predictions. Model diagnostics provide a systematic way to evaluate whether a fitted model is appropriate for the data at hand.</p>
<p>Linear regression relies on several key assumptions:</p>
<ol type="1">
<li><p><em>Linearity</em>: The relationship between the predictor(s) and the response is approximately linear. This is typically assessed using residuals versus fitted value plots.</p></li>
<li><p><em>Independence</em>: Observations are independent of one another, meaning that the outcome for one case does not influence another. This assumption is usually justified by the study design rather than diagnostic plots.</p></li>
<li><p><em>Normality</em>: The residuals follow an approximately normal distribution, which is commonly checked using a normal Q–Q plot.</p></li>
<li><p><em>Constant Variance (Homoscedasticity)</em>: The residuals have roughly constant variance across the range of fitted values. Residuals versus fitted plots and scale–location plots are useful for assessing this condition.</p></li>
</ol>
<p>Violations of these assumptions can compromise both inference and prediction. Even models with strong overall fit, such as a high <span class="math inline">\(R^2\)</span>, may be unreliable if key assumptions are not met.</p>
<p>To illustrate regression diagnostics in practice, we examine the multiple regression model introduced in Section <a href="#sec-ch10-stepwise" class="quarto-xref"><span>10.8</span></a>, fitted to the <code>marketing</code> dataset. This model predicts daily revenue (<code>revenue</code>) using <code>clicks</code> and <code>display</code> as predictors. The standard diagnostic plots for this model are generated as follows:</p>
<div class="cell" data-layout-nrow="2" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>stepwise_model <span class="ot">=</span> <span class="fu">lm</span>(revenue <span class="sc">~</span> clicks <span class="sc">+</span> display, <span class="at">data =</span> marketing)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(stepwise_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch10-model-diagnostics" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ch10-model-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch10-model-diagnostics" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch10-model-diagnostics-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch10-model-diagnostics-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-ch10-model-diagnostics-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch10-model-diagnostics">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch10-model-diagnostics-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Residuals vs Fitted
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch10-model-diagnostics" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch10-model-diagnostics-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch10-model-diagnostics-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-ch10-model-diagnostics-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch10-model-diagnostics">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch10-model-diagnostics-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Normal Q-Q
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch10-model-diagnostics" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch10-model-diagnostics-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch10-model-diagnostics-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-ch10-model-diagnostics-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch10-model-diagnostics">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch10-model-diagnostics-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Scale-Location
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ch10-model-diagnostics" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ch10-model-diagnostics-4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ch10-model-diagnostics-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-Regression_files/figure-html/fig-ch10-model-diagnostics-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-pos="H" data-ref-parent="fig-ch10-model-diagnostics">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ch10-model-diagnostics-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Residuals vs Leverage
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ch10-model-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.6: Diagnostic plots for assessing regression model assumptions.
</figcaption>
</figure>
</div>
</div>
<p>These plots provide complementary perspectives on model adequacy. The <em>Residuals vs.&nbsp;Fitted</em> plot (upper left) is used to assess linearity and constant variance. A random scatter of points with no systematic pattern supports both assumptions. In this case, the residuals appear evenly distributed without obvious curvature or funnel shapes.</p>
<p>The <em>Normal Q–Q</em> plot (upper right) evaluates the normality of residuals. When points lie close to the diagonal reference line, the normality assumption is reasonable. Here, the residuals follow the theoretical quantiles closely, suggesting no major departures from normality.</p>
<p>The <em>Scale–Location</em> plot (lower left) provides an additional check for homoscedasticity by displaying the spread of standardized residuals across fitted values. The relatively uniform spread observed here supports the constant variance assumption.</p>
<p>Independence is not directly tested using diagnostic plots and must be assessed based on the data-generating process. For the <code>marketing</code> dataset, daily revenue observations are assumed to be independent, making this assumption plausible.</p>
<p>When interpreting diagnostic plots, it is useful to ask targeted questions: Do the residuals appear randomly scattered? Do they show systematic patterns or changing spread? Do extreme observations exert undue influence? Actively engaging with these questions helps develop sound diagnostic judgment.</p>
<p>Taken together, the diagnostic plots suggest that the fitted model satisfies the key assumptions required for reliable inference and prediction. In practice, such checks should always accompany regression analysis.</p>
<p>When assumptions are violated, alternative strategies may be necessary. <em>Transformations</em> of variables can help stabilize variance or address skewness. <em>Polynomial regression</em> or other non-linear models can address curvature. <em>Robust regression</em> techniques offer protection against departures from normality or the presence of influential observations.</p>
<p>Careful diagnostic analysis is therefore an integral part of regression modeling. By validating assumptions and responding appropriately when they are violated, we ensure that regression models provide reliable, interpretable, and actionable insights.</p>
</section>
<section id="sec-ch10-case-study" class="level2" data-number="10.12">
<h2 data-number="10.12" class="anchored" data-anchor-id="sec-ch10-case-study"><span class="header-section-number">10.12</span> Case Study: Customer Churn Prediction Models</h2>
<p>Customer churn, defined as the event in which a customer discontinues a service, represents a major challenge in subscription-based industries such as telecommunications, banking, and online platforms. Accurately identifying customers who are at risk of churning enables proactive retention strategies and can substantially reduce revenue loss. This case study focuses on predicting customer churn using multiple classification models and comparing their performance in a realistic modeling setting.</p>
<p>Throughout this chapter, we have introduced several classification approaches from different perspectives. In this case study, we bring these methods together and apply them to the same prediction task using a common dataset. Specifically, we compare three models introduced earlier in the book: logistic regression (Section <a href="#sec-ch10-logistic-regression" class="quarto-xref"><span>10.6</span></a>), k-Nearest Neighbors (Chapter <a href="7-Classification-kNN.html" class="quarto-xref"><span>7</span></a>), and the Naive Bayes classifier (Chapter <a href="9-Naive-Bayes.html" class="quarto-xref"><span>9</span></a>). Each model reflects a different modeling philosophy, ranging from parametric and interpretable to instance-based and probabilistic.</p>
<p>The analysis is based on the <code>churn_mlc</code> dataset from the <strong>liver</strong> package, which contains customer-level information on service usage, plan characteristics, and interactions with customer service. The target variable is <code>churn</code>, a binary indicator that records whether a customer has left the service (<code>yes</code>) or remained active (<code>no</code>). The dataset is provided in an analysis-ready format, allowing us to focus directly on modeling and evaluation within the Data Science Workflow introduced in Chapter <a href="2-Intro-data-science.html" class="quarto-xref"><span>2</span></a>. We begin by loading the dataset and inspecting its structure:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(liver)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(churn_mlc)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(churn_mlc)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">5000</span> obs. of  <span class="dv">20</span> variables<span class="sc">:</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="er">$</span> state         <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">51</span> levels <span class="st">"AK"</span>,<span class="st">"AL"</span>,<span class="st">"AR"</span>,..<span class="sc">:</span> <span class="dv">17</span> <span class="dv">36</span> <span class="dv">32</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">2</span> <span class="dv">20</span> <span class="dv">25</span> <span class="dv">19</span> <span class="dv">50</span> ...</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> area_code     <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">3</span> levels <span class="st">"area_code_408"</span>,..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> ...</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> account_length<span class="sc">:</span> int  <span class="dv">128</span> <span class="dv">107</span> <span class="dv">137</span> <span class="dv">84</span> <span class="dv">75</span> <span class="dv">118</span> <span class="dv">121</span> <span class="dv">147</span> <span class="dv">117</span> <span class="dv">141</span> ...</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> voice_plan    <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> ...</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> voice_messages<span class="sc">:</span> int  <span class="dv">25</span> <span class="dv">26</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">24</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">37</span> ...</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_plan     <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> ...</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_mins     <span class="sc">:</span> num  <span class="dv">10</span> <span class="fl">13.7</span> <span class="fl">12.2</span> <span class="fl">6.6</span> <span class="fl">10.1</span> <span class="fl">6.3</span> <span class="fl">7.5</span> <span class="fl">7.1</span> <span class="fl">8.7</span> <span class="fl">11.2</span> ...</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_calls    <span class="sc">:</span> int  <span class="dv">3</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">7</span> <span class="dv">3</span> <span class="dv">6</span> <span class="dv">7</span> <span class="dv">6</span> <span class="dv">4</span> <span class="dv">5</span> ...</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> intl_charge   <span class="sc">:</span> num  <span class="fl">2.7</span> <span class="fl">3.7</span> <span class="fl">3.29</span> <span class="fl">1.78</span> <span class="fl">2.73</span> <span class="fl">1.7</span> <span class="fl">2.03</span> <span class="fl">1.92</span> <span class="fl">2.35</span> <span class="fl">3.02</span> ...</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> day_mins      <span class="sc">:</span> num  <span class="dv">265</span> <span class="dv">162</span> <span class="dv">243</span> <span class="dv">299</span> <span class="dv">167</span> ...</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> day_calls     <span class="sc">:</span> int  <span class="dv">110</span> <span class="dv">123</span> <span class="dv">114</span> <span class="dv">71</span> <span class="dv">113</span> <span class="dv">98</span> <span class="dv">88</span> <span class="dv">79</span> <span class="dv">97</span> <span class="dv">84</span> ...</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> day_charge    <span class="sc">:</span> num  <span class="fl">45.1</span> <span class="fl">27.5</span> <span class="fl">41.4</span> <span class="fl">50.9</span> <span class="fl">28.3</span> ...</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> eve_mins      <span class="sc">:</span> num  <span class="fl">197.4</span> <span class="fl">195.5</span> <span class="fl">121.2</span> <span class="fl">61.9</span> <span class="fl">148.3</span> ...</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> eve_calls     <span class="sc">:</span> int  <span class="dv">99</span> <span class="dv">103</span> <span class="dv">110</span> <span class="dv">88</span> <span class="dv">122</span> <span class="dv">101</span> <span class="dv">108</span> <span class="dv">94</span> <span class="dv">80</span> <span class="dv">111</span> ...</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> eve_charge    <span class="sc">:</span> num  <span class="fl">16.78</span> <span class="fl">16.62</span> <span class="fl">10.3</span> <span class="fl">5.26</span> <span class="fl">12.61</span> ...</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> night_mins    <span class="sc">:</span> num  <span class="dv">245</span> <span class="dv">254</span> <span class="dv">163</span> <span class="dv">197</span> <span class="dv">187</span> ...</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> night_calls   <span class="sc">:</span> int  <span class="dv">91</span> <span class="dv">103</span> <span class="dv">104</span> <span class="dv">89</span> <span class="dv">121</span> <span class="dv">118</span> <span class="dv">118</span> <span class="dv">96</span> <span class="dv">90</span> <span class="dv">97</span> ...</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> night_charge  <span class="sc">:</span> num  <span class="fl">11.01</span> <span class="fl">11.45</span> <span class="fl">7.32</span> <span class="fl">8.86</span> <span class="fl">8.41</span> ...</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> customer_calls<span class="sc">:</span> int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">0</span> <span class="dv">3</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> ...</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    <span class="sc">$</span> churn         <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"yes"</span>,<span class="st">"no"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset consists of 5000 observations and 20 variables. The features describe customer usage patterns, subscription plans, and interactions with customer service. Rather than modeling all available variables, we select a subset of predictors that capture core aspects of customer behavior and are commonly used in churn analysis. Since the primary goal of this case study is to compare modeling approaches rather than to perform exploratory analysis, we keep EDA brief and move directly to data partitioning and model fitting.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Apply exploratory data analysis techniques to the <code>churn_mlc</code> dataset following the approach used in Chapter <a href="4-Exploratory-data-analysis.html" class="quarto-xref"><span>4</span></a>. Compare the patterns you observe with those from the <code>churn</code> dataset.</p>
</blockquote>
<p>To ensure a fair comparison across models, we use the same set of predictors and preprocessing steps for all three classification methods. Model performance is evaluated using ROC curves and the area under the ROC curve (AUC), as introduced in Chapter <a href="8-Model-evaluation.html" class="quarto-xref"><span>8</span></a>. These metrics provide a threshold-independent assessment of classification performance and allow us to compare models on equal footing. The modeling formula used throughout this case study is:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>formula <span class="ot">=</span> churn <span class="sc">~</span> account_length <span class="sc">+</span> voice_plan <span class="sc">+</span> voice_messages <span class="sc">+</span> intl_plan <span class="sc">+</span> intl_mins <span class="sc">+</span> intl_calls <span class="sc">+</span> day_mins <span class="sc">+</span> day_calls <span class="sc">+</span> eve_mins <span class="sc">+</span> eve_calls <span class="sc">+</span> night_mins <span class="sc">+</span> night_calls <span class="sc">+</span> customer_calls</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the following sections, we fit each classification model using this common setup and compare their predictive performance, interpretability, and practical suitability for churn prediction.</p>
<section id="data-setup-for-modeling" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="data-setup-for-modeling">Data Setup for Modeling</h3>
<p>To evaluate how well our classification models generalize to unseen data, we partition the dataset into separate training and test sets. This separation ensures that model performance is assessed on observations that were not used during model fitting, providing an unbiased estimate of predictive accuracy.</p>
<p>To maintain consistency across chapters and enable meaningful comparison with earlier results, we adopt the same data partitioning strategy used in Chapter <a href="7-Classification-kNN.html#sec-ch7-knn-churn" class="quarto-xref"><span>7.7</span></a>. Specifically, we use the <code>partition()</code> function from the <strong>liver</strong> package to randomly split the data into non-overlapping subsets. Setting a random seed guarantees that the results are reproducible.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>data_sets <span class="ot">=</span> <span class="fu">partition</span>(<span class="at">data =</span> churn_mlc, <span class="at">ratio =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.2</span>))</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>train_set <span class="ot">=</span> data_sets<span class="sc">$</span>part1</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>test_set  <span class="ot">=</span> data_sets<span class="sc">$</span>part2</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>test_labels <span class="ot">=</span> test_set<span class="sc">$</span>churn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This procedure assigns 80% of the observations to the training set and reserves the remaining 20% for model evaluation. The response variable from the test set is stored separately in <code>test_labels</code> and will be used to assess predictive performance using ROC curves and AUC.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Repartition the <code>churn_mlc</code> dataset into a 70% training set and a 30% test set using the same approach. Check whether the class distribution of the target variable <code>churn</code> is similar in both subsets, and reflect on why preserving this balance is important for fair model evaluation.</p>
</blockquote>
<p>In the following subsections, we train each classification model using the same formula and training data. We then generate predictions on the test set and compare model performance using ROC curves and the area under the curve (AUC).</p>
</section>
<section id="training-the-logistic-regression-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="training-the-logistic-regression-model">Training the Logistic Regression Model</h3>
<p>We begin with logistic regression, a widely used baseline model for binary classification. Logistic regression models the probability of customer churn as a function of the selected predictors, making it both interpretable and well suited for probabilistic evaluation.</p>
<p>We fit the model using the <code>glm()</code> function, specifying the <code>binomial</code> family to indicate a binary response:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>logistic_model <span class="ot">=</span> <span class="fu">glm</span>(<span class="at">formula =</span> formula, <span class="at">data =</span> train_set, <span class="at">family =</span> binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once the model is fitted, we generate predicted probabilities for the observations in the test set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>logistic_probs <span class="ot">=</span> <span class="fu">predict</span>(logistic_model, <span class="at">newdata =</span> test_set, <span class="at">type =</span> <span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In logistic regression, <code>predict(..., type = "response")</code> returns estimated probabilities rather than class labels. By default, these probabilities correspond to the <em>non-reference class</em> of the response variable. In the <code>churn_mlc</code> dataset, the response variable <code>churn</code> has two levels, <code>"yes"</code> and <code>"no"</code>. Since <code>"yes"</code> is the first factor level and therefore treated as the reference category, the predicted probabilities returned here represent the probability of <code>"no"</code> (i.e., <em>not churning</em>).</p>
<p>If the goal is instead to obtain predicted probabilities for <code>"yes"</code> (customer churn), the reference level should be redefined <em>before</em> data partitioning and model fitting. For example:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>churn_mlc<span class="sc">$</span>churn <span class="ot">=</span> <span class="fu">relevel</span>(churn_mlc<span class="sc">$</span>churn, <span class="at">ref =</span> <span class="st">"no"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Refitting the model after this change would cause <code>predict()</code> to return probabilities of churn directly. Importantly, while the numerical probabilities change interpretation, the underlying fitted model remains equivalent.</p>
<p>At this stage, we retain the probabilistic predictions rather than converting them to class labels. This allows us to evaluate model performance across all possible classification thresholds using ROC curves and AUC, as discussed in Chapter <a href="8-Model-evaluation.html" class="quarto-xref"><span>8</span></a>.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> How would you convert the predicted probabilities into binary class labels? Try using thresholds of 0.5 and 0.3. How do the resulting classifications differ, and what are the implications for false positives and false negatives?</p>
</blockquote>
</section>
<section id="training-the-naive-bayes-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="training-the-naive-bayes-model">Training the Naive Bayes Model</h3>
<p>We briefly introduced the Naive Bayes classifier and its probabilistic foundations in Chapter <a href="9-Naive-Bayes.html" class="quarto-xref"><span>9</span></a>. Here, we apply the model to the same customer churn prediction task, using the same set of predictors as in the logistic regression and kNN models to ensure a fair comparison.</p>
<p>Naive Bayes is a fast, probabilistic classifier that is particularly well suited to high-dimensional and mixed-type data. Its defining assumption is that predictors are conditionally independent given the class label. While this assumption is often violated in practice, Naive Bayes can still perform surprisingly well, especially as a baseline model.</p>
<p>We fit the Naive Bayes classifier using the <code>naive_bayes()</code> function from the <strong>naivebayes</strong> package:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(naivebayes)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>bayes_model <span class="ot">=</span> <span class="fu">naive_bayes</span>(formula, <span class="at">data =</span> train_set)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once the model is trained, we generate predicted class probabilities for the test set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>bayes_probs <span class="ot">=</span> <span class="fu">predict</span>(bayes_model, test_set, <span class="at">type =</span> <span class="st">"prob"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The object <code>bayes_probs</code> is a matrix in which each row corresponds to a test observation and each column represents the estimated probability of belonging to one of the two classes (<code>no</code> or <code>yes</code>). As with logistic regression, we retain these probabilistic predictions rather than converting them to class labels, since they are required for threshold-independent evaluation using ROC curves and AUC.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> How might the conditional independence assumption affect the performance of Naive Bayes on this dataset, where usage variables such as call minutes and call counts are likely correlated? Compare this to the assumptions underlying logistic regression.</p>
</blockquote>
</section>
<section id="training-the-knn-model" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="training-the-knn-model">Training the kNN Model</h3>
<p>The k-Nearest Neighbors (kNN) algorithm is a non-parametric, instance-based classifier that assigns a class label to each test observation based on the majority class among its <span class="math inline">\(k\)</span> closest neighbors in the training set. Because kNN relies entirely on distance calculations, it is particularly sensitive to the scale and encoding of the input features.</p>
<p>We train a kNN model using the <code>kNN()</code> function from the <strong>liver</strong> package, setting the number of neighbors to <span class="math inline">\(k = 5\)</span>. This choice is informed by experimentation with different values of <span class="math inline">\(k\)</span> using the <code>kNN.plot()</code> function, as discussed in Chapter <a href="7-Classification-kNN.html#sec-ch7-knn-choose-k" class="quarto-xref"><span>7.6</span></a>. To ensure that all predictors contribute appropriately to distance computations, we apply min–max scaling and binary encoding using the <code>scaler = "minmax"</code> option:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>knn_probs <span class="ot">=</span> <span class="fu">kNN</span>(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> formula,</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">train   =</span> train_set,</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">test    =</span> test_set,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">k       =</span> <span class="dv">5</span>,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">scaler  =</span> <span class="st">"minmax"</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type    =</span> <span class="st">"prob"</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This preprocessing step scales all numeric predictors to the <span class="math inline">\([0, 1]\)</span> range and encodes binary categorical variables in a format suitable for distance-based modeling. As with logistic regression and Naive Bayes, we retain predicted class probabilities rather than class labels, since these probabilities are required for threshold-independent evaluation using ROC curves and AUC.</p>
<p>With predicted probabilities now available from all three models (logistic regression, Naive Bayes, and kNN), we are ready to compare their classification performance using ROC curves and the area under the curve.</p>
</section>
<section id="model-evaluation-and-comparison" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="model-evaluation-and-comparison">Model Evaluation and Comparison</h3>
<p>To evaluate and compare the performance of the three classification models across all possible classification thresholds, we use ROC curves and the Area Under the Curve (AUC) metric. As introduced in Chapter <a href="8-Model-evaluation.html" class="quarto-xref"><span>8</span></a>, the ROC curve plots the true positive rate against the false positive rate, while the AUC summarizes the overall discriminatory ability of a classifier: values closer to 1 indicate stronger separation between classes.</p>
<p>ROC-based evaluation is particularly useful in churn prediction settings, where class imbalance is common and the choice of classification threshold may vary depending on business objectives. We compute ROC curves using the <strong>pROC</strong> package. Since ROC analysis requires class probabilities, we extract the predicted probabilities corresponding to the <code>"yes"</code> (churn) class for each model:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>roc_logistic <span class="ot">=</span> <span class="fu">roc</span>(test_labels, logistic_probs)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>roc_bayes    <span class="ot">=</span> <span class="fu">roc</span>(test_labels, bayes_probs[, <span class="st">"yes"</span>])</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>roc_knn      <span class="ot">=</span> <span class="fu">roc</span>(test_labels, knn_probs[, <span class="st">"yes"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To facilitate comparison, we visualize all three ROC curves in a single plot:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggroc</span>(<span class="fu">list</span>(roc_logistic, roc_bayes, roc_knn), <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span> </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"#377EB8"</span>, <span class="st">"#E66101"</span>, <span class="st">"#4DAF4A"</span>),</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>             <span class="fu">paste</span>(<span class="st">"Logistic (AUC ="</span>, <span class="fu">round</span>(<span class="fu">auc</span>(roc_logistic), <span class="dv">3</span>), <span class="st">")"</span>),</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>             <span class="fu">paste</span>(<span class="st">"Naive Bayes (AUC ="</span>, <span class="fu">round</span>(<span class="fu">auc</span>(roc_bayes), <span class="dv">3</span>), <span class="st">")"</span>),</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>             <span class="fu">paste</span>(<span class="st">"kNN (AUC ="</span>, <span class="fu">round</span>(<span class="fu">auc</span>(roc_knn), <span class="dv">3</span>), <span class="st">")"</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>           )) <span class="sc">+</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"ROC Curves with AUC for Three Models"</span>) <span class="sc">+</span> </span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>(), <span class="at">legend.position =</span> <span class="fu">c</span>(.<span class="dv">7</span>, .<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="10-Regression_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%" data-fig-pos="H"></p>
</figure>
</div>
</div>
</div>
<p>The ROC curves summarize the trade-off between sensitivity and specificity for each classifier. The corresponding AUC values are 0.834 for logistic regression, 0.866 for Naive Bayes, and 0.855 for kNN. Although kNN achieves the highest AUC, the differences among the three models are modest. This suggests that all three approaches provide comparable predictive performance on this dataset.</p>
<p>From a practical perspective, these results highlight an important modeling trade-off. While kNN offers slightly stronger discrimination, logistic regression and Naive Bayes remain attractive alternatives due to their interpretability, simplicity, and lower computational cost. In many real-world applications, such considerations may outweigh small gains in predictive accuracy.</p>
<blockquote class="blockquote">
<p><em>Practice:</em> Repartition the <code>churn_mlc</code> dataset using a 70%–30% train–test split. Following the same workflow as in this section, fit a logistic regression model, a Naive Bayes classifier, and a kNN model, and report the corresponding ROC curves and AUC values. Compare these results with those obtained using the 80%–20% split. What do you observe about the stability of model evaluation across different data partitions?</p>
</blockquote>
</section>
</section>
<section id="sec-ch10-summary" class="level2" data-number="10.13">
<h2 data-number="10.13" class="anchored" data-anchor-id="sec-ch10-summary"><span class="header-section-number">10.13</span> Chapter Summary and Takeaways</h2>
<p>In this chapter, we examined regression analysis as a foundational tool for modeling relationships and making predictions in data science. Beginning with simple linear regression, we gradually expanded the framework to include multiple regression, generalized linear models, and polynomial regression, illustrating how increasingly flexible models can address more complex data structures.</p>
<p>Throughout the chapter, we emphasized both <em>interpretation</em> and <em>prediction</em>. We showed how regression coefficients can be interpreted in context, how assumptions can be assessed through residual diagnostics, and how model quality can be evaluated using metrics such as the residual standard error, <span class="math inline">\(R^2\)</span>, and adjusted <span class="math inline">\(R^2\)</span>. We also discussed principled approaches to predictor selection, including stepwise regression guided by information criteria such as AIC and BIC.</p>
<p>By extending regression to non-continuous outcomes, we demonstrated how logistic regression and Poisson regression adapt the linear modeling framework to binary and count data. A case study on customer churn brought these ideas together, comparing logistic regression, Naive Bayes, and kNN classifiers using ROC curves and AUC. This comparison highlighted an important practical insight: models with very different assumptions and structures can achieve similar predictive performance, making interpretability, robustness, and computational considerations central to model choice.</p>
<p>Taken together, this chapter reinforces a key message of the Data Science Workflow: effective modeling is not about applying the most complex method available, but about selecting models that are appropriate for the data, the problem, and the decision context. Regression models are not merely statistical tools; they provide a structured way to reason about uncertainty, quantify relationships, and support informed, transparent decisions. In the chapters that follow, we continue to build on these ideas by exploring more flexible modeling techniques and strategies for validating and comparing predictive models.</p>
</section>
<section id="sec-ch10-exercises" class="level2" data-number="10.14">
<h2 data-number="10.14" class="anchored" data-anchor-id="sec-ch10-exercises"><span class="header-section-number">10.14</span> Exercises</h2>
<p>These exercises reinforce key ideas from the chapter, combining conceptual questions, interpretation of regression outputs, and practical implementation in R. The datasets used are included in the <strong>liver</strong> and <strong>ggplot2</strong> packages.</p>
<section id="linear-regression" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="linear-regression">Linear Regression</h4>
<section id="conceptual-questions" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="conceptual-questions">Conceptual Questions</h5>
<ol type="1">
<li><p>How does simple linear regression differ from multiple linear regression?</p></li>
<li><p>List the key assumptions of linear regression. Why do they matter?</p></li>
<li><p>What does the R-squared (<span class="math inline">\(R^2\)</span>) value tell us about a regression model?</p></li>
<li><p>Compare RSE and <span class="math inline">\(R^2\)</span>. What does each measure?</p></li>
<li><p>What is multicollinearity, and how does it affect regression models?</p></li>
<li><p>Why is Adjusted <span class="math inline">\(R^2\)</span> preferred over <span class="math inline">\(R^2\)</span> in models with multiple predictors?</p></li>
<li><p>How are categorical variables handled in regression models in R?</p></li>
</ol>
</section>
<section id="hands-on-practice-regression-with-the-house-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-regression-with-the-house-dataset">Hands-On Practice: Regression with the <em>house</em> Dataset</h5>
<div class="sourceCode" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(house, <span class="at">package =</span> <span class="st">"liver"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="8" type="1">
<li><p>Fit a model predicting <code>unit_price</code> using <code>house_age</code>. Summarize the results.</p></li>
<li><p>Add <code>distance_to_MRT</code> and <code>stores_number</code> as predictors. Interpret the updated model.</p></li>
<li><p>Predict <code>unit_price</code> for homes aged 10, 20, and 30 years.</p></li>
<li><p>Evaluate whether including <code>latitude</code> and <code>longitude</code> improves model performance.</p></li>
<li><p>Report the RSE and <span class="math inline">\(R^2\)</span>. What do they suggest about the model’s fit?</p></li>
<li><p>Create a residual plot. What does it reveal about model assumptions?</p></li>
<li><p>Use a Q-Q plot to assess the normality of residuals.</p></li>
</ol>
</section>
<section id="hands-on-practice-regression-with-the-insurance-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-regression-with-the-insurance-dataset">Hands-On Practice: Regression with the <em>insurance</em> Dataset</h5>
<div class="sourceCode" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(insurance, <span class="at">package =</span> <span class="st">"liver"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="15" type="1">
<li><p>Model <code>charges</code> using <code>age</code>, <code>bmi</code>, <code>children</code>, and <code>smoker</code>.</p></li>
<li><p>Interpret the coefficient ffig-cap:or <code>smoker</code>.</p></li>
<li><p>Include an interaction between <code>age</code> and <code>bmi</code>. Does it improve the model?</p></li>
<li><p>Add <code>region</code> as a predictor. Does Adjusted <span class="math inline">\(R^2\)</span> increase?</p></li>
<li><p>Use stepwise regression to find a simpler model with comparable performance.</p></li>
</ol>
</section>
<section id="hands-on-practice-regression-with-the-cereal-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-regression-with-the-cereal-dataset">Hands-On Practice: Regression with the <em>cereal</em> Dataset</h5>
<div class="sourceCode" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(cereal, <span class="at">package =</span> <span class="st">"liver"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="20" type="1">
<li><p>Model <code>rating</code> using <code>calories</code>, <code>protein</code>, <code>sugars</code>, and <code>fiber</code>.</p></li>
<li><p>Which predictor appears to have the strongest impact on <code>rating</code>?</p></li>
<li><p>Should <code>sodium</code> be included in the model? Support your answer.</p></li>
<li><p>Compare the effects of <code>fiber</code> and <code>sugars</code>.</p></li>
<li><p>Use stepwise regression to identify a more parsimonious model.</p></li>
</ol>
</section>
<section id="hands-on-practice-regression-with-the-diamonds-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-regression-with-the-diamonds-dataset">Hands-On Practice: Regression with the <em>diamonds</em> Dataset</h5>
<p>These exercises use the <em>diamonds</em> dataset from the <strong>ggplot2</strong> package. Recall that this dataset contains over 50,000 records of diamond characteristics and their prices. Use the dataset after appropriate cleaning and transformation, as discussed in Chapter <a href="3-Data-preparation.html" class="quarto-xref"><span>3</span></a>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(diamonds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="25" type="1">
<li><p>Fit a simple regression model using <code>carat</code> as the sole predictor of <code>price</code>. Interpret the intercept and slope of the fitted model. What does this suggest about how diamond size affects price?</p></li>
<li><p>Create a scatter plot of <code>price</code> versus <code>carat</code> and add the regression line. Does the linear trend appear appropriate across the full range of carat values?</p></li>
<li><p>Fit a multiple linear regression model using <code>carat</code>, <code>cut</code>, and <code>color</code> as predictors of <code>price</code>. Which predictors are statistically significant? How do you interpret the coefficients for categorical variables?</p></li>
<li><p>Use diagnostic plots to evaluate the residuals of your multiple regression model. Do they appear approximately normally distributed? Is there evidence of non-constant variance or outliers?</p></li>
<li><p>Add a quadratic term for <code>carat</code> (i.e., <code>carat^2</code>) to capture possible curvature in the relationship. Does this improve model fit?</p></li>
<li><p>Compare the linear and polynomial models using R-squared, adjusted R-squared, and RMSE. Which model would you prefer for prediction, and why?</p></li>
<li><p>Predict the price of a diamond with the following characteristics: 0.8 carats, cut = “Premium”, and color = “E”. Include both a confidence interval for the mean prediction and a prediction interval for a new observation.</p></li>
<li><p>Challenge: Explore whether the effect of <code>carat</code> on <code>price</code> differs by <code>cut</code>. Add an interaction term between <code>carat</code> and <code>cut</code> to your model. Interpret the interaction and discuss whether it adds value to the model.</p></li>
</ol>
</section>
</section>
<section id="polynomial-regression" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="polynomial-regression">Polynomial Regression</h4>
<section id="conceptual-questions-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="conceptual-questions-1">Conceptual Questions</h5>
<ol start="33" type="1">
<li><p>What is polynomial regression, and how does it extend linear regression?</p></li>
<li><p>Why is polynomial regression still considered a linear model?</p></li>
<li><p>What risks are associated with using high-degree polynomials?</p></li>
<li><p>How can you determine the most appropriate polynomial degree?</p></li>
<li><p>What visual or statistical tools can help detect overfitting?</p></li>
</ol>
</section>
<section id="hands-on-practice-polynomial-regression-with-house-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-polynomial-regression-with-house-dataset">Hands-On Practice: Polynomial Regression with <em>house</em> Dataset</h5>
<ol start="38" type="1">
<li><p>Fit a quadratic model for <code>unit_price</code> using <code>house_age</code>. Compare it to a linear model.</p></li>
<li><p>Fit a cubic model. Is there evidence of improved performance?</p></li>
<li><p>Plot the linear, quadratic, and cubic fits together.</p></li>
<li><p>Use cross-validation to select the optimal polynomial degree.</p></li>
<li><p>Interpret the coefficients of the quadratic model.</p></li>
</ol>
</section>
</section>
<section id="logistic-regression" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="logistic-regression">Logistic Regression</h4>
<section id="conceptual-questions-2" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="conceptual-questions-2">Conceptual Questions</h5>
<ol start="43" type="1">
<li><p>What distinguishes logistic regression from linear regression?</p></li>
<li><p>Why does logistic regression use the logit function?</p></li>
<li><p>Explain how to interpret an odds ratio.</p></li>
<li><p>What is a confusion matrix, and how is it used?</p></li>
<li><p>Distinguish between precision and recall in classification evaluation.</p></li>
</ol>
</section>
<section id="hands-on-practice-logistic-regression-with-bank-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-logistic-regression-with-bank-dataset">Hands-On Practice: Logistic Regression with <em>bank</em> Dataset</h5>
<div class="sourceCode" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(bank, <span class="at">package =</span> <span class="st">"liver"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="48" type="1">
<li><p>Predict <code>y</code> using <code>age</code>, <code>balance</code>, and <code>duration</code>.</p></li>
<li><p>Interpret model coefficients as odds ratios.</p></li>
<li><p>Estimate the probability of subscription for a new customer.</p></li>
<li><p>Generate a confusion matrix to assess prediction performance.</p></li>
<li><p>Report accuracy, precision, recall, and F1-score.</p></li>
<li><p>Apply stepwise regression to simplify the model.</p></li>
<li><p>Plot the ROC curve and compute the AUC.</p></li>
</ol>
</section>
<section id="hands-on-practice-stepwise-regression-with-house-dataset" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="hands-on-practice-stepwise-regression-with-house-dataset">Hands-On Practice: Stepwise Regression with <em>house</em> Dataset</h5>
<ol start="55" type="1">
<li><p>Use stepwise regression to model <code>unit_price</code>.</p></li>
<li><p>Compare the stepwise model to the full model.</p></li>
<li><p>Add interaction terms. Do they improve model performance?</p></li>
</ol>
</section>
</section>
<section id="model-diagnostics-and-validation" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="model-diagnostics-and-validation">Model Diagnostics and Validation</h4>
<ol start="58" type="1">
<li><p>Check linear regression assumptions for the multiple regression model on <code>house</code>.</p></li>
<li><p>Generate diagnostic plots: residuals vs fitted, Q-Q plot, and scale-location plot.</p></li>
<li><p>Apply cross-validation to compare model performance.</p></li>
<li><p>Compute and compare mean squared error (MSE) across models.</p></li>
<li><p>Does applying a log-transformation improve model accuracy?</p></li>
</ol>
</section>
<section id="self-reflection" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="self-reflection">Self-Reflection</h4>
<ol start="63" type="1">
<li>Think of a real-world prediction problem you care about, such as pricing, health outcomes, or consumer behavior. Which regression technique covered in this chapter would be most appropriate, and why?</li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-gareth2013introduction" class="csl-entry" role="listitem">
Gareth, James, Witten Daniela, Hastie Trevor, and Tibshirani Robert. 2013. <em>An Introduction to Statistical Learning: With Applications in r</em>. Spinger.
</div>
<div id="ref-wheelan2013naked" class="csl-entry" role="listitem">
Wheelan, Charles. 2013. <em>Naked Statistics: Stripping the Dread from the Data</em>. WW Norton &amp; Company.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/book-data-science-r\.netlify\.app");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./9-Naive-Bayes.html" class="pagination-link" aria-label="Naive Bayes Classifier">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Naive Bayes Classifier</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./11-Tree-based-models.html" class="pagination-link" aria-label="Decision Trees and Random Forests">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Decision Trees and Random Forests</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Data Science Foundations and Machine Learning with R was written by <a href="https://www.uva.nl/profile/a.mohammadi"><span style="color:#0056B3">Reza Mohammadi</span></a>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/edit/main/10-Regression.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/RezaMoammadi/Book-Data-Science-R/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>