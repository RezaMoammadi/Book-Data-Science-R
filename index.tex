% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
]{svmono}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
    \setmainfont[]{Palatino}
    \setmonofont[]{Inconsolata}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

% template.tex: Springer-compatible LaTeX header for Quarto

\usepackage{fontspec}

% Essential Springer-required fonts and packages
% \usepackage{mathptmx} % Times font (Springer default)
% \usepackage{helvet}   % Helvetica font (for sans-serif text)
% \usepackage{courier}  % Courier font (monospaced text)
% \usepackage{type1cm}  % Ensures scalable fonts (Type 1)

% Additional Springer-specific settings:
\usepackage{makeidx}  % Required for indexing
\makeindex            % Enable index generation

% For better tables
\usepackage{booktabs}

% Figures and graphics settings
\usepackage{graphicx}

% Math packages (often used in Springer books)
\usepackage{amsmath}
\usepackage{amssymb}

% Springer-specific gray boxes (optional):
\usepackage{tcolorbox}
\tcbuselibrary{listingsutf8}
\tcbset{
  boxrule=0pt,
  colback=gray!10,
  colframe=gray!40,
  sharp corners
}

\usepackage{listings}
\lstset{
  breaklines=true,
  breakatwhitespace=false,
  postbreak=\mbox{\textcolor{gray}{$\hookrightarrow$}\space},
  basicstyle=\monofont,
  columns=fullflexible,
  keepspaces=true,
  frame=single,
  xleftmargin=1em,
  tabsize=2
}


\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{
  breaklines=true,
  breakanywhere=true,
  fontsize=\small,
  commandchars=\\\{\}
}

\numberwithin{example}{subsection}


% Custom commands (optional):
\newcommand{\R}{\textsf{R}}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Data Science Foundations and Machine Learning with R: From Data to Decisions},
  pdfauthor={Reza Mohammadi},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{{Data Science Foundations and Machine Learning with R: From Data
to Decisions}}
\author{\href{https://www.uva.nl/profile/a.mohammadi}{{Reza Mohammadi}}}
\date{6 November 2025}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{}\label{section}
\addcontentsline{toc}{chapter}{}

\markboth{}{}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\emph{Data science} is transforming how we understand the world, solve
problems, and make informed decisions. From generative AI systems such
as ChatGPT, DeepSeek, and Gemini to personalized recommendations on
streaming platforms and fraud detection in banking, data-driven
techniques are reshaping industries and everyday life. As demand grows
for professionals who can analyze and model data effectively, accessible
and rigorous educational resources are more essential than ever.

\emph{Data Science Foundations and Machine Learning with R: From Data to
Decisions} offers a hands-on introduction to this dynamic field.
Designed for readers with no prior experience in analytics or
programming, the book provides a clear, structured pathway into data
science by emphasizing conceptual understanding, practical application,
and reproducible workflows using R.

This book is intended for newcomers to data science and machine
learning, particularly those without a background in programming or
statistics. Whether you are a student, business professional, or
researcher, it offers an approachable yet academically grounded learning
experience. Drawing on my experience teaching data science at the
university level, I emphasize an applied, example-driven approach that
fosters active engagement and deep comprehension.

The motivation for this book stems from a recurring challenge I
encountered in the classroom: many of my students were eager to explore
data science but lacked resources that were both accessible and
conceptually rigorous. I saw a clear need for materials that bridge
foundational theory and meaningful application. My goal was to provide a
guided, practical learning experience, lowering the barrier to entry
without sacrificing depth, through real data and hands-on practice in R.

To support a smoother learning curve, the book adopts \emph{active
learning strategies}. Concepts are introduced progressively and
reinforced through illustrative examples, guided coding exercises, and
applied problem-solving. By working directly with authentic datasets and
practical scenarios, readers learn not only how data science tools work,
but also when and why to use them. This experiential approach fosters
lasting understanding and builds confidence in applying these skills
independently.

Rather than presenting machine learning as a purely theoretical
discipline, the book integrates annotated code, real datasets, and
structured walkthroughs throughout. Each chapter concludes with a case
study that applies the chapter's core ideas to a realistic context,
bridging the gap between theory and practice. Exercises further
reinforce learning through direct implementation in R, helping readers
develop both conceptual clarity and practical fluency.

\section*{Why This Book?}\label{why-this-book}
\addcontentsline{toc}{section}{Why This Book?}

\markright{Why This Book?}

\emph{Data science} is a rapidly evolving field that integrates machine
learning, statistical modeling, and computational tools to extract
insights from data. This book provides a structured, application-focused
introduction to data analysis and machine learning using R, a widely
adopted, open-source language known for its strengths in statistical
computing, visualization, and reproducible workflows.

Unlike many textbooks that assume prior experience with programming or
analytics, this book is designed to be \emph{accessible and hands-on}.
Concepts are introduced clearly and reinforced through real-world
examples, guided exercises, and annotated R code. This approach allows
readers to build theoretical understanding alongside practical fluency
from the outset.

With its extensive ecosystem of packages, R remains a leading tool for
data science across academic, industrial, and research settings. This
book emphasizes its practical use in solving data-driven problems. For
readers who prefer Python, a companion volume titled \emph{Data Science
Foundations and Machine Learning with Python: From Data to Decisions} is
also available from the same publisher.

\section*{Who Should Read This Book?}\label{who-should-read-this-book}
\addcontentsline{toc}{section}{Who Should Read This Book?}

\markright{Who Should Read This Book?}

This book is intended for anyone seeking to learn data science and
machine learning, particularly those new to the field. It is well-suited
for:

\begin{itemize}
\item
  Business professionals aiming to integrate data-driven decision-making
  into their work,
\item
  Students and researchers applying data analysis in academic or applied
  contexts,
\item
  Beginners with no prior experience in programming or analytics,
\item
  Readers interested in learning data science and machine learning using
  R.
\end{itemize}

It is especially appropriate for undergraduate students in programs that
emphasize quantitative reasoning, such as economics, business
administration, business economics (including specializations in finance
or organizational economics), communication science, psychology, and
STEM fields (science, technology, engineering, and mathematics). It also
supports students in Master's programs in business analytics,
econometrics, and the social sciences.

Designed for both self-study and classroom use, the book offers a
structured and practice-oriented path to applying data science
techniques in real-world settings. It serves as the reference for
courses such as \emph{Data Analytics: Machine Learning}, \emph{Data
Wrangling}, and \emph{Business Analytics} across several BSc and MSc
programs at the University of Amsterdam.

It is equally useful for professionals pursuing continuing education in
analytics, offering an accessible foundation for those looking to
strengthen their skills in a rapidly evolving data landscape.

\section*{Skills You Will Gain}\label{skills-you-will-gain}
\addcontentsline{toc}{section}{Skills You Will Gain}

\markright{Skills You Will Gain}

This book walks you through a practical and progressive journey into
data science and machine learning using R, structured around the
\emph{Data Science Workflow} (Figure \ref{fig-ch0_DSW}). Each chapter
supports both conceptual mastery and applied skill development, helping
you progress from understanding and applying core ideas to analyzing
results and evaluating solutions.

By the end of this book, you will be able to:

\begin{itemize}
\item
  \emph{Recognize and describe} the key stages of a data science
  project, from problem formulation to model evaluation;
\item
  \emph{Apply} core R programming concepts, including data structures,
  control flow, and functions, to prepare and analyze data;
\item
  \emph{Clean and transform} raw datasets by handling missing values,
  outliers, and categorical variables using best practices;
\item
  \emph{Explore and interpret} data using descriptive statistics and
  effective visualizations;
\item
  \emph{Build and tune} machine learning models for classification,
  regression, and clustering using algorithms such as k-NN, Naive Bayes,
  decision trees, neural networks, and K-means;
\item
  \emph{Assess and compare} model performance using relevant metrics
  tailored to each type of task;
\item
  \emph{Transfer and adapt} your skills to solve real-world problems in
  marketing, finance, operations, and beyond.
\end{itemize}

Each chapter integrates illustrative examples, annotated R code, and
exercises that reinforce learning through practice. Chapters conclude
with a case study that synthesizes the main concepts, guiding you in
applying techniques to authentic scenarios. This structure ensures that
by the end of the book, you are not just familiar with the tools; you
are equipped to use them thoughtfully and effectively.

\section*{Structure of This Book}\label{structure-of-this-book}
\addcontentsline{toc}{section}{Structure of This Book}

\markright{Structure of This Book}

This book is structured around the \emph{Data Science Workflow}, an
iterative framework that guides you from foundational concepts to
advanced machine learning techniques through hands-on learning. Your
journey begins in Chapter \textbf{?@sec-ch1-intro-R}, where you will
install R, explore its syntax, and work with essential data structures.
From there, each chapter builds on the previous one, combining coding
practice with real-world case studies to help you gain both
understanding and experience.

\begin{figure}[H]

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{images/ch2_DSW.png}

}

\caption{\label{fig-ch0_DSW}The Data Science Workflow is an iterative
framework for structuring data science and machine learning projects.
Inspired by the CRISP-DM model (Cross-Industry Standard Process for Data
Mining), it supports systematic problem-solving and continuous
refinement.}

\end{figure}%

The \emph{Data Science Workflow}, introduced in Chapter
\textbf{?@sec-ch2-intro-data-science} and illustrated in
Figure~\ref{fig-ch0_DSW}, consists of seven key stages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Problem Understanding}: Define the objective and the broader
  context (Chapter \textbf{?@sec-ch2-intro-data-science}).
\item
  \emph{Data Preparation}: Clean, transform, and organize raw data
  (Chapter \textbf{?@sec-ch3-data-preparation}).
\item
  \emph{Exploratory Data Analysis (EDA)}: Visualize and summarize data
  to uncover patterns (Chapter \textbf{?@sec-ch4-EDA}).
\item
  \emph{Data Setup to Model}: Select features, partition datasets, and
  scale variables (Chapter \textbf{?@sec-ch6-setup-data}).
\item
  \emph{Modeling}: Build and train predictive models using a range of
  machine learning algorithms (Chapters
  \textbf{?@sec-ch7-classification-knn} to
  \textbf{?@sec-ch13-clustering}).
\item
  \emph{Evaluation}: Measure model performance using appropriate metrics
  (Chapter \textbf{?@sec-ch8-evaluation}).
\item
  \emph{Deployment}: Translate models into real-world applications.
\end{enumerate}

This workflow provides a practical and repeatable framework for tackling
data-driven problems. The chapter sequence mirrors these phases,
supporting a gradual progression from theory to implementation.

Chapter \textbf{?@sec-ch5-statistics} also provides a concise review of
key statistical ideas, such as confidence intervals and hypothesis
testing, that support critical thinking and model interpretation.

To bridge theory and practice, each chapter concludes with a case study
that applies its core ideas to a real-world problem. These case studies
walk through the \emph{Data Science Workflow} in action: guiding you
through data preparation, model development, evaluation, and
interpretation using real datasets. The datasets, listed in Table
Table~\ref{tbl-data-table}, are available through the \textbf{liver}
package. This enables you to reproduce examples, complete exercises, and
build practical skills with minimal setup.

Each chapter ends with exercises designed to consolidate learning: from
conceptual questions and hands-on coding tasks to applied
problem-solving challenges. These help reinforce key ideas, encourage
experimentation, and build confidence in using R for data science.

\section*{How to Use This Book}\label{how-to-use-this-book}
\addcontentsline{toc}{section}{How to Use This Book}

\markright{How to Use This Book}

This book is designed for \emph{self-study, classroom instruction, and
professional learning}. You can work through the chapters sequentially
for a structured learning path or consult individual sections to focus
on specific skills or concepts.

To make the most of this book:

\begin{itemize}
\item
  \emph{Run the code} -- Execute the R code examples interactively to
  reinforce key ideas through immediate feedback and hands-on
  experience.
\item
  \emph{Solve the exercises} -- Tackle a range of questions in each
  chapter to deepen your understanding and strengthen analytical
  fluency.
\item
  \emph{Experiment with the code} -- Modify examples, test new
  parameters, and experiment with different datasets to sharpen your
  problem-solving skills.
\item
  \emph{Study the case studies} -- Use the end-of-chapter case studies
  to see the Data Science Workflow in action, from data preparation to
  model interpretation.
\item
  \emph{Use the book as a reference} -- Return to chapters as needed to
  support your projects and refresh specific techniques.
\end{itemize}

Each chapter concludes with a case study based on a real-world dataset.
These walk through the complete Data Science Workflow: preparation,
modeling, evaluation, and interpretation, helping you consolidate
learning and apply techniques in realistic analytical contexts.

This book also supports collaborative learning. Working through
exercises and case studies in pairs or small groups can spark
discussion, deepen understanding, and foster diverse perspectives,
especially in classroom and workshop environments.

The book has been successfully used in data science courses at the
University of Amsterdam and is well-suited for academic programs and
professional training. Whether you are an independent learner,
instructor, or practitioner, it offers a flexible and structured path to
mastering essential tools and methods in data science and machine
learning.

\section*{Datasets Used in This Book}\label{datasets-used-in-this-book}
\addcontentsline{toc}{section}{Datasets Used in This Book}

\markright{Datasets Used in This Book}

This book integrates real-world datasets to support its applied,
hands-on approach to learning data science and machine learning. These
datasets are used throughout the chapters to illustrate key concepts,
demonstrate analytical techniques, and guide readers through full case
studies. Table~\ref{tbl-data-table} summarizes the core datasets
featured in the book, most of which are included in the \textbf{liver}
package (except the \emph{diamonds} dataset, available in the
\textbf{ggplot2} package). All datasets from \textbf{liver} can be
directly accessed in R for seamless replication of examples.

\begin{table}

\caption{\label{tbl-data-table}Overview of datasets used for case
studies in different chapters. All datasets are included in the R
package liver, except the diamonds dataset, which is available in the
ggplot2 package.}

\centering{

\centering
\begin{tabular}[t]{>{}l>{\raggedright\arraybackslash}p{20em}l}
\toprule
Name & Description & Chapter\\
\midrule
\textcolor{black}{churn} & Customer churn dataset. & Chapters 4, 6, 7, 8, 10\\
\textcolor{black}{bank} & Direct marketing data from a Portuguese bank. & Chapters 6, 7, 12\\
\textcolor{black}{adult} & US Census data for income prediction. & Chapters 3, 11\\
\textcolor{black}{risk} & Credit risk dataset. & Chapter 9\\
\textcolor{black}{marketing} & Marketing campaign performance data. & Chapter 10\\
\addlinespace
\textcolor{black}{house} & House price prediction dataset. & Chapter 10\\
\textcolor{black}{diamonds} & Diamond pricing dataset. & Chapter 3\\
\textcolor{black}{cereal} & Nutritional information for 77 breakfast cereals. & Chapter 13\\
\textcolor{black}{churnCredit} & Customer churn in the credit card industry. & Chapter 9\\
\textcolor{black}{churnTel} & Customer churn in the telecommunications industry. & Chapter 4\\
\addlinespace
\textcolor{black}{caravan} & Customer data for insurance purchase prediction. & Chapter 11\\
\textcolor{black}{insurance} & Insurance policyholder data. & Chapter 10\\
\textcolor{black}{housePrice} & House price data from Ames, Iowa. & Chapter 3\\
\textcolor{black}{drug} & Drug consumption dataset. & Chapter 7\\
\textcolor{black}{redWines} & Red wine quality dataset. & Chapters 11, 13\\
\addlinespace
\textcolor{black}{whiteWines} & White wine quality dataset. & Chapter 13\\
\bottomrule
\end{tabular}

}

\end{table}%

These datasets were selected to expose readers to a broad range of
real-world challenges spanning marketing, finance, customer analytics,
and predictive modeling. They appear throughout the book not only in
guided examples and code demonstrations but also in comprehensive case
studies that follow the full Data Science Workflow.

All datasets from the \textbf{liver} package can be loaded directly in R
using the \texttt{data()} function (for example, \texttt{data(churn)})
and explored with standard functions such as \texttt{str()},
\texttt{summary()}, and \texttt{head()}. Readers can also access
documentation and original dataset sources through the package reference
page at
\url{https://cran.r-project.org/web/packages/liver/refman/liver.html}.

Beyond the datasets listed in Table~\ref{tbl-data-table}, the
\textbf{liver} package includes more than 15 datasets in total. Several
of these appear in end-of-chapter exercises, offering readers further
opportunities to practice data exploration, modeling, and evaluation
across diverse contexts.

\section*{How to Teach with This
Book}\label{how-to-teach-with-this-book}
\addcontentsline{toc}{section}{How to Teach with This Book}

\markright{How to Teach with This Book}

This book is well-suited for introductory courses in data science and
machine learning, as well as for professional training programs. Its
structured progression, applied case studies, and extensive set of
exercises make it a versatile resource for both instructors and
learners.

To support systematic learning, the book includes over 500 exercises
across three levels: conceptual questions that reinforce key ideas,
applied tasks that involve real-world data, and advanced problems that
deepen understanding of machine learning techniques. Together, these
exercises help build a strong foundation and cultivate the analytical
mindset essential for practical data science.

Each chapter also features a case study that guides students through the
full Data Science Workflow: from data preparation and modeling to
evaluation and interpretation, demonstrating how theoretical concepts
are applied in realistic scenarios.

The book currently serves as the primary reference for courses such as
\emph{Data Analytics: Machine Learning}, \emph{Data Wrangling}, and
\emph{Business Analytics} in BSc and MSc programs at the University of
Amsterdam. It is also well suited for courses in applied statistics,
econometrics, business analytics, and quantitative methods across
programs in the social sciences, business, and STEM fields.

Instructors adopting this book have access to a full suite of teaching
materials, including a solutions manual, presentation slides, and test
banks. These resources provide a complete framework for delivering
effective and engaging data science instruction.

The book is further supported by the \textbf{liver} package, which
includes over 15 real-world datasets used throughout the chapters,
exercises, and case studies. Combined with its emphasis on active
learning through code walkthroughs, reproducible analysis, and applied
problem-solving, this book offers an ideal foundation for teaching data
science in both academic and professional contexts.

\section*{Acknowledgments}\label{acknowledgments}
\addcontentsline{toc}{section}{Acknowledgments}

\markright{Acknowledgments}

Writing this book has been both a challenging and deeply rewarding
journey, and I would like to express my sincere gratitude to those who
supported and inspired me along the way.

First and foremost, I thank my wife, Pariya, for her continuous support,
patience, and encouragement. I am also grateful to my family, and
especially my older brother, for their unwavering belief in me.

This book would not have taken shape without the contributions of my
collaborators. I am particularly thankful to Dr.~Kevin Burke for his
valuable input in shaping the structure of the book. I also wish to
acknowledge Dr.~Jeroen van Raak and Dr.~Julien Rossi, who have
enthusiastically partnered with me in developing the Python edition of
this book.

I am especially indebted to Eva Hiripi at Springer for her steadfast
support and for encouraging me to pursue this project in the first
place.

My colleagues in the Business Analytics Section at the University of
Amsterdam provided thoughtful feedback and generous support during the
writing process. I am particularly grateful to Prof.~Ilker Birbil,
Prof.~Dick den Hertog, Prof.~Marc Salomon, Prof.~Jeroen de Mast,
Prof.~Peter Kroos, Dr.~Marit Schoonhoven, Dr.~Stevan Rudinac, Dr.~Rob
Goedhart, Dr.~Chintan Amrit, Dr.~Inez Zwetsloot, Dr.~Alex Kuiper, and
Dr.~Bart Lameijer. I also thank my PhD students, Lucas Vogels (soon to
be Dr.) and Elias Dubbeldam, for their research insights and continued
collaboration.

I would also like to acknowledge my former colleagues and co-authors,
Dr.~Florian Böing-Messing and Dr.~Khodakaram Salimifard, for their
continued academic partnership.

Finally, I am grateful to the students of the courses \emph{Data
Analytics: Machine Learning} and \emph{Data Wrangling} at the University
of Amsterdam. Their feedback has helped refine the material in
meaningful ways, particularly John Gatev, whose thoughtful comments were
especially valuable.

To everyone who supported this book, your encouragement, feedback, and
collaboration have meant more than I can say.

\begin{center}
\textit{All models are wrong, but some are useful.}
\end{center}
\begin{flushright}
— George Box
\end{flushright}

Reza Mohammadi\\
Amsterdam, Netherlands\\
August 2025

\bookmarksetup{startatroot}

\chapter*{References}\label{references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\end{CSLReferences}




\end{document}
