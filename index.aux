\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\newlabel{section}{{}{5}{}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{}{5}{chapter*.2}\protected@file@percent }
\newlabel{preface}{{}{5}{Preface}{chapter*.3}{}}
\@writefile{toc}{\contentsline {chapter}{Preface}{5}{chapter*.3}\protected@file@percent }
\newlabel{why-this-book}{{}{6}{Why This Book?}{section*.4}{}}
\@writefile{toc}{\contentsline {section}{Why This Book?}{6}{section*.4}\protected@file@percent }
\newlabel{who-should-read-this-book}{{}{6}{Who Should Read This Book?}{section*.5}{}}
\@writefile{toc}{\contentsline {section}{Who Should Read This Book?}{6}{section*.5}\protected@file@percent }
\newlabel{skills-you-will-gain}{{}{7}{Skills You Will Gain}{section*.6}{}}
\@writefile{toc}{\contentsline {section}{Skills You Will Gain}{7}{section*.6}\protected@file@percent }
\newlabel{structure-of-this-book}{{}{8}{Structure of This Book}{section*.7}{}}
\@writefile{toc}{\contentsline {section}{Structure of This Book}{8}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {0.1}{\ignorespaces The Data Science Workflow is an iterative framework for structuring data science and machine learning projects. Inspired by the CRISP-DM model (Cross-Industry Standard Process for Data Mining), it supports systematic problem-solving and continuous refinement.}}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig-ch0_DSW}{{0.1}{9}{The Data Science Workflow is an iterative framework for structuring data science and machine learning projects. Inspired by the CRISP-DM model (Cross-Industry Standard Process for Data Mining), it supports systematic problem-solving and continuous refinement}{figure.caption.8}{}}
\newlabel{how-to-use-this-book}{{}{10}{How to Use This Book}{section*.9}{}}
\@writefile{toc}{\contentsline {section}{How to Use This Book}{10}{section*.9}\protected@file@percent }
\newlabel{datasets-used-in-this-book}{{}{11}{Datasets Used in This Book}{section*.10}{}}
\@writefile{toc}{\contentsline {section}{Datasets Used in This Book}{11}{section*.10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {0.1}{\ignorespaces Overview of datasets used for case studies in different chapters. All datasets are included in the R package liver.}}{11}{table.caption.11}\protected@file@percent }
\newlabel{tbl-data-table}{{0.1}{11}{Overview of datasets used for case studies in different chapters. All datasets are included in the R package liver}{table.caption.11}{}}
\newlabel{how-to-teach-with-this-book}{{}{12}{How to Teach with This Book}{section*.12}{}}
\@writefile{toc}{\contentsline {section}{How to Teach with This Book}{12}{section*.12}\protected@file@percent }
\newlabel{acknowledgments}{{}{13}{Acknowledgments}{section*.13}{}}
\@writefile{toc}{\contentsline {section}{Acknowledgments}{13}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Getting Started with R}{15}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch1-intro-R}{{1}{15}{Getting Started with R}{chapter.1}{}}
\newlabel{why-choose-r-for-data-science}{{1}{16}{Why Choose R for Data Science?}{section*.14}{}}
\@writefile{toc}{\contentsline {subsection}{Why Choose R for Data Science?}{16}{section*.14}\protected@file@percent }
\newlabel{what-this-chapter-covers}{{1}{16}{What This Chapter Covers}{section*.15}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{16}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.1}How to Learn R}{17}{section.1.1}\protected@file@percent }
\newlabel{how-to-learn-r}{{1.1}{17}{How to Learn R}{section.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The Power of Tiny Gains: A 1\% improvement every day leads to exponential growth over time. This plot was created entirely in R.}}{18}{figure.caption.16}\protected@file@percent }
\newlabel{fig-ch1-tiny-gains}{{1.1}{18}{The Power of Tiny Gains: A 1\% improvement every day leads to exponential growth over time. This plot was created entirely in R}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}How to Install R}{19}{section.1.2}\protected@file@percent }
\newlabel{how-to-install-r}{{1.2}{19}{How to Install R}{section.1.2}{}}
\newlabel{keeping-r-up-to-date}{{1.2}{19}{Keeping R Up to Date}{section*.17}{}}
\@writefile{toc}{\contentsline {subsection}{Keeping R Up to Date}{19}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}How to Install RStudio}{19}{section.1.3}\protected@file@percent }
\newlabel{how-to-install-rstudio}{{1.3}{19}{How to Install RStudio}{section.1.3}{}}
\newlabel{installing-rstudio}{{1.3}{20}{Installing RStudio}{section*.18}{}}
\@writefile{toc}{\contentsline {subsection}{Installing RStudio}{20}{section*.18}\protected@file@percent }
\newlabel{exploring-the-rstudio-interface}{{1.3}{20}{Exploring the RStudio Interface}{section*.19}{}}
\@writefile{toc}{\contentsline {subsection}{Exploring the RStudio Interface}{20}{section*.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces The RStudio window when you first launch the program.}}{21}{figure.caption.20}\protected@file@percent }
\newlabel{fig-RStudio-window-1}{{1.2}{21}{The RStudio window when you first launch the program}{figure.caption.20}{}}
\newlabel{customizing-rstudio}{{1.3}{21}{Customizing RStudio}{section*.21}{}}
\@writefile{toc}{\contentsline {subsection}{Customizing RStudio}{21}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Getting Help and Learning More}{22}{section.1.4}\protected@file@percent }
\newlabel{getting-help-and-learning-more}{{1.4}{22}{Getting Help and Learning More}{section.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Data Science and Machine Learning with R}{23}{section.1.5}\protected@file@percent }
\newlabel{data-science-and-machine-learning-with-r}{{1.5}{23}{Data Science and Machine Learning with R}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}How to Install R Packages}{24}{section.1.6}\protected@file@percent }
\newlabel{sec-install-packages}{{1.6}{24}{How to Install R Packages}{section.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Installing packages via the graphical interface in RStudio.}}{25}{figure.caption.22}\protected@file@percent }
\newlabel{fig-install-packages}{{1.3}{25}{Installing packages via the graphical interface in RStudio}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}How to Load R Packages}{26}{section.1.7}\protected@file@percent }
\newlabel{how-to-load-r-packages}{{1.7}{26}{How to Load R Packages}{section.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Running Your First R Code}{26}{section.1.8}\protected@file@percent }
\newlabel{running-your-first-r-code}{{1.8}{26}{Running Your First R Code}{section.1.8}{}}
\newlabel{using-comments-to-explain-your-code}{{1.8}{28}{Using Comments to Explain Your Code}{section*.23}{}}
\@writefile{toc}{\contentsline {subsection}{Using Comments to Explain Your Code}{28}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}How Functions Work in R}{28}{subsection.1.8.1}\protected@file@percent }
\newlabel{sec-ch1-functions-in-r}{{1.8.1}{28}{How Functions Work in R}{subsection.1.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Import Data into R}{29}{section.1.9}\protected@file@percent }
\newlabel{sec-ch1-import-data}{{1.9}{29}{Import Data into R}{section.1.9}{}}
\newlabel{importing-data-with-rstudios-graphical-interface}{{1.9}{29}{Importing Data with RStudio's Graphical Interface}{section*.24}{}}
\@writefile{toc}{\contentsline {subsection}{Importing Data with RStudio's Graphical Interface}{29}{section*.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Using the `Import Dataset' tab in RStudio to load data.}}{30}{figure.caption.25}\protected@file@percent }
\newlabel{fig-load-data}{{1.4}{30}{Using the `Import Dataset' tab in RStudio to load data}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Adjusting import settings in RStudio before loading the dataset.}}{31}{figure.caption.26}\protected@file@percent }
\newlabel{fig-load-data-2}{{1.5}{31}{Adjusting import settings in RStudio before loading the dataset}{figure.caption.26}{}}
\newlabel{importing-csv-files-with-read.csv}{{1.9}{31}{\texorpdfstring {Importing CSV Files with \texttt {read.csv()}}{Importing CSV Files with read.csv()}}{section*.27}{}}
\@writefile{toc}{\contentsline {subsection}{Importing CSV Files with \texttt  {read.csv()}}{31}{section*.27}\protected@file@percent }
\newlabel{setting-the-working-directory}{{1.9}{32}{Setting the Working Directory}{section*.28}{}}
\@writefile{toc}{\contentsline {subsection}{Setting the Working Directory}{32}{section*.28}\protected@file@percent }
\newlabel{importing-data-using-dialogs-and-urls}{{1.9}{32}{Importing Data Using Dialogs and URLs}{section*.29}{}}
\@writefile{toc}{\contentsline {subsection}{Importing Data Using Dialogs and URLs}{32}{section*.29}\protected@file@percent }
\newlabel{importing-excel-files-with-read_excel}{{1.9}{33}{\texorpdfstring {Importing Excel Files with \texttt {read\_excel()}}{Importing Excel Files with read\_excel()}}{section*.30}{}}
\@writefile{toc}{\contentsline {subsection}{Importing Excel Files with \texttt  {read\_excel()}}{33}{section*.30}\protected@file@percent }
\newlabel{loading-data-from-r-packages}{{1.9}{33}{Loading Data from R Packages}{section*.31}{}}
\@writefile{toc}{\contentsline {subsection}{Loading Data from R Packages}{33}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.10}Why Data Types Matter in R}{34}{section.1.10}\protected@file@percent }
\newlabel{why-data-types-matter-in-r}{{1.10}{34}{Why Data Types Matter in R}{section.1.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.11}Data Structures in R}{35}{section.1.11}\protected@file@percent }
\newlabel{data-structures-in-r}{{1.11}{35}{Data Structures in R}{section.1.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces A visual guide to five common data structures in R, organized by dimensionality (1D, 2D, nD) and type uniformity (single vs.~multiple types).}}{36}{figure.caption.32}\protected@file@percent }
\newlabel{fig-R-objects}{{1.6}{36}{A visual guide to five common data structures in R, organized by dimensionality (1D, 2D, nD) and type uniformity (single vs.~multiple types)}{figure.caption.32}{}}
\newlabel{vectors-in-r}{{1.11}{36}{Vectors in R}{section*.33}{}}
\@writefile{toc}{\contentsline {subsection}{Vectors in R}{36}{section*.33}\protected@file@percent }
\newlabel{matrices-in-r}{{1.11}{37}{Matrices in R}{section*.34}{}}
\@writefile{toc}{\contentsline {subsection}{Matrices in R}{37}{section*.34}\protected@file@percent }
\newlabel{data-frames-in-r}{{1.11}{38}{Data Frames in R}{section*.35}{}}
\@writefile{toc}{\contentsline {subsection}{Data Frames in R}{38}{section*.35}\protected@file@percent }
\newlabel{accessing-and-modifying-columns}{{1.11}{39}{Accessing and Modifying Columns}{section*.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{Accessing and Modifying Columns}{39}{section*.36}\protected@file@percent }
\newlabel{lists-in-r}{{1.11}{41}{Lists in R}{section*.37}{}}
\@writefile{toc}{\contentsline {subsection}{Lists in R}{41}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.12}Accessing Columns and Rows in R}{42}{section.1.12}\protected@file@percent }
\newlabel{accessing-columns-and-rows-in-r}{{1.12}{42}{Accessing Columns and Rows in R}{section.1.12}{}}
\newlabel{using-the-operator}{{1.12}{43}{\texorpdfstring {Using the \texttt {\$} Operator}{Using the \$ Operator}}{section*.38}{}}
\@writefile{toc}{\contentsline {subsection}{Using the \texttt  {\$} Operator}{43}{section*.38}\protected@file@percent }
\newlabel{using-the-operator-1}{{1.12}{43}{\texorpdfstring {Using the \texttt {{[}{]}} Operator}{Using the {[}{]} Operator}}{section*.39}{}}
\@writefile{toc}{\contentsline {subsection}{Using the \texttt  {{[}{]}} Operator}{43}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.13}How to Merge Data in R}{44}{section.1.13}\protected@file@percent }
\newlabel{how-to-merge-data-in-r}{{1.13}{44}{How to Merge Data in R}{section.1.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.14}Getting Started with Data Visualization in R}{45}{section.1.14}\protected@file@percent }
\newlabel{sec-ch1-visualization}{{1.14}{45}{Getting Started with Data Visualization in R}{section.1.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Grammar of Graphics and ggplot2 layers. The seven core layers of a ggplot: data, aesthetics, geometries, facets, statistics, coordinates, and theme.}}{47}{figure.caption.40}\protected@file@percent }
\newlabel{fig-ggplot-layes}{{1.7}{47}{Grammar of Graphics and ggplot2 layers. The seven core layers of a ggplot: data, aesthetics, geometries, facets, statistics, coordinates, and theme}{figure.caption.40}{}}
\newlabel{geom-functions-in-ggplot2}{{1.14}{48}{Geom Functions in ggplot2}{section*.41}{}}
\@writefile{toc}{\contentsline {subsection}{Geom Functions in ggplot2}{48}{section*.41}\protected@file@percent }
\newlabel{aesthetics-in-ggplot2}{{1.14}{50}{Aesthetics in ggplot2}{section*.42}{}}
\@writefile{toc}{\contentsline {subsection}{Aesthetics in ggplot2}{50}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.15}Formula in R}{52}{section.1.15}\protected@file@percent }
\newlabel{sec-formula-in-R}{{1.15}{52}{Formula in R}{section.1.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.16}Simulating Data in R}{54}{section.1.16}\protected@file@percent }
\newlabel{sec-ch1-simulate-data}{{1.16}{54}{Simulating Data in R}{section.1.16}{}}
\newlabel{ex-simulate-normal}{{1.16}{54}{Simulating Data in R}{section*.44}{}}
\newlabel{ex-simulate-patients}{{1.16}{55}{Simulating Data in R}{section*.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.17}Reporting with R Markdown}{56}{section.1.17}\protected@file@percent }
\newlabel{reporting-with-r-markdown}{{1.17}{56}{Reporting with R Markdown}{section.1.17}{}}
\newlabel{r-markdown-basics}{{1.17}{57}{R Markdown Basics}{section*.46}{}}
\@writefile{toc}{\contentsline {subsection}{R Markdown Basics}{57}{section*.46}\protected@file@percent }
\newlabel{the-header}{{1.17}{57}{The Header}{section*.47}{}}
\@writefile{toc}{\contentsline {subsection}{The Header}{57}{section*.47}\protected@file@percent }
\newlabel{code-chunks-and-inline-code}{{1.17}{58}{Code Chunks and Inline Code}{section*.48}{}}
\@writefile{toc}{\contentsline {subsection}{Code Chunks and Inline Code}{58}{section*.48}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Executing a code chunk in R Markdown using the `Run' button in RStudio.}}{59}{figure.caption.49}\protected@file@percent }
\newlabel{fig-run-chunk}{{1.8}{59}{Executing a code chunk in R Markdown using the `Run' button in RStudio}{figure.caption.49}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Behavior of code chunk options and their impact on execution, visibility, and outputs.}}{60}{table.caption.50}\protected@file@percent }
\newlabel{tbl-chunk-options}{{1.1}{60}{Behavior of code chunk options and their impact on execution, visibility, and outputs}{table.caption.50}{}}
\newlabel{styling-text}{{1.17}{61}{Styling Text}{section*.51}{}}
\@writefile{toc}{\contentsline {subsection}{Styling Text}{61}{section*.51}\protected@file@percent }
\newlabel{mastering-r-markdown}{{1.17}{62}{Mastering R Markdown}{section*.52}{}}
\@writefile{toc}{\contentsline {subsection}{Mastering R Markdown}{62}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.18}Reporting with Quarto}{62}{section.1.18}\protected@file@percent }
\newlabel{reporting-with-quarto}{{1.18}{62}{Reporting with Quarto}{section.1.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.19}Chapter Summary and Takeaways}{63}{section.1.19}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways}{{1.19}{63}{Chapter Summary and Takeaways}{section.1.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.20}Exercises}{64}{section.1.20}\protected@file@percent }
\newlabel{sec-intro-R-exercises}{{1.20}{64}{Exercises}{section.1.20}{}}
\newlabel{basic-exercises}{{1.20}{64}{Basic Exercises}{section*.53}{}}
\@writefile{toc}{\contentsline {subsection}{Basic Exercises}{64}{section*.53}\protected@file@percent }
\newlabel{more-challenging-exercises}{{1.20}{65}{More Challenging Exercises}{section*.54}{}}
\@writefile{toc}{\contentsline {subsection}{More Challenging Exercises}{65}{section*.54}\protected@file@percent }
\newlabel{reflect-and-connect}{{1.20}{67}{Reflect and Connect}{section*.55}{}}
\@writefile{toc}{\contentsline {subsection}{Reflect and Connect}{67}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Foundations of Data Science and Machine Learning}{69}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch2-intro-data-science}{{2}{69}{Foundations of Data Science and Machine Learning}{chapter.2}{}}
\newlabel{what-this-chapter-covers-1}{{2}{70}{What This Chapter Covers}{section*.56}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{70}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}What is Data Science?}{70}{section.2.1}\protected@file@percent }
\newlabel{what-is-data-science}{{2.1}{70}{What is Data Science?}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Venn diagram of data science (inspired by Drew Conway's original illustration). Data science is a multidisciplinary field that integrates computational skills, statistical reasoning, and domain knowledge to extract insights from data.}}{71}{figure.caption.57}\protected@file@percent }
\newlabel{fig-Data-Science}{{2.1}{71}{Venn diagram of data science (inspired by Drew Conway's original illustration). Data science is a multidisciplinary field that integrates computational skills, statistical reasoning, and domain knowledge to extract insights from data}{figure.caption.57}{}}
\newlabel{key-components-of-data-science}{{2.1}{71}{Key Components of Data Science}{section*.58}{}}
\@writefile{toc}{\contentsline {subsection}{Key Components of Data Science}{71}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Why Data Science Matters}{72}{section.2.2}\protected@file@percent }
\newlabel{why-data-science-matters}{{2.2}{72}{Why Data Science Matters}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}The Data Science Workflow}{73}{section.2.3}\protected@file@percent }
\newlabel{the-data-science-workflow}{{2.3}{73}{The Data Science Workflow}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The DIKW Pyramid illustrates the transformation of raw data into higher-order insights, progressing from data to information, knowledge, and ultimately wisdom.}}{74}{figure.caption.59}\protected@file@percent }
\newlabel{fig-DIKW-Pyramid}{{2.2}{74}{The DIKW Pyramid illustrates the transformation of raw data into higher-order insights, progressing from data to information, knowledge, and ultimately wisdom}{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The Data Science Workflow is an iterative framework for structuring data science and machine learning projects. Inspired by the CRISP-DM model, it emphasizes reproducibility, continuous refinement, and impact-driven analysis.}}{75}{figure.caption.60}\protected@file@percent }
\newlabel{fig-ch2_DSW}{{2.3}{75}{The Data Science Workflow is an iterative framework for structuring data science and machine learning projects. Inspired by the CRISP-DM model, it emphasizes reproducibility, continuous refinement, and impact-driven analysis}{figure.caption.60}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem Understanding}{76}{section.2.4}\protected@file@percent }
\newlabel{sec-ch2-Problem-Understanding}{{2.4}{76}{Problem Understanding}{section.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Bullet damage was recorded on planes that returned from missions. Those hit in more vulnerable areas did not return. (Image: Wikipedia).}}{76}{figure.caption.61}\protected@file@percent }
\newlabel{fig-case-WW2-plane}{{2.4}{76}{Bullet damage was recorded on planes that returned from missions. Those hit in more vulnerable areas did not return. (Image: Wikipedia)}{figure.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Distribution of bullet holes per square foot on returned aircraft.}}{76}{table.caption.62}\protected@file@percent }
\newlabel{tbl-WW2-bullet-holes}{{2.1}{76}{Distribution of bullet holes per square foot on returned aircraft}{table.caption.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Data Preparation}{78}{section.2.5}\protected@file@percent }
\newlabel{data-preparation}{{2.5}{78}{Data Preparation}{section.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Exploratory Data Analysis (EDA)}{79}{section.2.6}\protected@file@percent }
\newlabel{exploratory-data-analysis-eda}{{2.6}{79}{Exploratory Data Analysis (EDA)}{section.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Data Setup to Model}{80}{section.2.7}\protected@file@percent }
\newlabel{data-setup-to-model}{{2.7}{80}{Data Setup to Model}{section.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Modeling}{80}{section.2.8}\protected@file@percent }
\newlabel{modeling}{{2.8}{80}{Modeling}{section.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Evaluation}{81}{section.2.9}\protected@file@percent }
\newlabel{evaluation}{{2.9}{81}{Evaluation}{section.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Deployment}{82}{section.2.10}\protected@file@percent }
\newlabel{deployment}{{2.10}{82}{Deployment}{section.2.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Machine Learning: The Engine of Intelligent Systems}{83}{section.2.11}\protected@file@percent }
\newlabel{sec-ch2-machine-learning}{{2.11}{83}{Machine Learning: The Engine of Intelligent Systems}{section.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Machine learning tasks can be broadly categorized into supervised learning, unsupervised learning, and reinforcement learning, which differ in how models learn from data and what goals they pursue.}}{85}{figure.caption.63}\protected@file@percent }
\newlabel{fig-machine-learning}{{2.5}{85}{Machine learning tasks can be broadly categorized into supervised learning, unsupervised learning, and reinforcement learning, which differ in how models learn from data and what goals they pursue}{figure.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Comparison of supervised, unsupervised, and reinforcement learning tasks.}}{85}{table.caption.64}\protected@file@percent }
\newlabel{tbl-ch2-machine-learning}{{2.2}{85}{Comparison of supervised, unsupervised, and reinforcement learning tasks}{table.caption.64}{}}
\newlabel{supervised-learning-learning-from-labeled-data}{{2.11}{85}{Supervised Learning: Learning from Labeled Data}{section*.65}{}}
\@writefile{toc}{\contentsline {subsection}{Supervised Learning: Learning from Labeled Data}{85}{section*.65}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Supervised learning methods aim to predict the output variable (Y) based on input features (X).}}{86}{figure.caption.66}\protected@file@percent }
\newlabel{fig-supervised-learning}{{2.6}{86}{Supervised learning methods aim to predict the output variable (Y) based on input features (X)}{figure.caption.66}{}}
\newlabel{unsupervised-learning-discovering-structure-without-labels}{{2.11}{86}{Unsupervised Learning: Discovering Structure Without Labels}{section*.67}{}}
\@writefile{toc}{\contentsline {subsection}{Unsupervised Learning: Discovering Structure Without Labels}{86}{section*.67}\protected@file@percent }
\newlabel{reinforcement-learning-learning-through-interaction}{{2.11}{87}{Reinforcement Learning: Learning Through Interaction}{section*.68}{}}
\@writefile{toc}{\contentsline {subsection}{Reinforcement Learning: Learning Through Interaction}{87}{section*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.12}Chapter Summary and Takeaways}{88}{section.2.12}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-1}{{2.12}{88}{Chapter Summary and Takeaways}{section.2.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.13}Exercises}{89}{section.2.13}\protected@file@percent }
\newlabel{sec-ch2-exercises}{{2.13}{89}{Exercises}{section.2.13}{}}
\newlabel{warm-up-questions}{{2.13}{89}{Warm-Up Questions}{section*.69}{}}
\@writefile{toc}{\contentsline {subsection}{Warm-Up Questions}{89}{section*.69}\protected@file@percent }
\newlabel{exploring-the-data-science-workflow}{{2.13}{89}{Exploring the Data Science Workflow}{section*.70}{}}
\@writefile{toc}{\contentsline {subsection}{Exploring the Data Science Workflow}{89}{section*.70}\protected@file@percent }
\newlabel{applied-scenarios-and-case-based-thinking}{{2.13}{90}{Applied Scenarios and Case-Based Thinking}{section*.71}{}}
\@writefile{toc}{\contentsline {subsection}{Applied Scenarios and Case-Based Thinking}{90}{section*.71}\protected@file@percent }
\newlabel{applying-machine-learning-methods}{{2.13}{90}{Applying Machine Learning Methods}{section*.72}{}}
\@writefile{toc}{\contentsline {subsection}{Applying Machine Learning Methods}{90}{section*.72}\protected@file@percent }
\newlabel{evaluation-bias-and-fairness}{{2.13}{91}{Evaluation, Bias, and Fairness}{section*.73}{}}
\@writefile{toc}{\contentsline {subsection}{Evaluation, Bias, and Fairness}{91}{section*.73}\protected@file@percent }
\newlabel{broader-reflections-and-ethics}{{2.13}{91}{Broader Reflections and Ethics}{section*.74}{}}
\@writefile{toc}{\contentsline {subsection}{Broader Reflections and Ethics}{91}{section*.74}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Data Preparation in Practice: Turning Raw Data into Insight}{93}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch3-data-preparation}{{3}{93}{Data Preparation in Practice: Turning Raw Data into Insight}{chapter.3}{}}
\newlabel{what-this-chapter-covers-2}{{3}{94}{What This Chapter Covers}{section*.75}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{94}{section*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data Preparation in Action: The \emph  {diamonds} Dataset}{94}{section.3.1}\protected@file@percent }
\newlabel{sec-ch3-problem-understanding}{{3.1}{94}{\texorpdfstring {Data Preparation in Action: The \emph {diamonds} Dataset}{Data Preparation in Action: The diamonds Dataset}}{section.3.1}{}}
\newlabel{loading-and-exploring-the-diamonds-dataset}{{3.1}{95}{\texorpdfstring {Loading and Exploring the \emph {diamonds} Dataset}{Loading and Exploring the diamonds Dataset}}{section*.76}{}}
\@writefile{toc}{\contentsline {subsection}{Loading and Exploring the \emph  {diamonds} Dataset}{95}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Identifying Feature Types}{96}{section.3.2}\protected@file@percent }
\newlabel{identifying-feature-types}{{3.2}{96}{Identifying Feature Types}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of common feature types used in data analysis, including numerical (continuous and discrete) and categorical (ordinal, nominal, and binary) variables.}}{97}{figure.caption.77}\protected@file@percent }
\newlabel{fig-ch3-feature-type}{{3.1}{97}{Overview of common feature types used in data analysis, including numerical (continuous and discrete) and categorical (ordinal, nominal, and binary) variables}{figure.caption.77}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Key Considerations for Data Preparation}{98}{section.3.3}\protected@file@percent }
\newlabel{key-considerations-for-data-preparation}{{3.3}{98}{Key Considerations for Data Preparation}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Outliers: What They Are and Why They Matter}{99}{section.3.4}\protected@file@percent }
\newlabel{sec-ch3-data-pre-outliers}{{3.4}{99}{Outliers: What They Are and Why They Matter}{section.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Spotting Outliers with Visual Tools}{100}{section.3.5}\protected@file@percent }
\newlabel{spotting-outliers-with-visual-tools}{{3.5}{100}{Spotting Outliers with Visual Tools}{section.3.5}{}}
\newlabel{boxplots-visualizing-and-flagging-outliers}{{3.5}{100}{Boxplots: Visualizing and Flagging Outliers}{section*.78}{}}
\@writefile{toc}{\contentsline {subsection}{Boxplots: Visualizing and Flagging Outliers}{100}{section*.78}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Boxplots summarize a variable's distribution and flag extreme values. Outliers are identified as points beyond 1.5 times the interquartile range (IQR) from the quartiles.}}{100}{figure.caption.79}\protected@file@percent }
\newlabel{fig-simple-boxplot}{{3.2}{100}{Boxplots summarize a variable's distribution and flag extreme values. Outliers are identified as points beyond 1.5 times the interquartile range (IQR) from the quartiles}{figure.caption.79}{}}
\newlabel{histograms-revealing-outlier-patterns}{{3.5}{101}{Histograms: Revealing Outlier Patterns}{section*.81}{}}
\@writefile{toc}{\contentsline {subsection}{Histograms: Revealing Outlier Patterns}{101}{section*.81}\protected@file@percent }
\newlabel{additional-tools-for-visual-outlier-detection}{{3.5}{103}{Additional Tools for Visual Outlier Detection}{section*.82}{}}
\@writefile{toc}{\contentsline {subsection}{Additional Tools for Visual Outlier Detection}{103}{section*.82}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}How to Handle Outliers}{103}{section.3.6}\protected@file@percent }
\newlabel{sec-ch3-handle-outliers}{{3.6}{103}{How to Handle Outliers}{section.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Outlier Treatment in Action}{104}{section.3.7}\protected@file@percent }
\newlabel{outlier-treatment-in-action}{{3.7}{104}{Outlier Treatment in Action}{section.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Missing Values: What They Are and Why They Matter}{105}{section.3.8}\protected@file@percent }
\newlabel{sec-ch3-missing-values}{{3.8}{105}{Missing Values: What They Are and Why They Matter}{section.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Imputation Techniques}{106}{section.3.9}\protected@file@percent }
\newlabel{imputation-techniques}{{3.9}{106}{Imputation Techniques}{section.3.9}{}}
\newlabel{example-random-sampling-imputation-in-r}{{3.9}{107}{Example: Random Sampling Imputation in R}{section*.83}{}}
\@writefile{toc}{\contentsline {subsection}{Example: Random Sampling Imputation in R}{107}{section*.83}\protected@file@percent }
\newlabel{alternative-approaches}{{3.9}{109}{Alternative Approaches}{section*.85}{}}
\@writefile{toc}{\contentsline {subsection}{Alternative Approaches}{109}{section*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Feature Scaling}{109}{section.3.10}\protected@file@percent }
\newlabel{sec-ch3-feature-scaling}{{3.10}{109}{Feature Scaling}{section.3.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Min-Max Scaling}{110}{section.3.11}\protected@file@percent }
\newlabel{min-max-scaling}{{3.11}{110}{Min-Max Scaling}{section.3.11}{}}
\newlabel{ex-min-max}{{3.11}{110}{Min-Max Scaling}{section*.86}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.12}Z-score Scaling}{111}{section.3.12}\protected@file@percent }
\newlabel{z-score-scaling}{{3.12}{111}{Z-score Scaling}{section.3.12}{}}
\newlabel{ex-zscore}{{3.12}{112}{Z-score Scaling}{section*.88}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.13}Encoding Categorical Features for Modeling}{113}{section.3.13}\protected@file@percent }
\newlabel{sec-ch3-encoding}{{3.13}{113}{Encoding Categorical Features for Modeling}{section.3.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.14}Ordinal Encoding}{113}{section.3.14}\protected@file@percent }
\newlabel{sec-ch3-ordinal-encoding}{{3.14}{113}{Ordinal Encoding}{section.3.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.15}One-Hot Encoding}{114}{section.3.15}\protected@file@percent }
\newlabel{sec-ch3-one-hot-encoding}{{3.15}{114}{One-Hot Encoding}{section.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.15.1}One-Hot Encoding in R}{115}{subsection.3.15.1}\protected@file@percent }
\newlabel{one-hot-encoding-in-r}{{3.15.1}{115}{One-Hot Encoding in R}{subsection.3.15.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.16}Case Study: Preparing Data to Predict High Earners}{116}{section.3.16}\protected@file@percent }
\newlabel{sec-ch3-data-pre-adult}{{3.16}{116}{Case Study: Preparing Data to Predict High Earners}{section.3.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.16.1}Overview of the Dataset}{117}{subsection.3.16.1}\protected@file@percent }
\newlabel{overview-of-the-dataset}{{3.16.1}{117}{Overview of the Dataset}{subsection.3.16.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.16.2}Handling Missing Values}{120}{subsection.3.16.2}\protected@file@percent }
\newlabel{handling-missing-values}{{3.16.2}{120}{Handling Missing Values}{subsection.3.16.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.16.3}Encoding Categorical Variables}{121}{subsection.3.16.3}\protected@file@percent }
\newlabel{encoding-categorical-variables}{{3.16.3}{121}{Encoding Categorical Variables}{subsection.3.16.3}{}}
\newlabel{grouping-native.country-by-region}{{3.16.3}{122}{\texorpdfstring {Grouping \texttt {native.country} by Region}{Grouping native.country by Region}}{section*.90}{}}
\@writefile{toc}{\contentsline {subsubsection}{Grouping \texttt  {native.country} by Region}{122}{section*.90}\protected@file@percent }
\newlabel{simplifying-workclass}{{3.16.3}{123}{\texorpdfstring {Simplifying \texttt {workclass}}{Simplifying workclass}}{section*.91}{}}
\@writefile{toc}{\contentsline {subsubsection}{Simplifying \texttt  {workclass}}{123}{section*.91}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.16.4}Handling Outliers}{123}{subsection.3.16.4}\protected@file@percent }
\newlabel{handling-outliers}{{3.16.4}{123}{Handling Outliers}{subsection.3.16.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.17}Chapter Summary and Takeaways}{125}{section.3.17}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-2}{{3.17}{125}{Chapter Summary and Takeaways}{section.3.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.18}Exercises}{126}{section.3.18}\protected@file@percent }
\newlabel{sec-ch3-exercises}{{3.18}{126}{Exercises}{section.3.18}{}}
\newlabel{understanding-data-types}{{3.18}{126}{Understanding Data Types}{section*.94}{}}
\@writefile{toc}{\contentsline {subsection}{Understanding Data Types}{126}{section*.94}\protected@file@percent }
\newlabel{working-with-the-diamonds-dataset}{{3.18}{126}{Working with the Diamonds Dataset}{section*.95}{}}
\@writefile{toc}{\contentsline {subsection}{Working with the Diamonds Dataset}{126}{section*.95}\protected@file@percent }
\newlabel{detecting-and-treating-outliers}{{3.18}{126}{Detecting and Treating Outliers}{section*.96}{}}
\@writefile{toc}{\contentsline {subsection}{Detecting and Treating Outliers}{126}{section*.96}\protected@file@percent }
\newlabel{encoding-categorical-variables-1}{{3.18}{127}{Encoding Categorical Variables}{section*.97}{}}
\@writefile{toc}{\contentsline {subsection}{Encoding Categorical Variables}{127}{section*.97}\protected@file@percent }
\newlabel{exploring-the-adult-dataset}{{3.18}{127}{Exploring the Adult Dataset}{section*.98}{}}
\@writefile{toc}{\contentsline {subsection}{Exploring the Adult Dataset}{127}{section*.98}\protected@file@percent }
\newlabel{feature-engineering-and-scaling}{{3.18}{128}{Feature Engineering and Scaling}{section*.99}{}}
\@writefile{toc}{\contentsline {subsection}{Feature Engineering and Scaling}{128}{section*.99}\protected@file@percent }
\newlabel{modeling-and-real-world-scenarios}{{3.18}{128}{Modeling and Real-World Scenarios}{section*.100}{}}
\@writefile{toc}{\contentsline {subsection}{Modeling and Real-World Scenarios}{128}{section*.100}\protected@file@percent }
\newlabel{ethics-and-reflection}{{3.18}{128}{Ethics and Reflection}{section*.101}{}}
\@writefile{toc}{\contentsline {subsection}{Ethics and Reflection}{128}{section*.101}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Exploratory Data Analysis}{131}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch4-EDA}{{4}{131}{Exploratory Data Analysis}{chapter.4}{}}
\newlabel{what-this-chapter-covers-3}{{4}{132}{What This Chapter Covers}{section*.102}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{132}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Key Objectives and Guiding Questions for EDA}{132}{section.4.1}\protected@file@percent }
\newlabel{sec-EDA-objectives-questions}{{4.1}{132}{Key Objectives and Guiding Questions for EDA}{section.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Overview of Recommended Tools for Common EDA Objectives.}}{134}{table.caption.103}\protected@file@percent }
\newlabel{tbl-EDA-table-tools}{{4.1}{134}{Overview of Recommended Tools for Common EDA Objectives}{table.caption.103}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}EDA as Data Storytelling}{134}{section.4.2}\protected@file@percent }
\newlabel{eda-as-data-storytelling}{{4.2}{134}{EDA as Data Storytelling}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Changes in GDP per capita and life expectancy by region from 1962 to 2011. Dot size is proportional to population.}}{136}{figure.caption.104}\protected@file@percent }
\newlabel{fig-EDA-fig-1}{{4.1}{136}{Changes in GDP per capita and life expectancy by region from 1962 to 2011. Dot size is proportional to population}{figure.caption.104}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}EDA in Practice: The \emph  {Churn} Dataset}{136}{section.4.3}\protected@file@percent }
\newlabel{sec-ch4-EDA-churn}{{4.3}{136}{\texorpdfstring {EDA in Practice: The \emph {Churn} Dataset}{EDA in Practice: The Churn Dataset}}{section.4.3}{}}
\newlabel{understanding-the-churn-problem}{{4.3}{137}{Understanding the Churn Problem}{section*.105}{}}
\@writefile{toc}{\contentsline {subsection}{Understanding the Churn Problem}{137}{section*.105}\protected@file@percent }
\newlabel{getting-to-know-the-data}{{4.3}{138}{Getting to Know the Data}{section*.106}{}}
\@writefile{toc}{\contentsline {subsection}{Getting to Know the Data}{138}{section*.106}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Examining Categorical Features and Churn Patterns}{140}{section.4.4}\protected@file@percent }
\newlabel{sec-chapter-EDA-categorical}{{4.4}{140}{Examining Categorical Features and Churn Patterns}{section.4.4}{}}
\newlabel{relationship-between-churn-and-subscription-plans}{{4.4}{141}{Relationship Between Churn and Subscription Plans}{section*.107}{}}
\@writefile{toc}{\contentsline {subsection}{Relationship Between Churn and Subscription Plans}{141}{section*.107}\protected@file@percent }
\newlabel{relationship-between-churn-and-voice-mail-plan}{{4.4}{143}{Relationship Between Churn and Voice Mail Plan}{section*.109}{}}
\@writefile{toc}{\contentsline {subsection}{Relationship Between Churn and Voice Mail Plan}{143}{section*.109}\protected@file@percent }
\newlabel{summary-of-categorical-findings}{{4.4}{144}{Summary of Categorical Findings}{section*.111}{}}
\@writefile{toc}{\contentsline {subsection}{Summary of Categorical Findings}{144}{section*.111}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Examining Numerical Features and Behavioral Trends}{144}{section.4.5}\protected@file@percent }
\newlabel{sec-EDA-sec-numeric}{{4.5}{144}{Examining Numerical Features and Behavioral Trends}{section.4.5}{}}
\newlabel{customer-service-calls-and-churn}{{4.5}{145}{Customer Service Calls and Churn}{section*.112}{}}
\@writefile{toc}{\contentsline {subsection}{Customer Service Calls and Churn}{145}{section*.112}\protected@file@percent }
\newlabel{daytime-minutes-and-churn}{{4.5}{147}{Daytime Minutes and Churn}{section*.114}{}}
\@writefile{toc}{\contentsline {subsection}{Daytime Minutes and Churn}{147}{section*.114}\protected@file@percent }
\newlabel{evening-and-nighttime-minutes}{{4.5}{148}{Evening and Nighttime Minutes}{section*.116}{}}
\@writefile{toc}{\contentsline {subsection}{Evening and Nighttime Minutes}{148}{section*.116}\protected@file@percent }
\newlabel{international-calls-and-churn}{{4.5}{149}{International Calls and Churn}{section*.119}{}}
\@writefile{toc}{\contentsline {subsection}{International Calls and Churn}{149}{section*.119}\protected@file@percent }
\newlabel{summary-of-numerical-findings}{{4.5}{150}{Summary of Numerical Findings}{section*.121}{}}
\@writefile{toc}{\contentsline {subsection}{Summary of Numerical Findings}{150}{section*.121}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Identifying Redundancy and Correlated Features}{151}{section.4.6}\protected@file@percent }
\newlabel{sec-ch4-EDA-correlation}{{4.6}{151}{Identifying Redundancy and Correlated Features}{section.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Example scatterplots showing different correlation coefficients.}}{152}{figure.caption.122}\protected@file@percent }
\newlabel{fig-correlation}{{4.2}{152}{Example scatterplots showing different correlation coefficients}{figure.caption.122}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Scatterplot illustrating the correlation between Nobel Prize wins and chocolate consumption (per 10 million population) across countries. Adapted from Messerli (2012).}}{153}{figure.caption.123}\protected@file@percent }
\newlabel{fig-correlation-chocolate}{{4.3}{153}{Scatterplot illustrating the correlation between Nobel Prize wins and chocolate consumption (per 10 million population) across countries. Adapted from Messerli (2012)}{figure.caption.123}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Exploring Multivariate Relationships}{155}{section.4.7}\protected@file@percent }
\newlabel{sec-EDA-sec-multivariate}{{4.7}{155}{Exploring Multivariate Relationships}{section.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Insights from Exploratory Data Analysis}{157}{section.4.8}\protected@file@percent }
\newlabel{sec-EDA-summary}{{4.8}{157}{Insights from Exploratory Data Analysis}{section.4.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Chapter Summary and Takeaways}{158}{section.4.9}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-3}{{4.9}{158}{Chapter Summary and Takeaways}{section.4.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.10}Exercises}{159}{section.4.10}\protected@file@percent }
\newlabel{sec-ch4-exercises}{{4.10}{159}{Exercises}{section.4.10}{}}
\newlabel{conceptual-questions}{{4.10}{159}{Conceptual Questions}{section*.124}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions}{159}{section*.124}\protected@file@percent }
\newlabel{hands-on-practice-exploring-the-bank-dataset}{{4.10}{161}{Hands-On Practice: Exploring the Bank Dataset}{section*.125}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On Practice: Exploring the Bank Dataset}{161}{section*.125}\protected@file@percent }
\newlabel{challenge-problems}{{4.10}{162}{Challenge Problems}{section*.126}{}}
\@writefile{toc}{\contentsline {subsection}{Challenge Problems}{162}{section*.126}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Statistical Inference and Hypothesis Testing}{163}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch5-statistics}{{5}{163}{Statistical Inference and Hypothesis Testing}{chapter.5}{}}
\newlabel{what-this-chapter-covers-4}{{5}{164}{What This Chapter Covers}{section*.127}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{164}{section*.127}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction to Statistical Inference}{164}{section.5.1}\protected@file@percent }
\newlabel{introduction-to-statistical-inference}{{5.1}{164}{Introduction to Statistical Inference}{section.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A conceptual overview of statistical inference. We generate data from a population to infer properties such as the mean, using probability to quantify uncertainty.}}{165}{figure.caption.128}\protected@file@percent }
\newlabel{fig-inference}{{5.1}{165}{A conceptual overview of statistical inference. We generate data from a population to infer properties such as the mean, using probability to quantify uncertainty}{figure.caption.128}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The three core goals of statistical inference: point estimation, confidence intervals, and hypothesis testing. Together, these components allow analysts to make principled inferences from data, moving beyond description toward reliable generalization.}}{165}{figure.caption.129}\protected@file@percent }
\newlabel{fig-stat-inference-pillars}{{5.2}{165}{The three core goals of statistical inference: point estimation, confidence intervals, and hypothesis testing. Together, these components allow analysts to make principled inferences from data, moving beyond description toward reliable generalization}{figure.caption.129}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Estimation: Drawing Informed Conclusions from Sample Data}{166}{section.5.2}\protected@file@percent }
\newlabel{estimation-drawing-informed-conclusions-from-sample-data}{{5.2}{166}{Estimation: Drawing Informed Conclusions from Sample Data}{section.5.2}{}}
\newlabel{ex-est-churn-proportion}{{5.2}{166}{Estimation: Drawing Informed Conclusions from Sample Data}{section*.130}{}}
\newlabel{ex-est-service-call}{{5.2}{167}{Estimation: Drawing Informed Conclusions from Sample Data}{section*.131}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Quantifying Uncertainty: Confidence Intervals}{167}{section.5.3}\protected@file@percent }
\newlabel{sec-ch5-confidence-interval}{{5.3}{167}{Quantifying Uncertainty: Confidence Intervals}{section.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Confidence interval for the population mean. The interval is centered around the point estimate, with the width determined by the margin of error. The confidence level specifies the probability that the interval contains the true population parameter.}}{168}{figure.caption.132}\protected@file@percent }
\newlabel{fig-confidence-interval}{{5.3}{168}{Confidence interval for the population mean. The interval is centered around the point estimate, with the width determined by the margin of error. The confidence level specifies the probability that the interval contains the true population parameter}{figure.caption.132}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Hypothesis Testing}{169}{section.5.4}\protected@file@percent }
\newlabel{hypothesis-testing}{{5.4}{169}{Hypothesis Testing}{section.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Visual summary of hypothesis testing, showing how sample evidence informs the decision to reject or do not reject the null hypothesis (\(H_0\)).}}{170}{figure.caption.133}\protected@file@percent }
\newlabel{fig-hypothesis-testing}{{5.4}{170}{Visual summary of hypothesis testing, showing how sample evidence informs the decision to reject or do not reject the null hypothesis (\(H_0\))}{figure.caption.133}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Types of Hypothesis Tests}{171}{subsection.5.4.1}\protected@file@percent }
\newlabel{types-of-hypothesis-tests}{{5.4.1}{171}{Types of Hypothesis Tests}{subsection.5.4.1}{}}
\gdef \LT@i {\LT@entry 
    {1}{83.2243pt}\LT@entry 
    {1}{130.13057pt}\LT@entry 
    {1}{119.54233pt}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Possible outcomes of hypothesis testing, with two correct decisions and two types of error.}}{172}{table.5.1}\protected@file@percent }
\newlabel{tbl-hypothesis-errors}{{5.1}{172}{Possible outcomes of hypothesis testing, with two correct decisions and two types of error}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Common Tests and When to Use Them}{172}{subsection.5.4.2}\protected@file@percent }
\newlabel{common-tests-and-when-to-use-them}{{5.4.2}{172}{Common Tests and When to Use Them}{subsection.5.4.2}{}}
\gdef \LT@ii {\LT@entry 
    {1}{96.85666pt}\LT@entry 
    {1}{84.7243pt}\LT@entry 
    {1}{151.31625pt}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Common hypothesis tests, their null hypotheses, and the types of variables they apply to.}}{173}{table.5.2}\protected@file@percent }
\newlabel{tbl-hypothesis-test}{{5.2}{173}{Common hypothesis tests, their null hypotheses, and the types of variables they apply to}{table.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}One-sample t-test}{173}{section.5.5}\protected@file@percent }
\newlabel{one-sample-t-test}{{5.5}{173}{One-sample t-test}{section.5.5}{}}
\newlabel{ex-one-sample-test}{{5.5}{174}{One-sample t-test}{section*.134}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Hypothesis Testing for Proportion}{175}{section.5.6}\protected@file@percent }
\newlabel{hypothesis-testing-for-proportion}{{5.6}{175}{Hypothesis Testing for Proportion}{section.5.6}{}}
\newlabel{ex-test-proportion}{{5.6}{175}{Hypothesis Testing for Proportion}{section*.135}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Two-sample t-test}{177}{section.5.7}\protected@file@percent }
\newlabel{sec-ch5-two-sample-t-test}{{5.7}{177}{Two-sample t-test}{section.5.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Two-sample Z-test}{179}{section.5.8}\protected@file@percent }
\newlabel{sec-ch5-two-sample-z-test}{{5.8}{179}{Two-sample Z-test}{section.5.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.9}Chi-square Test}{181}{section.5.9}\protected@file@percent }
\newlabel{chi-square-test}{{5.9}{181}{Chi-square Test}{section.5.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.10}Analysis of Variance (ANOVA) Test}{183}{section.5.10}\protected@file@percent }
\newlabel{analysis-of-variance-anova-test}{{5.10}{183}{Analysis of Variance (ANOVA) Test}{section.5.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.11}Correlation Test}{185}{section.5.11}\protected@file@percent }
\newlabel{sec-ch5-correlation-test}{{5.11}{185}{Correlation Test}{section.5.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.12}From Inference to Prediction in Data Science}{187}{section.5.12}\protected@file@percent }
\newlabel{sec-ch5-inference-ds}{{5.12}{187}{From Inference to Prediction in Data Science}{section.5.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.13}Chapter Summary and Takeaways}{188}{section.5.13}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-4}{{5.13}{188}{Chapter Summary and Takeaways}{section.5.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.14}Exercises}{189}{section.5.14}\protected@file@percent }
\newlabel{sec-ch5-exercises}{{5.14}{189}{Exercises}{section.5.14}{}}
\newlabel{conceptual-questions-1}{{5.14}{189}{Conceptual Questions}{section*.139}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions}{189}{section*.139}\protected@file@percent }
\newlabel{hands-on-practice-hypothesis-testing-in-r}{{5.14}{190}{Hands-On Practice: Hypothesis Testing in R}{section*.140}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On Practice: Hypothesis Testing in R}{190}{section*.140}\protected@file@percent }
\newlabel{reflection}{{5.14}{195}{Reflection}{section*.141}{}}
\@writefile{toc}{\contentsline {subsection}{Reflection}{195}{section*.141}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Setting Up Data for Modeling}{197}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch6-setup-data}{{6}{197}{Setting Up Data for Modeling}{chapter.6}{}}
\newlabel{what-this-chapter-covers-5}{{6}{198}{What This Chapter Covers}{section*.142}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{198}{section*.142}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Why Is It Necessary to Partition the Data?}{198}{section.6.1}\protected@file@percent }
\newlabel{why-is-it-necessary-to-partition-the-data}{{6.1}{198}{Why Is It Necessary to Partition the Data?}{section.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The trade-off between model complexity and accuracy on the training and test sets. Optimal performance is achieved at the point where test set accuracy is highest, before overfitting begins to dominate.}}{199}{figure.caption.143}\protected@file@percent }
\newlabel{fig-model-complexity}{{6.1}{199}{The trade-off between model complexity and accuracy on the training and test sets. Optimal performance is achieved at the point where test set accuracy is highest, before overfitting begins to dominate}{figure.caption.143}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces A general supervised learning process for building and evaluating predictive models. The 80--20 split ratio is a common default but may be adjusted based on the problem and dataset size.}}{200}{figure.caption.144}\protected@file@percent }
\newlabel{fig-modeling}{{6.2}{200}{A general supervised learning process for building and evaluating predictive models. The 80--20 split ratio is a common default but may be adjusted based on the problem and dataset size}{figure.caption.144}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Partitioning Data: The Train--Test Split}{200}{section.6.2}\protected@file@percent }
\newlabel{sec-train-test-split}{{6.2}{200}{Partitioning Data: The Train--Test Split}{section.6.2}{}}
\newlabel{example-traintest-split-in-r}{{6.2}{201}{Example: Train--Test Split in R}{section*.145}{}}
\@writefile{toc}{\contentsline {subsection}{Example: Train--Test Split in R}{201}{section*.145}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Cross-Validation for Robust Performance Estimation}{201}{section.6.3}\protected@file@percent }
\newlabel{sec-cross-validation}{{6.3}{201}{Cross-Validation for Robust Performance Estimation}{section.6.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Illustration of k-fold cross-validation. The dataset is randomly split into k non-overlapping folds (k = 5 shown). In each iteration, the model is trained on k--1 folds (shown in green) and evaluated on the remaining fold (shown in yellow).}}{202}{figure.caption.146}\protected@file@percent }
\newlabel{fig-cross-validation}{{6.3}{202}{Illustration of k-fold cross-validation. The dataset is randomly split into k non-overlapping folds (k = 5 shown). In each iteration, the model is trained on k--1 folds (shown in green) and evaluated on the remaining fold (shown in yellow)}{figure.caption.146}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Cross-validation applied within the training set. The test set is held out for final evaluation only. This strategy eliminates the need for a separate validation set and maximizes the use of available data for both training and validation.}}{203}{figure.caption.147}\protected@file@percent }
\newlabel{fig-cross-validation-2}{{6.4}{203}{Cross-validation applied within the training set. The test set is held out for final evaluation only. This strategy eliminates the need for a separate validation set and maximizes the use of available data for both training and validation}{figure.caption.147}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}How to Validate a Train-Test Split}{203}{section.6.4}\protected@file@percent }
\newlabel{sec-ch6-validate-partition}{{6.4}{203}{How to Validate a Train-Test Split}{section.6.4}{}}
\gdef \LT@iii {\LT@entry 
    {4}{147.70787pt}\LT@entry 
    {4}{83.6875pt}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Suggested hypothesis tests (from Chapter~\ref {sec-ch5-statistics}) for validating partitions, based on the type of target feature.}}{204}{table.6.1}\protected@file@percent }
\newlabel{tbl-partition-test}{{6.1}{204}{Suggested hypothesis tests (from Chapter~\ref {sec-ch5-statistics}) for validating partitions, based on the type of target feature}{table.6.1}{}}
\newlabel{what-if-the-partition-is-invalid}{{6.4}{205}{What If the Partition Is Invalid?}{section*.148}{}}
\@writefile{toc}{\contentsline {subsection}{What If the Partition Is Invalid?}{205}{section*.148}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Dealing with Class Imbalance}{206}{section.6.5}\protected@file@percent }
\newlabel{sec-ch6-balancing}{{6.5}{206}{Dealing with Class Imbalance}{section.6.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Chapter Summary and Takeaways}{208}{section.6.6}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-5}{{6.6}{208}{Chapter Summary and Takeaways}{section.6.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Exercises}{209}{section.6.7}\protected@file@percent }
\newlabel{sec-ch6-exercises}{{6.7}{209}{Exercises}{section.6.7}{}}
\newlabel{conceptual-questions-2}{{6.7}{209}{Conceptual Questions}{section*.149}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions}{209}{section*.149}\protected@file@percent }
\newlabel{hands-on-practice}{{6.7}{210}{Hands-On Practice}{section*.150}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On Practice}{210}{section*.150}\protected@file@percent }
\newlabel{partitioning-the-data}{{6.7}{211}{Partitioning the Data}{section*.151}{}}
\@writefile{toc}{\contentsline {subsubsection}{Partitioning the Data}{211}{section*.151}\protected@file@percent }
\newlabel{validating-the-partition}{{6.7}{211}{Validating the Partition}{section*.152}{}}
\@writefile{toc}{\contentsline {subsubsection}{Validating the Partition}{211}{section*.152}\protected@file@percent }
\newlabel{balancing-the-training-dataset}{{6.7}{211}{Balancing the Training Dataset}{section*.153}{}}
\@writefile{toc}{\contentsline {subsubsection}{Balancing the Training Dataset}{211}{section*.153}\protected@file@percent }
\newlabel{self-reflection}{{6.7}{212}{Self-Reflection}{section*.154}{}}
\@writefile{toc}{\contentsline {subsection}{Self-Reflection}{212}{section*.154}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Classification Using k-Nearest Neighbors}{213}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch7-classification-knn}{{7}{213}{Classification Using k-Nearest Neighbors}{chapter.7}{}}
\newlabel{what-this-chapter-covers-6}{{7}{213}{What This Chapter Covers}{section*.155}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{213}{section*.155}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Classification}{214}{section.7.1}\protected@file@percent }
\newlabel{classification}{{7.1}{214}{Classification}{section.7.1}{}}
\newlabel{how-classification-works}{{7.1}{214}{How Classification Works}{section*.156}{}}
\@writefile{toc}{\contentsline {subsection}{How Classification Works}{214}{section*.156}\protected@file@percent }
\newlabel{classification-algorithms-and-the-role-of-knn}{{7.1}{215}{Classification Algorithms and the Role of kNN}{section*.157}{}}
\@writefile{toc}{\contentsline {subsection}{Classification Algorithms and the Role of kNN}{215}{section*.157}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}How k-Nearest Neighbors Works}{216}{section.7.2}\protected@file@percent }
\newlabel{how-k-nearest-neighbors-works}{{7.2}{216}{How k-Nearest Neighbors Works}{section.7.2}{}}
\newlabel{how-does-knn-classify-a-new-observation}{{7.2}{216}{How Does kNN Classify a New Observation?}{section*.158}{}}
\@writefile{toc}{\contentsline {subsection}{How Does kNN Classify a New Observation?}{216}{section*.158}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces A two-dimensional toy dataset with two classes (Class A and Class B) and a new data point (dark star), illustrating the kNN algorithm with k = 3 and k = 6.}}{217}{figure.caption.159}\protected@file@percent }
\newlabel{fig-ch7-knn-image}{{7.1}{217}{A two-dimensional toy dataset with two classes (Class A and Class B) and a new data point (dark star), illustrating the kNN algorithm with k = 3 and k = 6}{figure.caption.159}{}}
\newlabel{strengths-and-limitations-of-knn}{{7.2}{217}{Strengths and Limitations of kNN}{section*.160}{}}
\@writefile{toc}{\contentsline {subsection}{Strengths and Limitations of kNN}{217}{section*.160}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}kNN in Action: A Toy Example for Drug Classification}{218}{section.7.3}\protected@file@percent }
\newlabel{knn-in-action-a-toy-example-for-drug-classification}{{7.3}{218}{kNN in Action: A Toy Example for Drug Classification}{section.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Scatter plot of Age vs.~Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape.}}{219}{figure.caption.161}\protected@file@percent }
\newlabel{fig-ch7-ex-drug-1}{{7.2}{219}{Scatter plot of Age vs.~Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape}{figure.caption.161}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Scatter plot of Age vs.~Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape. The three new patients are represented by large orange circles.}}{220}{figure.caption.162}\protected@file@percent }
\newlabel{fig-ch7-ex-drug-2}{{7.3}{220}{Scatter plot of Age vs.~Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape. The three new patients are represented by large orange circles}{figure.caption.162}{}}
\newlabel{fig-ch7-ex-drug-3-1}{{7.4a}{221}{Patient 1}{figure.caption.163}{}}
\newlabel{fig-ch7-ex-drug-3-2}{{7.4b}{221}{Patient 2}{figure.caption.163}{}}
\newlabel{fig-ch7-ex-drug-3-3}{{7.4c}{221}{Patient 3}{figure.caption.163}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Zoom-in plots for the three new patients and their nearest neighbors. The left plot is for Patient 1, the middle plot is for Patient 2, and the right plot is for Patient 3.}}{221}{figure.caption.163}\protected@file@percent }
\newlabel{fig-ch7-ex-drug-3}{{7.4}{221}{Zoom-in plots for the three new patients and their nearest neighbors. The left plot is for Patient 1, the middle plot is for Patient 2, and the right plot is for Patient 3}{figure.caption.163}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}How Does kNN Measure Similarity?}{221}{section.7.4}\protected@file@percent }
\newlabel{sec-ch7-knn-distance-metrics}{{7.4}{221}{How Does kNN Measure Similarity?}{section.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Euclidean Distance}{222}{subsection.7.4.1}\protected@file@percent }
\newlabel{euclidean-distance}{{7.4.1}{222}{Euclidean Distance}{subsection.7.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Visual representation of Euclidean distance between two patients in 2D space.}}{223}{figure.caption.164}\protected@file@percent }
\newlabel{fig-ch7-euclidean-distance}{{7.5}{223}{Visual representation of Euclidean distance between two patients in 2D space}{figure.caption.164}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Data Preparation for the kNN Algorithm}{223}{section.7.5}\protected@file@percent }
\newlabel{sec-ch7-knn-prep}{{7.5}{223}{Data Preparation for the kNN Algorithm}{section.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Encoding Categorical Variables for kNN}{224}{subsection.7.5.1}\protected@file@percent }
\newlabel{encoding-categorical-variables-for-knn}{{7.5.1}{224}{Encoding Categorical Variables for kNN}{subsection.7.5.1}{}}
\newlabel{binary-and-nominal-variables-one-hot-encoding}{{7.5.1}{224}{Binary and Nominal Variables: One-Hot Encoding}{section*.165}{}}
\@writefile{toc}{\contentsline {subsubsection}{Binary and Nominal Variables: One-Hot Encoding}{224}{section*.165}\protected@file@percent }
\newlabel{ordinal-variables-numeric-encoding}{{7.5.1}{225}{Ordinal Variables: Numeric Encoding}{section*.166}{}}
\@writefile{toc}{\contentsline {subsubsection}{Ordinal Variables: Numeric Encoding}{225}{section*.166}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Scaling Features for Fair Distance Computation}{226}{subsection.7.5.2}\protected@file@percent }
\newlabel{scaling-features-for-fair-distance-computation}{{7.5.2}{226}{Scaling Features for Fair Distance Computation}{subsection.7.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}Preventing Data Leakage during Scaling}{227}{subsection.7.5.3}\protected@file@percent }
\newlabel{sec-ch7-knn-proper-scaling}{{7.5.3}{227}{Preventing Data Leakage during Scaling}{subsection.7.5.3}{}}
\newlabel{fig-ch7-ex-proper-scaling-1}{{7.6a}{228}{Without Scaling}{figure.caption.167}{}}
\newlabel{fig-ch7-ex-proper-scaling-2}{{7.6b}{228}{Proper Scaling}{figure.caption.167}{}}
\newlabel{fig-ch7-ex-proper-scaling-3}{{7.6c}{228}{Improper Scaling}{figure.caption.167}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Visualization illustrating the difference between proper scaling and improper scaling. The left panel shows the original data without scaling. The middle panel shows the results of proper scaling. The right panel shows the results of improper scaling.}}{228}{figure.caption.167}\protected@file@percent }
\newlabel{fig-ch7-ex-proper-scaling}{{7.6}{228}{Visualization illustrating the difference between proper scaling and improper scaling. The left panel shows the original data without scaling. The middle panel shows the results of proper scaling. The right panel shows the results of improper scaling}{figure.caption.167}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Choosing the Right Value of \emph  {k} in kNN}{228}{section.7.6}\protected@file@percent }
\newlabel{choosing-the-right-value-of-k-in-knn}{{7.6}{228}{\texorpdfstring {Choosing the Right Value of \emph {k} in kNN}{Choosing the Right Value of k in kNN}}{section.7.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Case Study: Predicting Customer Churn with kNN}{229}{section.7.7}\protected@file@percent }
\newlabel{sec-ch7-knn-churn}{{7.7}{229}{Case Study: Predicting Customer Churn with kNN}{section.7.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}Partitioning and Preprocessing the Data for kNN}{231}{subsection.7.7.1}\protected@file@percent }
\newlabel{partitioning-and-preprocessing-the-data-for-knn}{{7.7.1}{231}{Partitioning and Preprocessing the Data for kNN}{subsection.7.7.1}{}}
\newlabel{encoding-categorical-features-for-knn}{{7.7.1}{231}{Encoding Categorical Features for kNN}{section*.168}{}}
\@writefile{toc}{\contentsline {subsubsection}{Encoding Categorical Features for kNN}{231}{section*.168}\protected@file@percent }
\newlabel{feature-scaling-for-knn}{{7.7.1}{232}{Feature Scaling for kNN}{section*.169}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Scaling for kNN}{232}{section*.169}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.2}Finding the Best Value for (k)}{233}{subsection.7.7.2}\protected@file@percent }
\newlabel{finding-the-best-value-for-k}{{7.7.2}{233}{Finding the Best Value for (k)}{subsection.7.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Accuracy of the kNN algorithm on the churn dataset for values of k ranging from 1 to 30.}}{234}{figure.caption.170}\protected@file@percent }
\newlabel{fig-ch7-kNN-plot}{{7.7}{234}{Accuracy of the kNN algorithm on the churn dataset for values of k ranging from 1 to 30}{figure.caption.170}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.3}Applying the kNN Classifier}{234}{subsection.7.7.3}\protected@file@percent }
\newlabel{applying-the-knn-classifier}{{7.7.3}{234}{Applying the kNN Classifier}{subsection.7.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.4}Evaluating Model Performance of the kNN Model}{235}{subsection.7.7.4}\protected@file@percent }
\newlabel{evaluating-model-performance-of-the-knn-model}{{7.7.4}{235}{Evaluating Model Performance of the kNN Model}{subsection.7.7.4}{}}
\newlabel{summary-of-the-knn-case-study}{{7.7.4}{236}{Summary of the kNN Case Study}{section*.171}{}}
\@writefile{toc}{\contentsline {subsection}{Summary of the kNN Case Study}{236}{section*.171}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Chapter Summary and Takeaways}{236}{section.7.8}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-6}{{7.8}{236}{Chapter Summary and Takeaways}{section.7.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}Exercises}{237}{section.7.9}\protected@file@percent }
\newlabel{sec-ch7-exercises}{{7.9}{237}{Exercises}{section.7.9}{}}
\newlabel{conceptual-questions-3}{{7.9}{238}{Conceptual Questions}{section*.172}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions}{238}{section*.172}\protected@file@percent }
\newlabel{hands-on-practice-applying-knn-to-the-bank-dataset}{{7.9}{238}{Hands-On Practice: Applying kNN to the Bank Dataset}{section*.173}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On Practice: Applying kNN to the Bank Dataset}{238}{section*.173}\protected@file@percent }
\newlabel{data-exploration-and-preparation}{{7.9}{239}{Data Exploration and Preparation}{section*.174}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Exploration and Preparation}{239}{section*.174}\protected@file@percent }
\newlabel{diagnosing-the-impact-of-preprocessing}{{7.9}{240}{Diagnosing the Impact of Preprocessing}{section*.175}{}}
\@writefile{toc}{\contentsline {subsubsection}{Diagnosing the Impact of Preprocessing}{240}{section*.175}\protected@file@percent }
\newlabel{choosing-the-optimal-k}{{7.9}{240}{Choosing the Optimal k}{section*.176}{}}
\@writefile{toc}{\contentsline {subsubsection}{Choosing the Optimal k}{240}{section*.176}\protected@file@percent }
\newlabel{building-and-evaluating-the-knn-model}{{7.9}{240}{Building and Evaluating the kNN Model}{section*.177}{}}
\@writefile{toc}{\contentsline {subsubsection}{Building and Evaluating the kNN Model}{240}{section*.177}\protected@file@percent }
\newlabel{critical-thinking-and-real-world-applications}{{7.9}{241}{Critical Thinking and Real-World Applications}{section*.178}{}}
\@writefile{toc}{\contentsline {subsection}{Critical Thinking and Real-World Applications}{241}{section*.178}\protected@file@percent }
\newlabel{self-reflection-1}{{7.9}{242}{Self-Reflection}{section*.179}{}}
\@writefile{toc}{\contentsline {subsection}{Self-Reflection}{242}{section*.179}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Evaluating Machine Learning Models}{243}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch8-evaluation}{{8}{243}{Evaluating Machine Learning Models}{chapter.8}{}}
\newlabel{why-is-model-evaluation-important}{{8}{244}{Why Is Model Evaluation Important?}{section*.180}{}}
\@writefile{toc}{\contentsline {subsection}{Why Is Model Evaluation Important?}{244}{section*.180}\protected@file@percent }
\newlabel{what-this-chapter-covers-7}{{8}{245}{What This Chapter Covers}{section*.181}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{245}{section*.181}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Confusion Matrix}{245}{section.8.1}\protected@file@percent }
\newlabel{sec-ch8-confusion-matrix}{{8.1}{245}{Confusion Matrix}{section.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Confusion matrix for binary classification, summarizing correct and incorrect predictions based on whether the actual class is positive or negative.}}{246}{figure.caption.182}\protected@file@percent }
\newlabel{fig-ch8-confusion-matrix}{{8.1}{246}{Confusion matrix for binary classification, summarizing correct and incorrect predictions based on whether the actual class is positive or negative}{figure.caption.182}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Sensitivity and Specificity}{249}{section.8.2}\protected@file@percent }
\newlabel{sensitivity-and-specificity}{{8.2}{249}{Sensitivity and Specificity}{section.8.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Sensitivity}{249}{subsection.8.2.1}\protected@file@percent }
\newlabel{sensitivity}{{8.2.1}{249}{Sensitivity}{subsection.8.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Specificity}{250}{subsection.8.2.2}\protected@file@percent }
\newlabel{specificity}{{8.2.2}{250}{Specificity}{subsection.8.2.2}{}}
\newlabel{sensitivity-vs.-specificity-a-balancing-act}{{8.2.2}{251}{Sensitivity vs.~Specificity: A Balancing Act}{section*.183}{}}
\@writefile{toc}{\contentsline {subsection}{Sensitivity vs.~Specificity: A Balancing Act}{251}{section*.183}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Precision, Recall, and F1-Score}{251}{section.8.3}\protected@file@percent }
\newlabel{precision-recall-and-f1-score}{{8.3}{251}{Precision, Recall, and F1-Score}{section.8.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Taking Uncertainty into Account}{254}{section.8.4}\protected@file@percent }
\newlabel{sec-ch8-taking-uncertainty}{{8.4}{254}{Taking Uncertainty into Account}{section.8.4}{}}
\newlabel{ex-confusion-matrix-kNN-prob}{{8.4}{254}{Taking Uncertainty into Account}{section*.184}{}}
\newlabel{tuning-the-classification-threshold}{{8.4}{256}{Tuning the Classification Threshold}{section*.185}{}}
\@writefile{toc}{\contentsline {subsection}{Tuning the Classification Threshold}{256}{section*.185}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Receiver Operating Characteristic (ROC) curve}{256}{section.8.5}\protected@file@percent }
\newlabel{receiver-operating-characteristic-roc-curve}{{8.5}{256}{Receiver Operating Characteristic (ROC) curve}{section.8.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces The ROC curve illustrates the trade-off between sensitivity and specificity at different thresholds. The diagonal line represents a classifier with no predictive value (red dashed line), while the curves represent varying levels of performance: green for optimal and blue for good.}}{257}{figure.caption.186}\protected@file@percent }
\newlabel{fig-roc-curve}{{8.2}{257}{The ROC curve illustrates the trade-off between sensitivity and specificity at different thresholds. The diagonal line represents a classifier with no predictive value (red dashed line), while the curves represent varying levels of performance: green for optimal and blue for good}{figure.caption.186}{}}
\newlabel{ex-roc-curve-kNN}{{8.5}{258}{Receiver Operating Characteristic (ROC) curve}{section*.187}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces ROC curve for kNN with k = 9, based on churn data.}}{258}{figure.caption.188}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.6}Area Under the Curve (AUC)}{259}{section.8.6}\protected@file@percent }
\newlabel{area-under-the-curve-auc}{{8.6}{259}{Area Under the Curve (AUC)}{section.8.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces The AUC summarizes the ROC curve into a single number, representing the model's ability to rank positive cases higher than negative ones. AUC = 1: Perfect model. AUC = 0.5: No better than random guessing.}}{260}{figure.caption.189}\protected@file@percent }
\newlabel{fig-ch8-auc}{{8.4}{260}{The AUC summarizes the ROC curve into a single number, representing the model's ability to rank positive cases higher than negative ones. AUC = 1: Perfect model. AUC = 0.5: No better than random guessing}{figure.caption.189}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.7}Metrics for Multi-Class Classification}{261}{section.8.7}\protected@file@percent }
\newlabel{metrics-for-multi-class-classification}{{8.7}{261}{Metrics for Multi-Class Classification}{section.8.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces Confusion matrices for binary (left) and multi-class (right) classification. Diagonal cells show correct predictions; off-diagonal cells show misclassifications. Matrix size grows with the number of classes.}}{261}{figure.caption.190}\protected@file@percent }
\newlabel{fig-ch8-confusion-matrices}{{8.5}{261}{Confusion matrices for binary (left) and multi-class (right) classification. Diagonal cells show correct predictions; off-diagonal cells show misclassifications. Matrix size grows with the number of classes}{figure.caption.190}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.8}Evaluation Metrics for Continuous Targets}{262}{section.8.8}\protected@file@percent }
\newlabel{evaluation-metrics-for-continuous-targets}{{8.8}{262}{Evaluation Metrics for Continuous Targets}{section.8.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.9}Chapter Summary and Takeaways}{264}{section.8.9}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-7}{{8.9}{264}{Chapter Summary and Takeaways}{section.8.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Summary of evaluation metrics introduced in this chapter. Each captures a distinct aspect of model performance and should be chosen based on task-specific goals and constraints.}}{265}{table.caption.191}\protected@file@percent }
\newlabel{tbl-eval-metrics}{{8.1}{265}{Summary of evaluation metrics introduced in this chapter. Each captures a distinct aspect of model performance and should be chosen based on task-specific goals and constraints}{table.caption.191}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.10}Exercises}{266}{section.8.10}\protected@file@percent }
\newlabel{sec-ch8-exercises}{{8.10}{266}{Exercises}{section.8.10}{}}
\newlabel{conceptual-questions-4}{{8.10}{266}{Conceptual Questions}{section*.192}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions}{266}{section*.192}\protected@file@percent }
\newlabel{hands-on-practice-evaluating-models-with-the-bank-dataset}{{8.10}{267}{\texorpdfstring {Hands-On Practice: Evaluating Models with the \emph {bank} Dataset}{Hands-On Practice: Evaluating Models with the bank Dataset}}{section*.193}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On Practice: Evaluating Models with the \emph  {bank} Dataset}{267}{section*.193}\protected@file@percent }
\newlabel{data-preparation-1}{{8.10}{268}{Data Preparation}{section*.194}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Preparation}{268}{section*.194}\protected@file@percent }
\newlabel{model-training-and-evaluation}{{8.10}{268}{Model Training and Evaluation}{section*.195}{}}
\@writefile{toc}{\contentsline {subsection}{Model Training and Evaluation}{268}{section*.195}\protected@file@percent }
\newlabel{critical-thinking-and-real-world-applications-1}{{8.10}{269}{Critical Thinking and Real-World Applications}{section*.196}{}}
\@writefile{toc}{\contentsline {subsection}{Critical Thinking and Real-World Applications}{269}{section*.196}\protected@file@percent }
\newlabel{self-reflection-2}{{8.10}{269}{Self-Reflection}{section*.197}{}}
\@writefile{toc}{\contentsline {subsection}{Self-Reflection}{269}{section*.197}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Naive Bayes Classifier}{271}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch9-bayes}{{9}{271}{Naive Bayes Classifier}{chapter.9}{}}
\newlabel{what-this-chapter-covers-8}{{9}{272}{What This Chapter Covers}{section*.198}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{272}{section*.198}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Bayes' Theorem and Probabilistic Foundations}{273}{section.9.1}\protected@file@percent }
\newlabel{bayes-theorem-and-probabilistic-foundations}{{9.1}{273}{Bayes' Theorem and Probabilistic Foundations}{section.9.1}{}}
\newlabel{the-essence-of-bayes-theorem}{{9.1}{274}{The Essence of Bayes' Theorem}{section*.199}{}}
\@writefile{toc}{\contentsline {subsection}{The Essence of Bayes' Theorem}{274}{section*.199}\protected@file@percent }
\newlabel{eq-bayes-theorem}{{9.1}{274}{The Essence of Bayes' Theorem}{equation.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Venn diagram illustrating the joint and marginal probabilities in Bayes' Theorem.}}{274}{figure.caption.200}\protected@file@percent }
\newlabel{fig-venn-diagram}{{9.1}{274}{Venn diagram illustrating the joint and marginal probabilities in Bayes' Theorem}{figure.caption.200}{}}
\newlabel{eq-bayes-theorem-2}{{9.2}{275}{The Essence of Bayes' Theorem}{equation.9.2}{}}
\newlabel{ex-bayes-risk}{{9.1}{275}{The Essence of Bayes' Theorem}{section*.201}{}}
\newlabel{eq1}{{9.3}{276}{The Essence of Bayes' Theorem}{equation.9.3}{}}
\newlabel{how-does-bayes-theorem-work}{{9.1}{276}{How Does Bayes' Theorem Work?}{section*.202}{}}
\@writefile{toc}{\contentsline {subsection}{How Does Bayes' Theorem Work?}{276}{section*.202}\protected@file@percent }
\newlabel{from-bayes-theorem-to-naive-bayes}{{9.1}{277}{From Bayes' Theorem to Naive Bayes}{section*.203}{}}
\@writefile{toc}{\contentsline {subsection}{From Bayes' Theorem to Naive Bayes}{277}{section*.203}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Why Is It Called ``Naive''?}{277}{section.9.2}\protected@file@percent }
\newlabel{sec-ch9-naive}{{9.2}{277}{Why Is It Called ``Naive''?}{section.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}The Laplace Smoothing Technique}{279}{section.9.3}\protected@file@percent }
\newlabel{sec-ch9-laplace}{{9.3}{279}{The Laplace Smoothing Technique}{section.9.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Types of Naive Bayes Classifiers}{280}{section.9.4}\protected@file@percent }
\newlabel{sec-ch9-types}{{9.4}{280}{Types of Naive Bayes Classifiers}{section.9.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Case Study: Predicting Financial Risk with Naive Bayes}{281}{section.9.5}\protected@file@percent }
\newlabel{case-study-predicting-financial-risk-with-naive-bayes}{{9.5}{281}{Case Study: Predicting Financial Risk with Naive Bayes}{section.9.5}{}}
\newlabel{problem-understanding}{{9.5}{282}{Problem Understanding}{section*.204}{}}
\@writefile{toc}{\contentsline {subsection}{Problem Understanding}{282}{section*.204}\protected@file@percent }
\newlabel{data-understanding}{{9.5}{282}{Data Understanding}{section*.205}{}}
\@writefile{toc}{\contentsline {subsection}{Data Understanding}{282}{section*.205}\protected@file@percent }
\newlabel{data-setup-to-model-1}{{9.5}{283}{Data Setup to Model}{section*.206}{}}
\@writefile{toc}{\contentsline {subsection}{Data Setup to Model}{283}{section*.206}\protected@file@percent }
\newlabel{applying-the-naive-bayes-classifier}{{9.5}{285}{Applying the Naive Bayes Classifier}{section*.207}{}}
\@writefile{toc}{\contentsline {subsection}{Applying the Naive Bayes Classifier}{285}{section*.207}\protected@file@percent }
\newlabel{prediction-and-model-evaluation}{{9.5}{288}{Prediction and Model Evaluation}{section*.208}{}}
\@writefile{toc}{\contentsline {subsection}{Prediction and Model Evaluation}{288}{section*.208}\protected@file@percent }
\newlabel{confusion-matrix}{{9.5}{289}{Confusion Matrix}{section*.209}{}}
\@writefile{toc}{\contentsline {subsubsection}{Confusion Matrix}{289}{section*.209}\protected@file@percent }
\newlabel{roc-curve-and-auc}{{9.5}{290}{ROC Curve and AUC}{section*.210}{}}
\@writefile{toc}{\contentsline {subsubsection}{ROC Curve and AUC}{290}{section*.210}\protected@file@percent }
\newlabel{takeaways-from-the-case-study}{{9.5}{291}{Takeaways from the Case Study}{section*.211}{}}
\@writefile{toc}{\contentsline {subsection}{Takeaways from the Case Study}{291}{section*.211}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-8}{{9.5}{292}{Chapter Summary and Takeaways}{section*.212}{}}
\@writefile{toc}{\contentsline {section}{Chapter Summary and Takeaways}{292}{section*.212}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Exercises}{293}{section.9.6}\protected@file@percent }
\newlabel{sec-ch9-exercises}{{9.6}{293}{Exercises}{section.9.6}{}}
\newlabel{conceptual-questions-5}{{9.6}{293}{Conceptual Questions}{section*.213}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions}{293}{section*.213}\protected@file@percent }
\newlabel{hands-on-implementation-with-the-churn-dataset}{{9.6}{294}{Hands-on Implementation with the Churn Dataset}{section*.214}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-on Implementation with the Churn Dataset}{294}{section*.214}\protected@file@percent }
\newlabel{data-preparation-2}{{9.6}{294}{Data Preparation}{section*.215}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Preparation}{294}{section*.215}\protected@file@percent }
\newlabel{training-and-evaluating-the-naive-bayes-classifier}{{9.6}{295}{Training and Evaluating the Naive Bayes Classifier}{section*.216}{}}
\@writefile{toc}{\contentsline {subsection}{Training and Evaluating the Naive Bayes Classifier}{295}{section*.216}\protected@file@percent }
\newlabel{real-world-application-and-critical-thinking}{{9.6}{296}{Real-World Application and Critical Thinking}{section*.217}{}}
\@writefile{toc}{\contentsline {subsection}{Real-World Application and Critical Thinking}{296}{section*.217}\protected@file@percent }
\newlabel{self-reflection-3}{{9.6}{297}{Self-Reflection}{section*.218}{}}
\@writefile{toc}{\contentsline {subsection}{Self-Reflection}{297}{section*.218}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Regression Analysis: Foundations and Applications}{299}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch10-regression}{{10}{299}{Regression Analysis: Foundations and Applications}{chapter.10}{}}
\newlabel{what-this-chapter-covers-9}{{10}{300}{What This Chapter Covers}{section*.219}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{300}{section*.219}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Simple Linear Regression}{301}{section.10.1}\protected@file@percent }
\newlabel{sec-simple-regression}{{10.1}{301}{Simple Linear Regression}{section.10.1}{}}
\newlabel{exploring-relationships-in-the-data}{{10.1}{302}{Exploring Relationships in the Data}{section*.220}{}}
\@writefile{toc}{\contentsline {subsection}{Exploring Relationships in the Data}{302}{section*.220}\protected@file@percent }
\newlabel{fitting-a-simple-linear-regression-model}{{10.1}{303}{Fitting a Simple Linear Regression Model}{section*.221}{}}
\@writefile{toc}{\contentsline {subsection}{Fitting a Simple Linear Regression Model}{303}{section*.221}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Scatter plot of daily revenue (euros) versus daily spend (euros) for 40 observations, with the fitted least-squares regression line (red) showing the linear relationship.}}{304}{figure.caption.222}\protected@file@percent }
\newlabel{fig-scoter-plot-simple-reg}{{10.1}{304}{Scatter plot of daily revenue (euros) versus daily spend (euros) for 40 observations, with the fitted least-squares regression line (red) showing the linear relationship}{figure.caption.222}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Conceptual view of a simple regression model: the red line shows the fitted regression line, blue points represent observed data, and the vertical line illustrates a residual (error), calculated as the difference between the observed value and its predicted value.}}{305}{figure.caption.223}\protected@file@percent }
\newlabel{fig-simple-regression}{{10.2}{305}{Conceptual view of a simple regression model: the red line shows the fitted regression line, blue points represent observed data, and the vertical line illustrates a residual (error), calculated as the difference between the observed value and its predicted value}{figure.caption.223}{}}
\newlabel{fitting-the-simple-regression-model-in-r}{{10.1}{305}{Fitting the Simple Regression Model in R}{section*.224}{}}
\@writefile{toc}{\contentsline {subsection}{Fitting the Simple Regression Model in R}{305}{section*.224}\protected@file@percent }
\newlabel{making-predictions-with-the-regression-line}{{10.1}{307}{Making Predictions with the Regression Line}{section*.225}{}}
\@writefile{toc}{\contentsline {subsection}{Making Predictions with the Regression Line}{307}{section*.225}\protected@file@percent }
\newlabel{residuals-and-model-fit}{{10.1}{308}{Residuals and Model Fit}{section*.226}{}}
\@writefile{toc}{\contentsline {subsection}{Residuals and Model Fit}{308}{section*.226}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Scatter plot of daily revenue (euros) versus daily spend (euros) for 40 observations. The red line shows the fitted regression line, and the orange dashed lines represent residuals, the vertical distances between observed values and their predicted values on the line.}}{309}{figure.caption.227}\protected@file@percent }
\newlabel{fig-residual-simple-reg}{{10.3}{309}{Scatter plot of daily revenue (euros) versus daily spend (euros) for 40 observations. The red line shows the fitted regression line, and the orange dashed lines represent residuals, the vertical distances between observed values and their predicted values on the line}{figure.caption.227}{}}
\newlabel{eq-sse}{{10.3}{310}{Residuals and Model Fit}{section*.228}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Hypothesis Testing in Simple Linear Regression}{310}{section.10.2}\protected@file@percent }
\newlabel{hypothesis-testing-in-simple-linear-regression}{{10.2}{310}{Hypothesis Testing in Simple Linear Regression}{section.10.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Measuring the Quality of a Regression Model}{312}{section.10.3}\protected@file@percent }
\newlabel{measuring-the-quality-of-a-regression-model}{{10.3}{312}{Measuring the Quality of a Regression Model}{section.10.3}{}}
\newlabel{residual-standard-error-rse}{{10.3}{313}{Residual Standard Error (RSE)}{section*.229}{}}
\@writefile{toc}{\contentsline {subsection}{Residual Standard Error (RSE)}{313}{section*.229}\protected@file@percent }
\newlabel{r-squared-r2}{{10.3}{313}{\texorpdfstring {R-squared (\(R^2\))}{R-squared (R\^{}2)}}{section*.230}{}}
\@writefile{toc}{\contentsline {subsection}{R-squared (\(R^2\))}{313}{section*.230}\protected@file@percent }
\newlabel{adjusted-r-squared}{{10.3}{314}{Adjusted R-squared}{section*.231}{}}
\@writefile{toc}{\contentsline {subsection}{Adjusted R-squared}{314}{section*.231}\protected@file@percent }
\newlabel{interpreting-model-quality}{{10.3}{315}{Interpreting Model Quality}{section*.232}{}}
\@writefile{toc}{\contentsline {subsection}{Interpreting Model Quality}{315}{section*.232}\protected@file@percent }
\gdef \LT@iv {\LT@entry 
    {1}{87.76842pt}\LT@entry 
    {1}{134.6747pt}\LT@entry 
    {1}{110.4541pt}}
\@writefile{lot}{\contentsline {table}{\numberline {10.1}{\ignorespaces Overview of commonly used regression model quality metrics.}}{316}{table.10.1}\protected@file@percent }
\newlabel{tbl-reg-quality-matrics}{{10.1}{316}{Overview of commonly used regression model quality metrics}{table.10.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Multiple Linear Regression}{316}{section.10.4}\protected@file@percent }
\newlabel{sec-ch10-multiple-regression}{{10.4}{316}{Multiple Linear Regression}{section.10.4}{}}
\newlabel{fitting-the-multiple-regression-model-in-r}{{10.4}{317}{Fitting the Multiple Regression Model in R}{section*.233}{}}
\@writefile{toc}{\contentsline {subsection}{Fitting the Multiple Regression Model in R}{317}{section*.233}\protected@file@percent }
\newlabel{making-predictions}{{10.4}{318}{Making Predictions}{section*.234}{}}
\@writefile{toc}{\contentsline {subsection}{Making Predictions}{318}{section*.234}\protected@file@percent }
\newlabel{evaluating-model-performance}{{10.4}{319}{Evaluating Model Performance}{section*.235}{}}
\@writefile{toc}{\contentsline {subsection}{Evaluating Model Performance}{319}{section*.235}\protected@file@percent }
\newlabel{same-data-different-story-what-simpsons-paradox-can-teach-us}{{10.4}{319}{Same Data, Different Story: What Simpson's Paradox Can Teach Us}{section*.236}{}}
\@writefile{toc}{\contentsline {subsection}{Same Data, Different Story: What Simpson's Paradox Can Teach Us}{319}{section*.236}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Simpson's Paradox: The left plot shows a regression line fitted to the full dataset, ignoring group structure. The right plot fits separate regression lines for each group, revealing positive trends within groups that are hidden when data are aggregated.}}{320}{figure.caption.237}\protected@file@percent }
\newlabel{fig-ch10-Simpson-Paradox}{{10.4}{320}{Simpson's Paradox: The left plot shows a regression line fitted to the full dataset, ignoring group structure. The right plot fits separate regression lines for each group, revealing positive trends within groups that are hidden when data are aggregated}{figure.caption.237}{}}
\newlabel{summary-and-implications}{{10.4}{321}{Summary and Implications}{section*.238}{}}
\@writefile{toc}{\contentsline {subsection}{Summary and Implications}{321}{section*.238}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Generalized Linear Models (GLMs)}{322}{section.10.5}\protected@file@percent }
\newlabel{generalized-linear-models-glms}{{10.5}{322}{Generalized Linear Models (GLMs)}{section.10.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Logistic Regression for Binary Classification}{323}{section.10.6}\protected@file@percent }
\newlabel{sec-ch10-logistic-regression}{{10.6}{323}{Logistic Regression for Binary Classification}{section.10.6}{}}
\newlabel{fitting-a-logistic-regression-model-in-r}{{10.6}{323}{Fitting a Logistic Regression Model in R}{section*.239}{}}
\@writefile{toc}{\contentsline {subsection}{Fitting a Logistic Regression Model in R}{323}{section*.239}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.7}Poisson Regression for Modeling Count Data}{326}{section.10.7}\protected@file@percent }
\newlabel{poisson-regression-for-modeling-count-data}{{10.7}{326}{Poisson Regression for Modeling Count Data}{section.10.7}{}}
\newlabel{fitting-a-poisson-regression-model-in-r}{{10.7}{327}{Fitting a Poisson Regression Model in R}{section*.240}{}}
\@writefile{toc}{\contentsline {subsection}{Fitting a Poisson Regression Model in R}{327}{section*.240}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.8}Choosing the Right Predictors: Stepwise Regression in Action}{329}{section.10.8}\protected@file@percent }
\newlabel{sec-ch10-stepwise}{{10.8}{329}{Choosing the Right Predictors: Stepwise Regression in Action}{section.10.8}{}}
\newlabel{how-aic-guides-model-selection}{{10.8}{330}{How AIC Guides Model Selection}{section*.241}{}}
\@writefile{toc}{\contentsline {subsection}{How AIC Guides Model Selection}{330}{section*.241}\protected@file@percent }
\newlabel{stepwise-regression-in-practice-using-step-in-r}{{10.8}{331}{\texorpdfstring {Stepwise Regression in Practice: Using \texttt {step()} in R}{Stepwise Regression in Practice: Using step() in R}}{section*.242}{}}
\@writefile{toc}{\contentsline {subsection}{Stepwise Regression in Practice: Using \texttt  {step()} in R}{331}{section*.242}\protected@file@percent }
\newlabel{ex-stepwise-regression}{{10.8}{332}{\texorpdfstring {Stepwise Regression in Practice: Using \texttt {step()} in R}{Stepwise Regression in Practice: Using step() in R}}{section*.243}{}}
\newlabel{strengths-limitations-and-considerations-for-stepwise-regression}{{10.8}{335}{Strengths, Limitations, and Considerations for Stepwise Regression}{section*.244}{}}
\@writefile{toc}{\contentsline {subsection}{Strengths, Limitations, and Considerations for Stepwise Regression}{335}{section*.244}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.9}Extending Linear Models to Capture Non-Linear Relationships}{336}{section.10.9}\protected@file@percent }
\newlabel{extending-linear-models-to-capture-non-linear-relationships}{{10.9}{336}{Extending Linear Models to Capture Non-Linear Relationships}{section.10.9}{}}
\newlabel{the-need-for-non-linear-regression}{{10.9}{337}{The Need for Non-Linear Regression}{section*.245}{}}
\@writefile{toc}{\contentsline {subsection}{The Need for Non-Linear Regression}{337}{section*.245}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Scatter plot of house price (\$) versus house age (years) for the house dataset, with the fitted simple linear regression line in orange and the quadratic regression curve in blue.}}{338}{figure.caption.246}\protected@file@percent }
\newlabel{fig-scoter-plot-non-reg}{{10.5}{338}{Scatter plot of house price (\$) versus house age (years) for the house dataset, with the fitted simple linear regression line in orange and the quadratic regression curve in blue}{figure.caption.246}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.10}Polynomial Regression in Practice}{339}{section.10.10}\protected@file@percent }
\newlabel{polynomial-regression-in-practice}{{10.10}{339}{Polynomial Regression in Practice}{section.10.10}{}}
\newlabel{ex-polynomial-regression}{{10.10}{339}{Polynomial Regression in Practice}{section*.247}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.11}Diagnosing and Validating Regression Models}{341}{section.10.11}\protected@file@percent }
\newlabel{diagnosing-and-validating-regression-models}{{10.11}{341}{Diagnosing and Validating Regression Models}{section.10.11}{}}
\newlabel{ex-diagnosing-regression}{{10.11}{341}{Diagnosing and Validating Regression Models}{section*.248}{}}
\newlabel{fig-ch10-model-diagnostics-1}{{10.6a}{342}{}{figure.caption.249}{}}
\newlabel{fig-ch10-model-diagnostics-2}{{10.6b}{342}{}{figure.caption.249}{}}
\newlabel{fig-ch10-model-diagnostics-3}{{10.6c}{342}{}{figure.caption.249}{}}
\newlabel{fig-ch10-model-diagnostics-4}{{10.6d}{342}{}{figure.caption.249}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Diagnostic plots for assessing regression model assumptions.}}{342}{figure.caption.249}\protected@file@percent }
\newlabel{fig-ch10-model-diagnostics}{{10.6}{342}{Diagnostic plots for assessing regression model assumptions}{figure.caption.249}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.12}Case Study: Comparing Classifiers to Predict Customer Churn}{343}{section.10.12}\protected@file@percent }
\newlabel{sec-ch10-case-study}{{10.12}{343}{Case Study: Comparing Classifiers to Predict Customer Churn}{section.10.12}{}}
\newlabel{partitioning-and-preprocessing}{{10.12}{344}{Partitioning and Preprocessing}{section*.250}{}}
\@writefile{toc}{\contentsline {subsection}{Partitioning and Preprocessing}{344}{section*.250}\protected@file@percent }
\newlabel{training-the-logistic-regression-model}{{10.12}{345}{Training the Logistic Regression Model}{section*.251}{}}
\@writefile{toc}{\contentsline {subsection}{Training the Logistic Regression Model}{345}{section*.251}\protected@file@percent }
\newlabel{training-the-naive-bayes-model}{{10.12}{346}{Training the Naive Bayes Model}{section*.252}{}}
\@writefile{toc}{\contentsline {subsection}{Training the Naive Bayes Model}{346}{section*.252}\protected@file@percent }
\newlabel{training-the-knn-model}{{10.12}{346}{Training the kNN Model}{section*.253}{}}
\@writefile{toc}{\contentsline {subsection}{Training the kNN Model}{346}{section*.253}\protected@file@percent }
\newlabel{model-evaluation-and-comparison}{{10.12}{347}{Model Evaluation and Comparison}{section*.254}{}}
\@writefile{toc}{\contentsline {subsection}{Model Evaluation and Comparison}{347}{section*.254}\protected@file@percent }
\newlabel{reflections-and-takeaways}{{10.12}{349}{Reflections and Takeaways}{section*.255}{}}
\@writefile{toc}{\contentsline {subsection}{Reflections and Takeaways}{349}{section*.255}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.13}Chapter Summary and Takeaways}{349}{section.10.13}\protected@file@percent }
\newlabel{sec-ch10-summary}{{10.13}{349}{Chapter Summary and Takeaways}{section.10.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.14}Exercises}{350}{section.10.14}\protected@file@percent }
\newlabel{sec-ch10-exercises}{{10.14}{350}{Exercises}{section.10.14}{}}
\newlabel{simple-and-multiple-linear-regression-house-insurance-and-cereal-datasets}{{10.14}{350}{Simple and Multiple Linear Regression (House, Insurance, and Cereal Datasets)}{section*.256}{}}
\@writefile{toc}{\contentsline {subsection}{Simple and Multiple Linear Regression (House, Insurance, and Cereal Datasets)}{350}{section*.256}\protected@file@percent }
\newlabel{conceptual-understanding}{{10.14}{350}{Conceptual Understanding}{section*.257}{}}
\@writefile{toc}{\contentsline {subsubsection}{Conceptual Understanding}{350}{section*.257}\protected@file@percent }
\newlabel{applications-using-the-house-dataset}{{10.14}{351}{Applications Using the House Dataset}{section*.258}{}}
\@writefile{toc}{\contentsline {subsubsection}{Applications Using the House Dataset}{351}{section*.258}\protected@file@percent }
\newlabel{applications-using-the-insurance-dataset}{{10.14}{351}{Applications Using the Insurance Dataset}{section*.259}{}}
\@writefile{toc}{\contentsline {subsubsection}{Applications Using the Insurance Dataset}{351}{section*.259}\protected@file@percent }
\newlabel{applications-using-the-cereal-dataset}{{10.14}{352}{Applications Using the Cereal Dataset}{section*.260}{}}
\@writefile{toc}{\contentsline {subsubsection}{Applications Using the Cereal Dataset}{352}{section*.260}\protected@file@percent }
\newlabel{applications-using-the-diamonds-dataset}{{10.14}{352}{Applications Using the Diamonds Dataset}{section*.261}{}}
\@writefile{toc}{\contentsline {subsection}{Applications Using the Diamonds Dataset}{352}{section*.261}\protected@file@percent }
\newlabel{polynomial-regression-house-dataset}{{10.14}{353}{Polynomial Regression (House Dataset)}{section*.262}{}}
\@writefile{toc}{\contentsline {subsection}{Polynomial Regression (House Dataset)}{353}{section*.262}\protected@file@percent }
\newlabel{conceptual-understanding-1}{{10.14}{353}{Conceptual Understanding}{section*.263}{}}
\@writefile{toc}{\contentsline {subsubsection}{Conceptual Understanding}{353}{section*.263}\protected@file@percent }
\newlabel{applications-using-the-house-dataset-1}{{10.14}{353}{Applications Using the House Dataset}{section*.264}{}}
\@writefile{toc}{\contentsline {subsubsection}{Applications Using the House Dataset}{353}{section*.264}\protected@file@percent }
\newlabel{logistic-regression-bank-dataset}{{10.14}{354}{Logistic Regression (Bank Dataset)}{section*.265}{}}
\@writefile{toc}{\contentsline {subsection}{Logistic Regression (Bank Dataset)}{354}{section*.265}\protected@file@percent }
\newlabel{conceptual-understanding-2}{{10.14}{354}{Conceptual Understanding}{section*.266}{}}
\@writefile{toc}{\contentsline {subsubsection}{Conceptual Understanding}{354}{section*.266}\protected@file@percent }
\newlabel{applications-using-the-bank-dataset}{{10.14}{354}{Applications Using the Bank Dataset}{section*.267}{}}
\@writefile{toc}{\contentsline {subsubsection}{Applications Using the Bank Dataset}{354}{section*.267}\protected@file@percent }
\newlabel{stepwise-regression-house-dataset}{{10.14}{354}{Stepwise Regression (House Dataset)}{section*.268}{}}
\@writefile{toc}{\contentsline {subsection}{Stepwise Regression (House Dataset)}{354}{section*.268}\protected@file@percent }
\newlabel{model-diagnostics-and-validation}{{10.14}{355}{Model Diagnostics and Validation}{section*.269}{}}
\@writefile{toc}{\contentsline {subsection}{Model Diagnostics and Validation}{355}{section*.269}\protected@file@percent }
\newlabel{self-reflection-4}{{10.14}{355}{Self-Reflection}{section*.270}{}}
\@writefile{toc}{\contentsline {subsection}{Self-Reflection}{355}{section*.270}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Decision Trees and Random Forests}{357}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch11-tree-models}{{11}{357}{Decision Trees and Random Forests}{chapter.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces A classification tree built using the CART algorithm on the risk dataset to predict credit risk based on age and income. Terminal nodes display predicted class and class probabilities, highlighting CART's transparent, rule-based structure.}}{358}{figure.caption.271}\protected@file@percent }
\newlabel{fig-ch11-simple-tree}{{11.1}{358}{A classification tree built using the CART algorithm on the risk dataset to predict credit risk based on age and income. Terminal nodes display predicted class and class probabilities, highlighting CART's transparent, rule-based structure}{figure.caption.271}{}}
\newlabel{what-this-chapter-covers-10}{{11}{358}{What This Chapter Covers}{section*.272}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{358}{section*.272}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.1}How Decision Trees Work}{359}{section.11.1}\protected@file@percent }
\newlabel{how-decision-trees-work}{{11.1}{359}{How Decision Trees Work}{section.11.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces A toy dataset with two features and two classes (Class A and Class B) with 50 observations (points). This example is used to illustrate the construction of a decision tree.}}{360}{figure.caption.273}\protected@file@percent }
\newlabel{fig-ch11-tree-1}{{11.2}{360}{A toy dataset with two features and two classes (Class A and Class B) with 50 observations (points). This example is used to illustrate the construction of a decision tree}{figure.caption.273}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Left: Decision boundary for a tree with depth 1. Right: The corresponding Decision Tree.}}{361}{figure.caption.274}\protected@file@percent }
\newlabel{fig-ch11-tree-2}{{11.3}{361}{Left: Decision boundary for a tree with depth 1. Right: The corresponding Decision Tree}{figure.caption.274}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces Left: Decision boundary for a tree with depth 2. Right: The corresponding Decision Tree.}}{361}{figure.caption.275}\protected@file@percent }
\newlabel{fig-ch11-tree-3}{{11.4}{361}{Left: Decision boundary for a tree with depth 2. Right: The corresponding Decision Tree}{figure.caption.275}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces Left: Decision boundary for a tree with depth 5. Right: The corresponding Decision Tree.}}{362}{figure.caption.276}\protected@file@percent }
\newlabel{fig-ch11-tree-4}{{11.5}{362}{Left: Decision boundary for a tree with depth 5. Right: The corresponding Decision Tree}{figure.caption.276}{}}
\newlabel{making-predictions-with-a-decision-tree}{{11.1}{362}{Making Predictions with a Decision Tree}{section*.277}{}}
\@writefile{toc}{\contentsline {subsection}{Making Predictions with a Decision Tree}{362}{section*.277}\protected@file@percent }
\newlabel{controlling-tree-complexity}{{11.1}{363}{Controlling Tree Complexity}{section*.278}{}}
\@writefile{toc}{\contentsline {subsection}{Controlling Tree Complexity}{363}{section*.278}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.2}How CART Builds Decision Trees}{363}{section.11.2}\protected@file@percent }
\newlabel{how-cart-builds-decision-trees}{{11.2}{363}{How CART Builds Decision Trees}{section.11.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}C5.0: More Flexible Decision Trees}{365}{section.11.3}\protected@file@percent }
\newlabel{sec-C50}{{11.3}{365}{C5.0: More Flexible Decision Trees}{section.11.3}{}}
\newlabel{a-simple-c5.0-example}{{11.3}{366}{A Simple C5.0 Example}{section*.279}{}}
\@writefile{toc}{\contentsline {subsection}{A Simple C5.0 Example}{366}{section*.279}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces C5.0 Decision Tree trained on the risk dataset. Unlike CART, this tree allows multi-way splits and uses entropy-based splitting criteria to classify credit risk.}}{366}{figure.caption.280}\protected@file@percent }
\newlabel{fig-ch11-tree-C50}{{11.6}{366}{C5.0 Decision Tree trained on the risk dataset. Unlike CART, this tree allows multi-way splits and uses entropy-based splitting criteria to classify credit risk}{figure.caption.280}{}}
\newlabel{advantages-and-limitations}{{11.3}{367}{Advantages and Limitations}{section*.281}{}}
\@writefile{toc}{\contentsline {subsection}{Advantages and Limitations}{367}{section*.281}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Random Forests: Boosting Accuracy with an Ensemble of Trees}{367}{section.11.4}\protected@file@percent }
\newlabel{random-forests-boosting-accuracy-with-an-ensemble-of-trees}{{11.4}{367}{Random Forests: Boosting Accuracy with an Ensemble of Trees}{section.11.4}{}}
\newlabel{strengths-and-limitations-of-random-forests}{{11.4}{368}{Strengths and Limitations of Random Forests}{section*.282}{}}
\@writefile{toc}{\contentsline {subsection}{Strengths and Limitations of Random Forests}{368}{section*.282}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Case Study: Who Can Earn More Than \$50K Per Year?}{369}{section.11.5}\protected@file@percent }
\newlabel{sec-ch11-case-study}{{11.5}{369}{Case Study: Who Can Earn More Than \$50K Per Year?}{section.11.5}{}}
\newlabel{overview-of-the-dataset-1}{{11.5}{369}{Overview of the Dataset}{section*.283}{}}
\@writefile{toc}{\contentsline {subsection}{Overview of the Dataset}{369}{section*.283}\protected@file@percent }
\newlabel{data-preparation-3}{{11.5}{371}{Data Preparation}{section*.284}{}}
\@writefile{toc}{\contentsline {subsection}{Data Preparation}{371}{section*.284}\protected@file@percent }
\newlabel{handling-missing-values-1}{{11.5}{371}{Handling Missing Values}{section*.285}{}}
\@writefile{toc}{\contentsline {subsubsection}{Handling Missing Values}{371}{section*.285}\protected@file@percent }
\newlabel{transforming-categorical-variables}{{11.5}{371}{Transforming Categorical Variables}{section*.286}{}}
\@writefile{toc}{\contentsline {subsubsection}{Transforming Categorical Variables}{371}{section*.286}\protected@file@percent }
\newlabel{setup-data-for-modeling}{{11.5}{373}{Setup Data for Modeling}{section*.287}{}}
\@writefile{toc}{\contentsline {subsection}{Setup Data for Modeling}{373}{section*.287}\protected@file@percent }
\newlabel{building-a-decision-tree-with-cart}{{11.5}{374}{Building a Decision Tree with CART}{section*.288}{}}
\@writefile{toc}{\contentsline {subsection}{Building a Decision Tree with CART}{374}{section*.288}\protected@file@percent }
\newlabel{visualizing-the-decision-tree}{{11.5}{375}{Visualizing the Decision Tree}{section*.289}{}}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing the Decision Tree}{375}{section*.289}\protected@file@percent }
\newlabel{interpreting-the-decision-tree}{{11.5}{376}{Interpreting the Decision Tree}{section*.290}{}}
\@writefile{toc}{\contentsline {subsubsection}{Interpreting the Decision Tree}{376}{section*.290}\protected@file@percent }
\newlabel{building-a-decision-tree-with-c5.0}{{11.5}{377}{Building a Decision Tree with C5.0}{section*.291}{}}
\@writefile{toc}{\contentsline {subsection}{Building a Decision Tree with C5.0}{377}{section*.291}\protected@file@percent }
\newlabel{building-a-random-forest-model}{{11.5}{378}{Building a Random Forest Model}{section*.292}{}}
\@writefile{toc}{\contentsline {subsection}{Building a Random Forest Model}{378}{section*.292}\protected@file@percent }
\newlabel{model-evaluation-and-comparison-1}{{11.5}{380}{Model Evaluation and Comparison}{section*.293}{}}
\@writefile{toc}{\contentsline {subsection}{Model Evaluation and Comparison}{380}{section*.293}\protected@file@percent }
\newlabel{confusion-matrix-and-classification-errors}{{11.5}{380}{Confusion Matrix and Classification Errors}{section*.294}{}}
\@writefile{toc}{\contentsline {subsubsection}{Confusion Matrix and Classification Errors}{380}{section*.294}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.7}{\ignorespaces Confusion matrices for CART, C5.0, and Random Forest models using a cutoff value of \(0.5\). Each matrix summarizes the number of true positives, true negatives, false positives, and false negatives for the corresponding model.}}{381}{figure.caption.295}\protected@file@percent }
\newlabel{fig-ch11-conf-plots}{{11.7}{381}{Confusion matrices for CART, C5.0, and Random Forest models using a cutoff value of \(0.5\). Each matrix summarizes the number of true positives, true negatives, false positives, and false negatives for the corresponding model}{figure.caption.295}{}}
\newlabel{roc-curve-and-auc-1}{{11.5}{382}{ROC Curve and AUC}{section*.296}{}}
\@writefile{toc}{\contentsline {subsubsection}{ROC Curve and AUC}{382}{section*.296}\protected@file@percent }
\newlabel{reflections-and-takeaways-1}{{11.5}{384}{Reflections and Takeaways}{section*.297}{}}
\@writefile{toc}{\contentsline {subsection}{Reflections and Takeaways}{384}{section*.297}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Chapter Summary and Takeaways}{384}{section.11.6}\protected@file@percent }
\newlabel{sec-ch11-summary}{{11.6}{384}{Chapter Summary and Takeaways}{section.11.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Exercises}{385}{section.11.7}\protected@file@percent }
\newlabel{sec-ch11-exercises}{{11.7}{385}{Exercises}{section.11.7}{}}
\newlabel{conceptual-understanding-3}{{11.7}{385}{Conceptual Understanding}{section*.298}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Understanding}{385}{section*.298}\protected@file@percent }
\newlabel{hands-on-classification-with-the-churn-dataset}{{11.7}{386}{Hands-On: Classification with the Churn Dataset}{section*.299}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On: Classification with the Churn Dataset}{386}{section*.299}\protected@file@percent }
\newlabel{data-preparation-4}{{11.7}{386}{Data Preparation}{section*.300}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Preparation}{386}{section*.300}\protected@file@percent }
\newlabel{modeling-with-decision-trees-cart}{{11.7}{387}{Modeling with Decision Trees (CART)}{section*.301}{}}
\@writefile{toc}{\contentsline {subsubsection}{Modeling with Decision Trees (CART)}{387}{section*.301}\protected@file@percent }
\newlabel{modeling-with-decision-trees-c5.0}{{11.7}{387}{Modeling with Decision Trees (C5.0)}{section*.302}{}}
\@writefile{toc}{\contentsline {subsubsection}{Modeling with Decision Trees (C5.0)}{387}{section*.302}\protected@file@percent }
\newlabel{modeling-with-random-forests}{{11.7}{387}{Modeling with Random Forests}{section*.303}{}}
\@writefile{toc}{\contentsline {subsubsection}{Modeling with Random Forests}{387}{section*.303}\protected@file@percent }
\newlabel{regression-trees-and-random-forests-the-redwines-dataset}{{11.7}{388}{Regression Trees and Random Forests: The redWines Dataset}{section*.304}{}}
\@writefile{toc}{\contentsline {subsection}{Regression Trees and Random Forests: The redWines Dataset}{388}{section*.304}\protected@file@percent }
\newlabel{conceptual-questions-regression-trees-and-random-forests}{{11.7}{388}{Conceptual Questions: Regression Trees and Random Forests}{section*.305}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual Questions: Regression Trees and Random Forests}{388}{section*.305}\protected@file@percent }
\newlabel{hands-on-regression-with-the-redwines-dataset}{{11.7}{388}{Hands-On: Regression with the redWines Dataset}{section*.306}{}}
\@writefile{toc}{\contentsline {subsection}{Hands-On: Regression with the redWines Dataset}{388}{section*.306}\protected@file@percent }
\newlabel{data-preparation-5}{{11.7}{388}{Data Preparation}{section*.307}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data Preparation}{388}{section*.307}\protected@file@percent }
\newlabel{modeling-and-evaluation}{{11.7}{389}{Modeling and Evaluation}{section*.308}{}}
\@writefile{toc}{\contentsline {subsubsection}{Modeling and Evaluation}{389}{section*.308}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Neural Networks: The Building Blocks of Artificial Intelligence}{391}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch12-neural-networks}{{12}{391}{Neural Networks: The Building Blocks of Artificial Intelligence}{chapter.12}{}}
\newlabel{why-neural-networks-are-powerful}{{12}{392}{Why Neural Networks Are Powerful}{section*.309}{}}
\@writefile{toc}{\contentsline {subsection}{Why Neural Networks Are Powerful}{392}{section*.309}\protected@file@percent }
\newlabel{what-this-chapter-covers-11}{{12}{393}{What This Chapter Covers}{section*.310}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{393}{section*.310}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.1}The Biological Inspiration Behind Neural Networks}{394}{section.12.1}\protected@file@percent }
\newlabel{sec-ch12-bio-inspiration}{{12.1}{394}{The Biological Inspiration Behind Neural Networks}{section.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Visualization of a biological neuron, which processes input signals through dendrites and sends outputs through the axon.}}{395}{figure.caption.311}\protected@file@percent }
\newlabel{fig-ch12-net-brain}{{12.1}{395}{Visualization of a biological neuron, which processes input signals through dendrites and sends outputs through the axon}{figure.caption.311}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces Illustration of an artificial neuron, designed to emulate the structure and function of a biological neuron in a simplified way.}}{395}{figure.caption.312}\protected@file@percent }
\newlabel{fig-ch12-net-1}{{12.2}{395}{Illustration of an artificial neuron, designed to emulate the structure and function of a biological neuron in a simplified way}{figure.caption.312}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}How Neural Networks Work}{396}{section.12.2}\protected@file@percent }
\newlabel{sec-ch12-how-nn-work}{{12.2}{396}{How Neural Networks Work}{section.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces A graphical representation of a regression model: input features and predictions are shown as nodes, with the coefficients represented as connections between the nodes.}}{396}{figure.caption.313}\protected@file@percent }
\newlabel{fig-ch12-net-reg}{{12.3}{396}{A graphical representation of a regression model: input features and predictions are shown as nodes, with the coefficients represented as connections between the nodes}{figure.caption.313}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Visualization of a multilayer neural network model with two hidden layers.}}{397}{figure.caption.314}\protected@file@percent }
\newlabel{fig-ch12-net-large}{{12.4}{397}{Visualization of a multilayer neural network model with two hidden layers}{figure.caption.314}{}}
\newlabel{key-characteristics-of-neural-networks}{{12.2}{398}{Key Characteristics of Neural Networks}{section*.315}{}}
\@writefile{toc}{\contentsline {subsection}{Key Characteristics of Neural Networks}{398}{section*.315}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Activation Functions}{399}{section.12.3}\protected@file@percent }
\newlabel{activation-functions}{{12.3}{399}{Activation Functions}{section.12.3}{}}
\newlabel{the-threshold-activation-function}{{12.3}{399}{The Threshold Activation Function}{section*.316}{}}
\@writefile{toc}{\contentsline {subsection}{The Threshold Activation Function}{399}{section*.316}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Visualization of the threshold activation function (unit step).}}{400}{figure.caption.317}\protected@file@percent }
\newlabel{fig-ch12-active-fun}{{12.5}{400}{Visualization of the threshold activation function (unit step)}{figure.caption.317}{}}
\newlabel{the-sigmoid-activation-function}{{12.3}{400}{The Sigmoid Activation Function}{section*.318}{}}
\@writefile{toc}{\contentsline {subsection}{The Sigmoid Activation Function}{400}{section*.318}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces Visualization of the sigmoid activation function.}}{401}{figure.caption.319}\protected@file@percent }
\newlabel{fig-ch12-active-fun-sigmoid}{{12.6}{401}{Visualization of the sigmoid activation function}{figure.caption.319}{}}
\newlabel{common-activation-functions-in-deep-networks}{{12.3}{402}{Common Activation Functions in Deep Networks}{section*.320}{}}
\@writefile{toc}{\contentsline {subsection}{Common Activation Functions in Deep Networks}{402}{section*.320}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces Comparison of common activation functions: sigmoid, tanh, and ReLU.}}{402}{figure.caption.321}\protected@file@percent }
\newlabel{fig-ch12-active-fun-comparison}{{12.7}{402}{Comparison of common activation functions: sigmoid, tanh, and ReLU}{figure.caption.321}{}}
\newlabel{choosing-the-right-activation-function}{{12.3}{403}{Choosing the Right Activation Function}{section*.322}{}}
\@writefile{toc}{\contentsline {subsection}{Choosing the Right Activation Function}{403}{section*.322}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Network Architecture}{403}{section.12.4}\protected@file@percent }
\newlabel{network-architecture}{{12.4}{403}{Network Architecture}{section.12.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}How Neural Networks Learn}{405}{section.12.5}\protected@file@percent }
\newlabel{how-neural-networks-learn}{{12.5}{405}{How Neural Networks Learn}{section.12.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Case Study: Predicting Term Deposit Subscriptions}{407}{section.12.6}\protected@file@percent }
\newlabel{sec-ch12-case-study}{{12.6}{407}{Case Study: Predicting Term Deposit Subscriptions}{section.12.6}{}}
\newlabel{problem-understanding-1}{{12.6}{407}{Problem Understanding}{section*.323}{}}
\@writefile{toc}{\contentsline {subsection}{Problem Understanding}{407}{section*.323}\protected@file@percent }
\newlabel{overview-of-the-dataset-2}{{12.6}{408}{Overview of the Dataset}{section*.324}{}}
\@writefile{toc}{\contentsline {subsection}{Overview of the Dataset}{408}{section*.324}\protected@file@percent }
\newlabel{setup-data-for-modeling-1}{{12.6}{409}{Setup Data for Modeling}{section*.325}{}}
\@writefile{toc}{\contentsline {subsection}{Setup Data for Modeling}{409}{section*.325}\protected@file@percent }
\newlabel{encoding-binary-and-nominal-predictors}{{12.6}{411}{Encoding Binary and Nominal Predictors}{section*.326}{}}
\@writefile{toc}{\contentsline {subsubsection}{Encoding Binary and Nominal Predictors}{411}{section*.326}\protected@file@percent }
\newlabel{feature-scaling-for-numerical-predictors}{{12.6}{413}{Feature Scaling for Numerical Predictors}{section*.327}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Scaling for Numerical Predictors}{413}{section*.327}\protected@file@percent }
\newlabel{training-a-neural-network-model-in-r}{{12.6}{414}{Training a Neural Network Model in R}{section*.329}{}}
\@writefile{toc}{\contentsline {subsection}{Training a Neural Network Model in R}{414}{section*.329}\protected@file@percent }
\newlabel{prediction-and-model-evaluation-1}{{12.6}{417}{Prediction and Model Evaluation}{section*.330}{}}
\@writefile{toc}{\contentsline {subsection}{Prediction and Model Evaluation}{417}{section*.330}\protected@file@percent }
\newlabel{reflections-and-takeaways-2}{{12.6}{419}{Reflections and Takeaways}{section*.331}{}}
\@writefile{toc}{\contentsline {subsection}{Reflections and Takeaways}{419}{section*.331}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Chapter Summary and Takeaways}{420}{section.12.7}\protected@file@percent }
\newlabel{chapter-summary-and-takeaways-9}{{12.7}{420}{Chapter Summary and Takeaways}{section.12.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.8}Exercises}{421}{section.12.8}\protected@file@percent }
\newlabel{sec-ch12-exercises}{{12.8}{421}{Exercises}{section.12.8}{}}
\newlabel{conceptual-questions-6}{{12.8}{421}{Conceptual questions}{section*.332}{}}
\@writefile{toc}{\contentsline {subsection}{Conceptual questions}{421}{section*.332}\protected@file@percent }
\newlabel{practical-exercises-using-the-bank-dataset}{{12.8}{422}{\texorpdfstring {Practical exercises using the \emph {bank} dataset}{Practical exercises using the bank dataset}}{section*.333}{}}
\@writefile{toc}{\contentsline {subsection}{Practical exercises using the \emph  {bank} dataset}{422}{section*.333}\protected@file@percent }
\newlabel{data-preparation-and-model-training}{{12.8}{423}{Data preparation and model training}{section*.334}{}}
\@writefile{toc}{\contentsline {subsubsection}{Data preparation and model training}{423}{section*.334}\protected@file@percent }
\newlabel{model-evaluation-and-comparison-with-tree-based-models}{{12.8}{423}{Model evaluation and comparison with tree-based models}{section*.335}{}}
\@writefile{toc}{\contentsline {subsubsection}{Model evaluation and comparison with tree-based models}{423}{section*.335}\protected@file@percent }
\newlabel{training-neural-networks-on-the-adult-dataset}{{12.8}{424}{\texorpdfstring {Training Neural Networks on the \emph {adult} Dataset}{Training Neural Networks on the adult Dataset}}{section*.336}{}}
\@writefile{toc}{\contentsline {subsubsection}{Training Neural Networks on the \emph  {adult} Dataset}{424}{section*.336}\protected@file@percent }
\newlabel{self-reflection-5}{{12.8}{425}{Self-Reflection}{section*.337}{}}
\@writefile{toc}{\contentsline {subsection}{Self-Reflection}{425}{section*.337}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Clustering for Insight: Segmenting Data Without Labels}{427}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec-ch13-clustering}{{13}{427}{Clustering for Insight: Segmenting Data Without Labels}{chapter.13}{}}
\newlabel{what-this-chapter-covers-12}{{13}{428}{What This Chapter Covers}{section*.338}{}}
\@writefile{toc}{\contentsline {subsection}{What This Chapter Covers}{428}{section*.338}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.1}What is Cluster Analysis?}{428}{section.13.1}\protected@file@percent }
\newlabel{sec-ch13-cluster-what}{{13.1}{428}{What is Cluster Analysis?}{section.13.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Clustering algorithms aim to minimize intra-cluster variation while maximizing inter-cluster separation.}}{429}{figure.caption.339}\protected@file@percent }
\newlabel{fig-ch13-cluster-1}{{13.1}{429}{Clustering algorithms aim to minimize intra-cluster variation while maximizing inter-cluster separation}{figure.caption.339}{}}
\newlabel{how-do-clustering-algorithms-measure-similarity}{{13.1}{430}{How Do Clustering Algorithms Measure Similarity?}{section*.340}{}}
\@writefile{toc}{\contentsline {subsection}{How Do Clustering Algorithms Measure Similarity?}{430}{section*.340}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces Visual representation of Euclidean distance between two points in 2D space.}}{430}{figure.caption.341}\protected@file@percent }
\newlabel{fig-ch13-euclidean-distance}{{13.2}{430}{Visual representation of Euclidean distance between two points in 2D space}{figure.caption.341}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}K-means Clustering}{431}{section.13.2}\protected@file@percent }
\newlabel{sec-ch13-kmeans}{{13.2}{431}{K-means Clustering}{section.13.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Scatter plot of 50 data points with two features, \(x_1\) and \(x_2\), used as the starting point for K-means clustering.}}{432}{figure.caption.342}\protected@file@percent }
\newlabel{fig-ch13-example-1}{{13.3}{432}{Scatter plot of 50 data points with two features, \(x_1\) and \(x_2\), used as the starting point for K-means clustering}{figure.caption.342}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces First iteration of K-means clustering. Left panel shows randomly initialized cluster centers (red stars); right panel shows the resulting initial assignments and Voronoi regions.}}{432}{figure.caption.343}\protected@file@percent }
\newlabel{fig-ch13-example-2}{{13.4}{432}{First iteration of K-means clustering. Left panel shows randomly initialized cluster centers (red stars); right panel shows the resulting initial assignments and Voronoi regions}{figure.caption.343}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces Second iteration of K-means clustering. Left panel shows updated cluster centroids; right panel displays new assignments and the corresponding Voronoi regions.}}{433}{figure.caption.344}\protected@file@percent }
\newlabel{fig-ch13-example-3}{{13.5}{433}{Second iteration of K-means clustering. Left panel shows updated cluster centroids; right panel displays new assignments and the corresponding Voronoi regions}{figure.caption.344}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces Third iteration of K-means clustering. Cluster centroids and point assignments are updated again as the algorithm continues refining the groupings.}}{434}{figure.caption.345}\protected@file@percent }
\newlabel{fig-ch13-example-4}{{13.6}{434}{Third iteration of K-means clustering. Cluster centroids and point assignments are updated again as the algorithm continues refining the groupings}{figure.caption.345}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces Final iteration of K-means clustering. Each data point is assigned to a stable cluster after convergence.}}{434}{figure.caption.346}\protected@file@percent }
\newlabel{fig-ch13-example-5}{{13.7}{434}{Final iteration of K-means clustering. Each data point is assigned to a stable cluster after convergence}{figure.caption.346}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Selecting the Optimal Number of Clusters}{435}{section.13.3}\protected@file@percent }
\newlabel{sec-ch13-kmeans-choose}{{13.3}{435}{Selecting the Optimal Number of Clusters}{section.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.8}{\ignorespaces The elbow method visualizes the trade-off between the number of clusters and within-cluster variation, helping to identify an appropriate value for \(k\).}}{436}{figure.caption.347}\protected@file@percent }
\newlabel{fig-ch13-elbow}{{13.8}{436}{The elbow method visualizes the trade-off between the number of clusters and within-cluster variation, helping to identify an appropriate value for \(k\)}{figure.caption.347}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Case Study: Segmenting Cereal Brands by Nutrition}{437}{section.13.4}\protected@file@percent }
\newlabel{sec-ch13-case-study}{{13.4}{437}{Case Study: Segmenting Cereal Brands by Nutrition}{section.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.1}Overview of the Dataset}{437}{subsection.13.4.1}\protected